<?xml version="1.0" encoding="utf-8"?><feed xmlns="http://www.w3.org/2005/Atom" xml:lang="en"><generator uri="https://jekyllrb.com/" version="3.5.2">Jekyll</generator><link href="http://localhost:4000/feed.xml" rel="self" type="application/atom+xml" /><link href="http://localhost:4000/" rel="alternate" type="text/html" hreflang="en" /><updated>2018-10-22T10:43:28+08:00</updated><id>http://localhost:4000/</id><title type="html">Cuner</title><subtitle>No zero day.</subtitle><author><name>{&quot;name&quot;=&gt;nil, &quot;job_title&quot;=&gt;nil, &quot;location&quot;=&gt;nil, &quot;email&quot;=&gt;nil, &quot;social_links&quot;=&gt;[{&quot;name&quot;=&gt;&quot;facebook&quot;, &quot;url&quot;=&gt;nil}, {&quot;name&quot;=&gt;&quot;github&quot;, &quot;url&quot;=&gt;&quot;https://github.com/Cuner&quot;}, {&quot;name&quot;=&gt;&quot;instagram&quot;, &quot;url&quot;=&gt;nil}, {&quot;name&quot;=&gt;&quot;linkedin&quot;, &quot;url&quot;=&gt;nil}, {&quot;name&quot;=&gt;&quot;stackoverflow&quot;, &quot;url&quot;=&gt;nil}, {&quot;name&quot;=&gt;&quot;twitter&quot;, &quot;url&quot;=&gt;nil}, {&quot;name&quot;=&gt;&quot;vk&quot;, &quot;url&quot;=&gt;nil}]}</name></author><entry><title type="html">paxos与raft一致性协议</title><link href="http://localhost:4000/blog/2018/10/22/raft-diff-paxos/" rel="alternate" type="text/html" title="paxos与raft一致性协议" /><published>2018-10-22T00:00:00+08:00</published><updated>2018-10-22T00:00:00+08:00</updated><id>http://localhost:4000/blog/2018/10/22/raft-diff-paxos</id><content type="html" xml:base="http://localhost:4000/blog/2018/10/22/raft-diff-paxos/">&lt;h1 id=&quot;heading-介绍&quot;&gt;介绍&lt;/h1&gt;
&lt;p&gt;下面是关于两种一致性协议的相关论文的详细讲解，这里就不再赘述&lt;/p&gt;
&lt;ul&gt;
  &lt;li&gt;PAXOS
    &lt;ul&gt;
      &lt;li&gt;&lt;a href=&quot;https://www.jianshu.com/p/6d01a8d2df9f&quot;&gt;《Paxos Made Simple》论文翻译&lt;/a&gt;&lt;/li&gt;
      &lt;li&gt;&lt;a href=&quot;/assets/pdf/paxos-simple1.pdf&quot;&gt;《Paxos Made Simple》原文&lt;/a&gt;&lt;/li&gt;
    &lt;/ul&gt;
  &lt;/li&gt;
  &lt;li&gt;RAFT
    &lt;ul&gt;
      &lt;li&gt;&lt;a href=&quot;http://www.infoq.com/cn/articles/raft-paper&quot;&gt;《In search of an Understandable Consensus Algorithm (Extended Version)》中文翻译&lt;/a&gt;&lt;/li&gt;
      &lt;li&gt;&lt;a href=&quot;/assets/pdf/raft.pdf&quot;&gt;《In search of an Understandable Consensus Algorithm (Extended Version)》原文&lt;/a&gt;&lt;/li&gt;
      &lt;li&gt;&lt;a href=&quot;http://thesecretlivesofdata.com/raft/&quot;&gt;Raft Understandable Distributed Consensus&lt;/a&gt;&lt;/li&gt;
      &lt;li&gt;&lt;a href=&quot;https://github.com/coreos/etcd/tree/master/raft#usage&quot;&gt;raft implementation by Go&lt;/a&gt;&lt;/li&gt;
    &lt;/ul&gt;
  &lt;/li&gt;
&lt;/ul&gt;

&lt;h1 id=&quot;heading-异同&quot;&gt;异同&lt;/h1&gt;</content><author><name>{&quot;name&quot;=&gt;nil, &quot;job_title&quot;=&gt;nil, &quot;location&quot;=&gt;nil, &quot;email&quot;=&gt;nil, &quot;social_links&quot;=&gt;[{&quot;name&quot;=&gt;&quot;facebook&quot;, &quot;url&quot;=&gt;nil}, {&quot;name&quot;=&gt;&quot;github&quot;, &quot;url&quot;=&gt;&quot;https://github.com/Cuner&quot;}, {&quot;name&quot;=&gt;&quot;instagram&quot;, &quot;url&quot;=&gt;nil}, {&quot;name&quot;=&gt;&quot;linkedin&quot;, &quot;url&quot;=&gt;nil}, {&quot;name&quot;=&gt;&quot;stackoverflow&quot;, &quot;url&quot;=&gt;nil}, {&quot;name&quot;=&gt;&quot;twitter&quot;, &quot;url&quot;=&gt;nil}, {&quot;name&quot;=&gt;&quot;vk&quot;, &quot;url&quot;=&gt;nil}]}</name></author><category term="一致性协议" /><summary type="html">介绍 下面是关于两种一致性协议的相关论文的详细讲解，这里就不再赘述 PAXOS 《Paxos Made Simple》论文翻译 《Paxos Made Simple》原文 RAFT 《In search of an Understandable Consensus Algorithm (Extended Version)》中文翻译 《In search of an Understandable Consensus Algorithm (Extended Version)》原文 Raft Understandable Distributed Consensus raft implementation by Go 异同</summary></entry><entry><title type="html">基于配置的流程管理框架</title><link href="http://localhost:4000/blog/2018/08/04/flow-framework/" rel="alternate" type="text/html" title="基于配置的流程管理框架" /><published>2018-08-04T00:00:00+08:00</published><updated>2018-08-04T00:00:00+08:00</updated><id>http://localhost:4000/blog/2018/08/04/flow-framework</id><content type="html" xml:base="http://localhost:4000/blog/2018/08/04/flow-framework/">&lt;h1 id=&quot;heading-介绍&quot;&gt;介绍&lt;/h1&gt;
&lt;p&gt;通用的流程编排框架，将整个流程以xml配置文件的形式管理起来：定义流程、管理上下文、控制流程的流转（按条件或者顺序），各个流程节点的执行（同步或者异步）。同时对每个流程节点进行监控以及统计，完成对流程的整体把控。&lt;/p&gt;

&lt;h1 id=&quot;heading-基本概念&quot;&gt;基本概念&lt;/h1&gt;

&lt;ul&gt;
  &lt;li&gt;flow:数据流程对象&lt;/li&gt;
  &lt;li&gt;step:流程的子步骤，也叫流程节点&lt;/li&gt;
  &lt;li&gt;action:流程中各个步骤执行的操作&lt;/li&gt;
  &lt;li&gt;subflow:子流程，一个流程节点可以执行操作；也可以执行某个子流程&lt;/li&gt;
&lt;/ul&gt;

&lt;h1 id=&quot;heading-用法&quot;&gt;用法&lt;/h1&gt;

&lt;h2 id=&quot;heading-1定义流程的输入与输出&quot;&gt;1.定义流程的输入与输出&lt;/h2&gt;

&lt;ul&gt;
  &lt;li&gt;定义输入为Data&lt;/li&gt;
  &lt;li&gt;定义输出为Result&lt;/li&gt;
&lt;/ul&gt;

&lt;h2 id=&quot;heading-2定义步骤子节点&quot;&gt;2.定义步骤（子节点）&lt;/h2&gt;

&lt;p&gt;所有的子节点需要实现接口org.cuner.flowframework.core.Action&amp;lt;Data, Result&amp;gt;&lt;/p&gt;

&lt;div class=&quot;highlighter-rouge&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;public class Action1 implements Action&amp;lt;Data, Result&amp;gt; {
    @Override
    public void execute(FlowContext&amp;lt;Data, Result&amp;gt; context) {
        if (context.getResult() == null) {
            context.setResult(new Result());
        }
        context.setParameter(&quot;param&quot;, 1);
        context.getResult().setResult(context.getData().getData());
        System.out.println(&quot;----------flow: &quot; +  context.getFlowName() + &quot; step: &quot; + context.getStepName() + &quot; action: &quot; + this.getClass().getSimpleName() + &quot;----------&quot;);
    }
}
&lt;/code&gt;&lt;/pre&gt;
&lt;/div&gt;

&lt;p&gt;同时保证启动后，将所有action注入到spring容器中&lt;/p&gt;

&lt;div class=&quot;highlighter-rouge&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;&amp;lt;bean id=&quot;action1&quot; class=&quot;org.cuner.flowframework.test.action.Action1&quot;/&amp;gt;
&amp;lt;bean id=&quot;action2&quot; class=&quot;org.cuner.flowframework.test.action.Action2&quot;/&amp;gt;
&amp;lt;bean id=&quot;action3&quot; class=&quot;org.cuner.flowframework.test.action.Action3&quot;/&amp;gt;
&lt;/code&gt;&lt;/pre&gt;
&lt;/div&gt;

&lt;h2 id=&quot;heading-3通过xml配置定义流程&quot;&gt;3.通过xml配置定义流程&lt;/h2&gt;

&lt;p&gt;详细的配置结构请查看xsd文件&lt;/p&gt;
&lt;ul&gt;
  &lt;li&gt;&lt;code class=&quot;highlighter-rouge&quot;&gt;flows&lt;/code&gt;标签为root标签，可包含多个&lt;code class=&quot;highlighter-rouge&quot;&gt;flow&lt;/code&gt;标签&lt;/li&gt;
  &lt;li&gt;&lt;code class=&quot;highlighter-rouge&quot;&gt;flow&lt;/code&gt;标签标识一个流程，可以是一个主流程也可以是一个子流程，拥有name属性代表流程名称（流程名字要求全局唯一），可包含多个&lt;code class=&quot;highlighter-rouge&quot;&gt;step&lt;/code&gt;标签&lt;/li&gt;
  &lt;li&gt;&lt;code class=&quot;highlighter-rouge&quot;&gt;step&lt;/code&gt;标签标识一个步骤（流程节点）
    &lt;ul&gt;
      &lt;li&gt;包含零或一个&lt;code class=&quot;highlighter-rouge&quot;&gt;condition类&lt;/code&gt;标签，标识该步骤的执行条件，若没有则默认执行&lt;/li&gt;
      &lt;li&gt;包含零或多个&lt;code class=&quot;highlighter-rouge&quot;&gt;conditionTransition&lt;/code&gt;标签，标识状态的流转，若没有则默认流转到配置文件中下一个步骤&lt;/li&gt;
      &lt;li&gt;name属性：标识步骤名称&lt;/li&gt;
      &lt;li&gt;asyn属性：标识是否异步执行&lt;/li&gt;
      &lt;li&gt;action属性：标识步骤执行的操作，关联Action接口某个实现类的bean id&lt;/li&gt;
      &lt;li&gt;subflow属性：标识步骤所代表的子流程（action属性和subflow属性只能存在一者）&lt;/li&gt;
    &lt;/ul&gt;
  &lt;/li&gt;
  &lt;li&gt;&lt;code class=&quot;highlighter-rouge&quot;&gt;condition类标签&lt;/code&gt;
    &lt;ul&gt;
      &lt;li&gt;&lt;code class=&quot;highlighter-rouge&quot;&gt;condition&lt;/code&gt;标签：
        &lt;ul&gt;
          &lt;li&gt;属性key：为输入对象Data的某个属性&lt;/li&gt;
          &lt;li&gt;value：与输入对象Data的某个属性值相比较的值&lt;/li&gt;
          &lt;li&gt;comparator：关系运算符（eq、ne、gt、lt、ge、le、ln）&lt;/li&gt;
        &lt;/ul&gt;
      &lt;/li&gt;
      &lt;li&gt;&lt;code class=&quot;highlighter-rouge&quot;&gt;expCondition&lt;/code&gt;标签，拥有express属性，值为判断条件的表达式，如 data == &quot;test&quot;，其中data为输入对象Data的一个属性&lt;/li&gt;
      &lt;li&gt;&lt;code class=&quot;highlighter-rouge&quot;&gt;andCondtion&lt;/code&gt;标签，包含多个condition类标签，对多个condition的结果做与操作&lt;/li&gt;
      &lt;li&gt;&lt;code class=&quot;highlighter-rouge&quot;&gt;orCondtion&lt;/code&gt;标签，包含多个condition类标签，对多个condition的结果做或操作&lt;/li&gt;
    &lt;/ul&gt;
  &lt;/li&gt;
  &lt;li&gt;&lt;code class=&quot;highlighter-rouge&quot;&gt;conditionTransition&lt;/code&gt;标签
    &lt;ul&gt;
      &lt;li&gt;包含一个&lt;code class=&quot;highlighter-rouge&quot;&gt;condition&lt;/code&gt;标签，判断是否符合状态流程的条件&lt;/li&gt;
      &lt;li&gt;包含一个to属性：标识状态流转的下一个节点&lt;/li&gt;
    &lt;/ul&gt;
  &lt;/li&gt;
&lt;/ul&gt;

&lt;div class=&quot;highlighter-rouge&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;&lt;span class=&quot;cp&quot;&gt;&amp;lt;?xml version=&quot;1.0&quot; encoding=&quot;UTF-8&quot;?&amp;gt;&lt;/span&gt;
&lt;span class=&quot;nt&quot;&gt;&amp;lt;flows&lt;/span&gt; &lt;span class=&quot;na&quot;&gt;xmlns=&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;&quot;http://repo.cuner.com/schema/flow&quot;&lt;/span&gt;&lt;span class=&quot;nt&quot;&gt;&amp;gt;&lt;/span&gt;
    &lt;span class=&quot;nt&quot;&gt;&amp;lt;flow&lt;/span&gt; &lt;span class=&quot;na&quot;&gt;name=&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;&quot;mainFlow&quot;&lt;/span&gt;&lt;span class=&quot;nt&quot;&gt;&amp;gt;&lt;/span&gt;
        &lt;span class=&quot;nt&quot;&gt;&amp;lt;step&lt;/span&gt; &lt;span class=&quot;na&quot;&gt;name=&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;&quot;step1&quot;&lt;/span&gt; &lt;span class=&quot;na&quot;&gt;action=&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;&quot;action1&quot;&lt;/span&gt;&lt;span class=&quot;nt&quot;&gt;/&amp;gt;&lt;/span&gt;
        &lt;span class=&quot;nt&quot;&gt;&amp;lt;step&lt;/span&gt; &lt;span class=&quot;na&quot;&gt;name=&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;&quot;step2&quot;&lt;/span&gt; &lt;span class=&quot;na&quot;&gt;action=&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;&quot;action2&quot;&lt;/span&gt; &lt;span class=&quot;na&quot;&gt;asyn=&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;&quot;true&quot;&lt;/span&gt;&lt;span class=&quot;nt&quot;&gt;/&amp;gt;&lt;/span&gt;
        &lt;span class=&quot;nt&quot;&gt;&amp;lt;step&lt;/span&gt; &lt;span class=&quot;na&quot;&gt;name=&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;&quot;step3&quot;&lt;/span&gt; &lt;span class=&quot;na&quot;&gt;subflow=&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;&quot;subflow&quot;&lt;/span&gt;&lt;span class=&quot;nt&quot;&gt;/&amp;gt;&lt;/span&gt;
        &lt;span class=&quot;nt&quot;&gt;&amp;lt;step&lt;/span&gt; &lt;span class=&quot;na&quot;&gt;name=&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;&quot;step4&quot;&lt;/span&gt; &lt;span class=&quot;na&quot;&gt;subflow=&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;&quot;subflow&quot;&lt;/span&gt; &lt;span class=&quot;na&quot;&gt;asyn=&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;&quot;true&quot;&lt;/span&gt;&lt;span class=&quot;nt&quot;&gt;/&amp;gt;&lt;/span&gt;
        &lt;span class=&quot;nt&quot;&gt;&amp;lt;step&lt;/span&gt; &lt;span class=&quot;na&quot;&gt;name=&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;&quot;step5&quot;&lt;/span&gt; &lt;span class=&quot;na&quot;&gt;action=&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;&quot;action3&quot;&lt;/span&gt;&lt;span class=&quot;nt&quot;&gt;&amp;gt;&lt;/span&gt;
            &lt;span class=&quot;nt&quot;&gt;&amp;lt;condition&lt;/span&gt; &lt;span class=&quot;na&quot;&gt;key=&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;&quot;data&quot;&lt;/span&gt; &lt;span class=&quot;na&quot;&gt;value=&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;&quot;test&quot;&lt;/span&gt; &lt;span class=&quot;na&quot;&gt;comparator=&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;&quot;eq&quot;&lt;/span&gt;&lt;span class=&quot;nt&quot;&gt;/&amp;gt;&lt;/span&gt;
        &lt;span class=&quot;nt&quot;&gt;&amp;lt;/step&amp;gt;&lt;/span&gt;
        &lt;span class=&quot;nt&quot;&gt;&amp;lt;step&lt;/span&gt; &lt;span class=&quot;na&quot;&gt;name=&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;&quot;step6&quot;&lt;/span&gt; &lt;span class=&quot;na&quot;&gt;action=&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;&quot;action3&quot;&lt;/span&gt;&lt;span class=&quot;nt&quot;&gt;&amp;gt;&lt;/span&gt;
            &lt;span class=&quot;nt&quot;&gt;&amp;lt;expCondition&lt;/span&gt; &lt;span class=&quot;na&quot;&gt;expression=&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;'data.getData() == &quot;test&quot; '&lt;/span&gt;&lt;span class=&quot;nt&quot;&gt;/&amp;gt;&lt;/span&gt;
        &lt;span class=&quot;nt&quot;&gt;&amp;lt;/step&amp;gt;&lt;/span&gt;
        &lt;span class=&quot;nt&quot;&gt;&amp;lt;step&lt;/span&gt; &lt;span class=&quot;na&quot;&gt;name=&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;&quot;step7&quot;&lt;/span&gt; &lt;span class=&quot;na&quot;&gt;action=&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;&quot;action3&quot;&lt;/span&gt;&lt;span class=&quot;nt&quot;&gt;&amp;gt;&lt;/span&gt;
            &lt;span class=&quot;nt&quot;&gt;&amp;lt;andCondition&amp;gt;&lt;/span&gt;
                &lt;span class=&quot;nt&quot;&gt;&amp;lt;condition&lt;/span&gt; &lt;span class=&quot;na&quot;&gt;key=&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;&quot;data&quot;&lt;/span&gt; &lt;span class=&quot;na&quot;&gt;value=&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;&quot;test&quot;&lt;/span&gt; &lt;span class=&quot;na&quot;&gt;comparator=&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;&quot;eq&quot;&lt;/span&gt;&lt;span class=&quot;nt&quot;&gt;/&amp;gt;&lt;/span&gt;
            &lt;span class=&quot;nt&quot;&gt;&amp;lt;/andCondition&amp;gt;&lt;/span&gt;
        &lt;span class=&quot;nt&quot;&gt;&amp;lt;/step&amp;gt;&lt;/span&gt;
        &lt;span class=&quot;nt&quot;&gt;&amp;lt;step&lt;/span&gt; &lt;span class=&quot;na&quot;&gt;name=&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;&quot;step8&quot;&lt;/span&gt; &lt;span class=&quot;na&quot;&gt;action=&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;&quot;action3&quot;&lt;/span&gt;&lt;span class=&quot;nt&quot;&gt;&amp;gt;&lt;/span&gt;
            &lt;span class=&quot;nt&quot;&gt;&amp;lt;orderTransition&lt;/span&gt; &lt;span class=&quot;na&quot;&gt;to=&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;&quot;step9&quot;&lt;/span&gt;&lt;span class=&quot;nt&quot;&gt;/&amp;gt;&lt;/span&gt;
        &lt;span class=&quot;nt&quot;&gt;&amp;lt;/step&amp;gt;&lt;/span&gt;
        &lt;span class=&quot;nt&quot;&gt;&amp;lt;step&lt;/span&gt; &lt;span class=&quot;na&quot;&gt;name=&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;&quot;step9&quot;&lt;/span&gt; &lt;span class=&quot;na&quot;&gt;action=&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;&quot;action3&quot;&lt;/span&gt;&lt;span class=&quot;nt&quot;&gt;&amp;gt;&lt;/span&gt;
            &lt;span class=&quot;nt&quot;&gt;&amp;lt;conditionTransition&lt;/span&gt; &lt;span class=&quot;na&quot;&gt;to=&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;&quot;step10&quot;&lt;/span&gt;&lt;span class=&quot;nt&quot;&gt;&amp;gt;&lt;/span&gt;
                &lt;span class=&quot;nt&quot;&gt;&amp;lt;condition&lt;/span&gt; &lt;span class=&quot;na&quot;&gt;key=&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;&quot;data&quot;&lt;/span&gt; &lt;span class=&quot;na&quot;&gt;value=&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;&quot;test&quot;&lt;/span&gt; &lt;span class=&quot;na&quot;&gt;comparator=&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;&quot;eq&quot;&lt;/span&gt;&lt;span class=&quot;nt&quot;&gt;/&amp;gt;&lt;/span&gt;
            &lt;span class=&quot;nt&quot;&gt;&amp;lt;/conditionTransition&amp;gt;&lt;/span&gt;
        &lt;span class=&quot;nt&quot;&gt;&amp;lt;/step&amp;gt;&lt;/span&gt;
        &lt;span class=&quot;nt&quot;&gt;&amp;lt;step&lt;/span&gt; &lt;span class=&quot;na&quot;&gt;name=&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;&quot;step10&quot;&lt;/span&gt; &lt;span class=&quot;na&quot;&gt;action=&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;&quot;action3&quot;&lt;/span&gt;&lt;span class=&quot;nt&quot;&gt;&amp;gt;&lt;/span&gt;
            &lt;span class=&quot;nt&quot;&gt;&amp;lt;expCondition&lt;/span&gt; &lt;span class=&quot;na&quot;&gt;expression=&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;'parameters.get(&quot;params&quot;) == 1'&lt;/span&gt;&lt;span class=&quot;nt&quot;&gt;/&amp;gt;&lt;/span&gt;
        &lt;span class=&quot;nt&quot;&gt;&amp;lt;/step&amp;gt;&lt;/span&gt;
    &lt;span class=&quot;nt&quot;&gt;&amp;lt;/flow&amp;gt;&lt;/span&gt;

    &lt;span class=&quot;nt&quot;&gt;&amp;lt;flow&lt;/span&gt; &lt;span class=&quot;na&quot;&gt;name=&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;&quot;subflow&quot;&lt;/span&gt;&lt;span class=&quot;nt&quot;&gt;&amp;gt;&lt;/span&gt;
        &lt;span class=&quot;nt&quot;&gt;&amp;lt;step&lt;/span&gt; &lt;span class=&quot;na&quot;&gt;name=&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;&quot;sub_step1&quot;&lt;/span&gt; &lt;span class=&quot;na&quot;&gt;action=&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;&quot;action1&quot;&lt;/span&gt; &lt;span class=&quot;na&quot;&gt;asyn=&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;&quot;true&quot;&lt;/span&gt;&lt;span class=&quot;nt&quot;&gt;/&amp;gt;&lt;/span&gt;
        &lt;span class=&quot;nt&quot;&gt;&amp;lt;step&lt;/span&gt; &lt;span class=&quot;na&quot;&gt;name=&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;&quot;sub_step2&quot;&lt;/span&gt; &lt;span class=&quot;na&quot;&gt;action=&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;&quot;action2&quot;&lt;/span&gt;&lt;span class=&quot;nt&quot;&gt;/&amp;gt;&lt;/span&gt;
    &lt;span class=&quot;nt&quot;&gt;&amp;lt;/flow&amp;gt;&lt;/span&gt;
&lt;span class=&quot;nt&quot;&gt;&amp;lt;/flows&amp;gt;&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;
&lt;/div&gt;

&lt;h2 id=&quot;heading-4流程注入&quot;&gt;4.流程注入&lt;/h2&gt;

&lt;p&gt;配置文件需要放在classpath下，案例中的配置文件就是在classpath下的flow.xml文件&lt;/p&gt;

&lt;div class=&quot;highlighter-rouge&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;&amp;lt;bean id=&quot;flowManager&quot; class=&quot;org.cuner.flowframework.core.manager.FlowManager&quot;&amp;gt;
    &amp;lt;property name=&quot;flowFiles&quot;&amp;gt;
        &amp;lt;list&amp;gt;
            &amp;lt;value&amp;gt;flow.xml&amp;lt;/value&amp;gt;
        &amp;lt;/list&amp;gt;
    &amp;lt;/property&amp;gt;
&amp;lt;/bean&amp;gt;
&lt;/code&gt;&lt;/pre&gt;
&lt;/div&gt;

&lt;h2 id=&quot;heading-5执行&quot;&gt;5.执行&lt;/h2&gt;

&lt;div class=&quot;highlighter-rouge&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;Result result = flowManager.execute(&quot;mainFlow&quot;, data);
&lt;/code&gt;&lt;/pre&gt;
&lt;/div&gt;
&lt;p&gt;由于各个步骤可异步执行，在主流程的执行中加入了闭锁，只有当所有步骤（包括异步的）执行完成，execute方法才能正确返回。&lt;/p&gt;

&lt;h2 id=&quot;heading-6查看日志&quot;&gt;6.查看日志&lt;/h2&gt;
&lt;p&gt;可查看流程执行的完整堆栈，可以在logback.xml中如下配置&lt;/p&gt;
&lt;div class=&quot;highlighter-rouge&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;&amp;lt;logger name=&quot;flow-record&quot; level=&quot;info&quot; additivity=&quot;false&quot;&amp;gt;
    &amp;lt;appender-ref ref=&quot;FLOW_RECORD&quot;/&amp;gt;
&amp;lt;/logger&amp;gt;
&lt;/code&gt;&lt;/pre&gt;
&lt;/div&gt;

&lt;p&gt;上述案例执行后日志如下&lt;/p&gt;
&lt;div class=&quot;highlighter-rouge&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;21:03:23.431 [main] INFO  flow-record - 2018-08-04 21:03:23,415
[flow:mainFlow | start:2018-08-04 21:03:23,353 | end:2018-08-04 21:03:23,380 | cost:27]
|----[step:step1 | start:2018-08-04 21:03:23,354 | end:2018-08-04 21:03:23,355 | cost:1]
|----(step:step2 | start:2018-08-04 21:03:23,358 | end:2018-08-04 21:03:23,359 | cost:1) (asynchronously)
|----[step:step3 | start:2018-08-04 21:03:23,359 | end:2018-08-04 21:03:23,360 | cost:1]
        |----[sub_flow:subflow | start:2018-08-04 21:03:23,359 | end:2018-08-04 21:03:23,360 | cost:1]
                |----(step:sub_step1 | start:2018-08-04 21:03:23,360 | end:2018-08-04 21:03:23,360 | cost:0) (asynchronously)
                |----[step:sub_step2 | start:2018-08-04 21:03:23,360 | end:2018-08-04 21:03:23,360 | cost:0]
|----(step:step4 | start:2018-08-04 21:03:23,361 | end:2018-08-04 21:03:23,361 | cost:0) (asynchronously)
        |----[sub_flow:subflow | start:2018-08-04 21:03:23,361 | end:2018-08-04 21:03:23,361 | cost:0]
                |----[step:sub_step2 | start:2018-08-04 21:03:23,361 | end:2018-08-04 21:03:23,361 | cost:0]
                |----(step:sub_step1 | start:2018-08-04 21:03:23,361 | end:2018-08-04 21:03:23,361 | cost:0) (asynchronously)
|----[step:step5 | start:2018-08-04 21:03:23,378 | end:2018-08-04 21:03:23,380 | cost:2]
|----[step:step6 | start:2018-08-04 21:03:23,380 | end:2018-08-04 21:03:23,380 | cost:0]
|----[step:step7 | start:2018-08-04 21:03:23,380 | end:2018-08-04 21:03:23,380 | cost:0]
|----[step:step8 | start:2018-08-04 21:03:23,380 | end:2018-08-04 21:03:23,380 | cost:0]
|----[step:step9 | start:2018-08-04 21:03:23,380 | end:2018-08-04 21:03:23,380 | cost:0]
|----[step:step10 | start:2018-08-04 21:03:23,380 | end:2018-08-04 21:03:23,380 | cost:0]
&lt;/code&gt;&lt;/pre&gt;
&lt;/div&gt;

&lt;h1 id=&quot;heading-源码&quot;&gt;源码&lt;/h1&gt;

&lt;p&gt;最后，附上代码:https://github.com/Cuner/flow-framework&lt;/p&gt;</content><author><name>{&quot;name&quot;=&gt;nil, &quot;job_title&quot;=&gt;nil, &quot;location&quot;=&gt;nil, &quot;email&quot;=&gt;nil, &quot;social_links&quot;=&gt;[{&quot;name&quot;=&gt;&quot;facebook&quot;, &quot;url&quot;=&gt;nil}, {&quot;name&quot;=&gt;&quot;github&quot;, &quot;url&quot;=&gt;&quot;https://github.com/Cuner&quot;}, {&quot;name&quot;=&gt;&quot;instagram&quot;, &quot;url&quot;=&gt;nil}, {&quot;name&quot;=&gt;&quot;linkedin&quot;, &quot;url&quot;=&gt;nil}, {&quot;name&quot;=&gt;&quot;stackoverflow&quot;, &quot;url&quot;=&gt;nil}, {&quot;name&quot;=&gt;&quot;twitter&quot;, &quot;url&quot;=&gt;nil}, {&quot;name&quot;=&gt;&quot;vk&quot;, &quot;url&quot;=&gt;nil}]}</name></author><category term="flow" /><summary type="html">介绍 通用的流程编排框架，将整个流程以xml配置文件的形式管理起来：定义流程、管理上下文、控制流程的流转（按条件或者顺序），各个流程节点的执行（同步或者异步）。同时对每个流程节点进行监控以及统计，完成对流程的整体把控。</summary></entry><entry><title type="html">基于spring的groovy动态加载</title><link href="http://localhost:4000/blog/2018/06/26/groovy-loader/" rel="alternate" type="text/html" title="基于spring的groovy动态加载" /><published>2018-06-26T00:00:00+08:00</published><updated>2018-06-26T00:00:00+08:00</updated><id>http://localhost:4000/blog/2018/06/26/groovy-loader</id><content type="html" xml:base="http://localhost:4000/blog/2018/06/26/groovy-loader/">&lt;h1 id=&quot;heading-groovy-loader背景&quot;&gt;groovy loader背景&lt;/h1&gt;
&lt;p&gt;由于groovy动态语言的特性，使用方式与java一致，同时又特别适合与Spring的动态语言支持一起使用，所以基于java的groovy脚本的动态加载的使用场景还是比较多的&lt;/p&gt;

&lt;h1 id=&quot;heading-简介&quot;&gt;简介&lt;/h1&gt;
&lt;p&gt;动态加载指定目录下的groovy脚本，并将其注册为groovy bean，放置于ApplicationContext容器中，并使用命名空间进行分类区分(一个namespace对应于一个ApplicationContext)。同时能够动态感知到groovy脚本的新增、修改以及删除事件，并自动重新加载。&lt;/p&gt;

&lt;h1 id=&quot;heading-原理&quot;&gt;原理&lt;/h1&gt;
&lt;ul&gt;
  &lt;li&gt;使用spring配置文件来管理注册groovy bean：每一个spring配置文件作为一个ApplicationContext，管理一个namespace下的groovy bean&lt;/li&gt;
  &lt;li&gt;spring配置文件使用标签&lt;code class=&quot;highlighter-rouge&quot;&gt;&amp;lt;lang:groovy&amp;gt;&lt;/code&gt;，通过指定script-source来加载指定路径下的groovy脚本，通过refresh-check-delay属性来定时动态加载每个groovy bean&lt;/li&gt;
  &lt;li&gt;通过扫描监听指定路径下spring配置文件的变更，来接受groovy脚本的新增、删除事件&lt;/li&gt;
&lt;/ul&gt;

&lt;h3 id=&quot;heading-监听器listener&quot;&gt;监听器listener&lt;/h3&gt;
&lt;p&gt;由于我们需要动态获取groovy脚本的变更，包含更新、新增、删除。接收到groovy脚本变更后需要触发用户自定义事件，所以我们先提供一个待用户实现的监听器接口，用于接受groovy变更事件，并执行相应代码&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;GroovyRefreshedEvent&lt;/li&gt;
&lt;/ul&gt;

&lt;div class=&quot;highlighter-rouge&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;public class GroovyRefreshedEvent {

    private ApplicationContext ancestorContext;

    private Map&amp;lt;String, FileSystemXmlApplicationContext&amp;gt; namespacedContextMap;

    public GroovyRefreshedEvent(ApplicationContext ancestorContext, Map&amp;lt;String, FileSystemXmlApplicationContext&amp;gt; contextMap) {
        this.ancestorContext = ancestorContext;
        this.namespacedContextMap = contextMap;
    }
    ...
}
&lt;/code&gt;&lt;/pre&gt;
&lt;/div&gt;

&lt;p&gt;上述提到过，指定目录下的groovy脚本会被注册为groovy bean，并使用Applocation容器进行管理，同时还引入了namespace的概念，每个namespace分别对应一个Application容器，允许namespace不同但是类名相关的groovy bean存在。于是监听器的Event对象被设计成包含一个父容器以及namespace为key，对应Applocation容易为value的Map。&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;GroovyRefreshedListener
    &lt;div class=&quot;highlighter-rouge&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;public interface GroovyRefreshedListener {

  void groovyRefreshed(GroovyRefreshedEvent event);
}
&lt;/code&gt;&lt;/pre&gt;
    &lt;/div&gt;
  &lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;这个需要用户来实现&lt;/p&gt;

&lt;h3 id=&quot;heading-触发器trigger&quot;&gt;触发器trigger&lt;/h3&gt;
&lt;p&gt;由于需要动态去发现groovy脚本的变更，需要通过定时轮训使用触发器去判断groovy脚本是否完成了变更。上述提到过，框架通过&lt;code class=&quot;highlighter-rouge&quot;&gt;&amp;lt;lang:Groovy&amp;gt;&lt;/code&gt;来定时加载groovy脚本，通过扫描监听指定路径下spring配置文件的变更。通过这样的方式来接受groovy脚本的新增、删除事件。同样触发器也允许用户自定义，框架提供了一个默认的触发器&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;GroovyRefreshedListener
    &lt;div class=&quot;highlighter-rouge&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;public interface GroovyRefreshTrigger {

  boolean isTriggered(Map&amp;lt;String, Long&amp;gt; resourcesLastModifiedMap, String groovyResourcesDir);
}
&lt;/code&gt;&lt;/pre&gt;
    &lt;/div&gt;
  &lt;/li&gt;
  &lt;li&gt;ResourceModifiedTrigger
    &lt;div class=&quot;highlighter-rouge&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;public class ResourceModifiedTrigger implements GroovyRefreshTrigger {
  public boolean isTriggered(Map&amp;lt;String, Long&amp;gt; resourcesLastModifiedMap, String groovyResourcesDir) {
      if (StringUtils.isBlank(groovyResourcesDir)) {
          groovyResourcesDir = this.getClass().getClassLoader().getResource(&quot;&quot;).getPath() + &quot;/spring/groovy&quot;;
      }
      File groovyFileDir = new File(groovyResourcesDir);
      List&amp;lt;File&amp;gt; groovyFileList = NamespacedGroovyLoader.getResourceListFromDir(groovyFileDir);
      for (File file : groovyFileList) {
          //新增
          if (!resourcesLastModifiedMap.containsKey(file.getName())) {
              return true;
          } else {
              //修改
              if (resourcesLastModifiedMap.get(file.getName()) != file.lastModified()) {
                  return true;
              }
          }
      }

      //删除
      if (resourcesLastModifiedMap.size() != groovyFileList.size()) {
          return true;
      }
      return false;
  }
}
&lt;/code&gt;&lt;/pre&gt;
    &lt;/div&gt;
    &lt;p&gt;默认的触发器就是通过spring配置文件上一次修改的时间，去判断文件是否被修改&lt;/p&gt;
  &lt;/li&gt;
&lt;/ul&gt;

&lt;h3 id=&quot;heading-groovy-loader&quot;&gt;groovy loader&lt;/h3&gt;
&lt;p&gt;初始化时会将指定目录下的groovy脚本动态加载成bean，并根据namespace注册到不同的Application容器中。注：以spring配置文件的名称作为namespace&lt;/p&gt;
&lt;div class=&quot;highlighter-rouge&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;private void initLoadResources() {
    if (MapUtils.isNotEmpty(this.namespacedContext)) {
        toDestoryContext = new ArrayList&amp;lt;FileSystemXmlApplicationContext&amp;gt;(this.namespacedContext.values());
    }
    this.namespacedContext = new HashMap&amp;lt;String, FileSystemXmlApplicationContext&amp;gt;();
    this.resourcesLastModifiedMap = new ConcurrentHashMap&amp;lt;String, Long&amp;gt;();
    //定位资源文件路径
    if (StringUtils.isBlank(groovyResourcesDir)) {
        groovyResourcesDir = this.getClass().getClassLoader().getResource(&quot;&quot;).getPath() + &quot;/spring/groovy&quot;;
    }
    File groovyFileDir = new File(groovyResourcesDir);
    List&amp;lt;File&amp;gt; groovyFileList = getResourceListFromDir(groovyFileDir);//获取指定目录下所有groovy脚本文件
    for (File file : groovyFileList) {
        FileSystemXmlApplicationContext context = new FileSystemXmlApplicationContext(new String[] {file.toURI().toString()}, true, parentContext);
        this.namespacedContext.put(file.getName().replace(&quot;xml&quot;, &quot;&quot;), context);
        this.resourcesLastModifiedMap.put(file.getName(), file.lastModified());
    }

    //触发监听器事件
    listener.groovyRefreshed(new GroovyRefreshedEvent(parentContext, this.namespacedContext));

    if (CollectionUtils.isNotEmpty(toDestoryContext)) {
        for (FileSystemXmlApplicationContext fileSystemXmlApplicationContext : toDestoryContext) {
            fileSystemXmlApplicationContext.close();
        }
    }
}
&lt;/code&gt;&lt;/pre&gt;
&lt;/div&gt;

&lt;h3 id=&quot;heading-spring配置文件&quot;&gt;spring配置文件&lt;/h3&gt;
&lt;div class=&quot;highlighter-rouge&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;&lt;span class=&quot;cp&quot;&gt;&amp;lt;?xml version=&quot;1.0&quot; encoding=&quot;UTF-8&quot;?&amp;gt;&lt;/span&gt;
&lt;span class=&quot;nt&quot;&gt;&amp;lt;beans&lt;/span&gt; &lt;span class=&quot;na&quot;&gt;xmlns=&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;&quot;http://www.springframework.org/schema/beans&quot;&lt;/span&gt;
       &lt;span class=&quot;na&quot;&gt;xmlns:context=&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;&quot;http://www.springframework.org/schema/context&quot;&lt;/span&gt;
       &lt;span class=&quot;na&quot;&gt;xmlns:lang=&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;&quot;http://www.springframework.org/schema/lang&quot;&lt;/span&gt; &lt;span class=&quot;na&quot;&gt;xmlns:xsi=&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;&quot;http://www.w3.org/2001/XMLSchema-instance&quot;&lt;/span&gt;
       &lt;span class=&quot;na&quot;&gt;xsi:schemaLocation=&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;&quot;http://www.springframework.org/schema/beans&lt;/span&gt; &lt;span class=&quot;err&quot;&gt;http://www.springframework.org/schema/beans/spring-beans.xsd&lt;/span&gt;
    &lt;span class=&quot;err&quot;&gt;http://www.springframework.org/schema/context&lt;/span&gt; &lt;span class=&quot;err&quot;&gt;http://www.springframework.org/schema/context/spring-context.xsd&lt;/span&gt;
    &lt;span class=&quot;err&quot;&gt;http://www.springframework.org/schema/lang&lt;/span&gt; &lt;span class=&quot;err&quot;&gt;http://www.springframework.org/schema/lang/spring-lang.xsd&lt;/span&gt; &lt;span class=&quot;err&quot;&gt;&quot;&lt;/span&gt;&lt;span class=&quot;nt&quot;&gt;&amp;gt;&lt;/span&gt;

    &lt;span class=&quot;nt&quot;&gt;&amp;lt;context:annotation-config&lt;/span&gt; &lt;span class=&quot;nt&quot;&gt;/&amp;gt;&lt;/span&gt;

    &lt;span class=&quot;nt&quot;&gt;&amp;lt;lang:groovy&lt;/span&gt; &lt;span class=&quot;na&quot;&gt;id=&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;&quot;test&quot;&lt;/span&gt; &lt;span class=&quot;na&quot;&gt;refresh-check-delay=&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;&quot;2000&quot;&lt;/span&gt; &lt;span class=&quot;na&quot;&gt;proxy-target-class=&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;&quot;true&quot;&lt;/span&gt;
                 &lt;span class=&quot;na&quot;&gt;script-source=&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;&quot;classpath:groovy/one/Test.groovy&quot;&lt;/span&gt; &lt;span class=&quot;nt&quot;&gt;/&amp;gt;&lt;/span&gt;

&lt;span class=&quot;nt&quot;&gt;&amp;lt;/beans&amp;gt;&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;
&lt;/div&gt;

&lt;h1 id=&quot;heading-使用&quot;&gt;使用&lt;/h1&gt;
&lt;div class=&quot;highlighter-rouge&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;&amp;lt;bean id=&quot;listener&quot; class=&quot;org.cuner.groovy.loader.test.TestListener&quot;/&amp;gt;&amp;lt;!--需要实现org.cuner.groovy.loader.listener.GroovyRefreshedListener --&amp;gt;
&amp;lt;bean id=&quot;groovyLoader&quot; class=&quot;org.cuner.groovy.loader.NamespacedGroovyLoader&quot;&amp;gt;
    &amp;lt;property name=&quot;groovyResourcesDir&quot; value=&quot;&quot;/&amp;gt;&amp;lt;!--指定spring groovy配置文件目录，若不设置或者为空则默认为classpath下/spring/groovy目录--&amp;gt;
    &amp;lt;property name=&quot;listener&quot; ref=&quot;listener&quot;/&amp;gt;
    &amp;lt;property name=&quot;trigger&quot; ref=&quot;trigger&quot;/&amp;gt;
&amp;lt;/bean&amp;gt;
&lt;/code&gt;&lt;/pre&gt;
&lt;/div&gt;

&lt;h1 id=&quot;heading-源码demo&quot;&gt;源码&amp;amp;Demo&lt;/h1&gt;
&lt;p&gt;代码托管在Github上，并附有使用demo，欢迎下载运行: https://github.com/Cuner/groovy-loader&lt;/p&gt;

&lt;h1 id=&quot;heading-版本升级-groovy-loader-v2&quot;&gt;版本升级 groovy-loader-v2&lt;/h1&gt;
&lt;p&gt;v1版本存在的缺陷在于：由于使用了&lt;code class=&quot;highlighter-rouge&quot;&gt;&amp;lt;lang:groovy&amp;gt;&lt;/code&gt;标签，spring定时去重加载groovy bean，即使这个bean没有被修改，由此会产生一些性能消耗问题。为了解决这点，v2实现了groovy脚本的加载以及groovy bean的注入。同时由定时扫描spring配置改为扫描目录下的所有groovy脚本来实现触发器。&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;GroovyScriptsModifiedTrigger
    &lt;div class=&quot;highlighter-rouge&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;public boolean isTriggered(Map&amp;lt;String, Long&amp;gt; lastScriptsModified, String baseDir) {
  if (StringUtils.isBlank(baseDir)) {
      baseDir = this.getClass().getClassLoader().getResource(&quot;&quot;).getPath() + &quot;/groovy&quot;;
  }

  List&amp;lt;File&amp;gt; fileList = getFileList(new File(baseDir));
  for (File file : fileList) {
      if (lastScriptsModified.get(file.getPath()) == null) {
          return true;
      }
      if (file.lastModified() != lastScriptsModified.get(file.getPath())) {
          return true;
      }
  }

  if (fileList.size() != lastScriptsModified.size()) {
      return true;
  }

  return false;
}
&lt;/code&gt;&lt;/pre&gt;
    &lt;/div&gt;
    &lt;p&gt;具体实现基本一致，区别在于外部传参baseDir由spring配置文件路径改为groovy脚本根目录路径。接下来我们看看是如何实现groovy脚本的加载以及groovy bean的注入。&lt;/p&gt;
  &lt;/li&gt;
  &lt;li&gt;NamespacedGroovyLoader&lt;/li&gt;
&lt;/ul&gt;

&lt;div class=&quot;highlighter-rouge&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;/**
 * 递归查找并加载namespace下的所有groovy文件
 * @param file
 * @param namespace
 */
private void scanGroovyFiles(File file, String namespace) throws Exception {
    if (!file.exists()) {
        return;
    }

    if (file.isFile() &amp;amp;&amp;amp; file.getName().endsWith(&quot;.groovy&quot;)) {
        ApplicationContext context = getOrCreateContext(namespace);
        DefaultListableBeanFactory beanFactory = (DefaultListableBeanFactory) context.getAutowireCapableBeanFactory();

        String scriptLocation = file.toURI().toString();
        if (scriptNotExists(context, scriptLocation)) {
            throw new IllegalArgumentException(&quot;script not exists : &quot; + scriptLocation);
        }
        scriptLastModifiedMap.put(file.getPath(), file.lastModified());

        String className = StringUtils.removeEnd(scriptLocation.substring(scriptLocation.indexOf(baseDir) + baseDir.length() + 1).replace(&quot;/&quot;, &quot;.&quot;), &quot;.groovy&quot;);
        // 只有GroovyBean声明的类才实例化
        DSLScriptSource scriptSource = new DSLScriptSource(new ResourceScriptSource(context.getResource(scriptLocation)), className);

        Class scriptClass = groovyClassLoader.parseClass(scriptSource.getScriptAsString(), scriptSource.suggestedClassName());

        // Tell Groovy we don't need any meta
        // information about these classes
        GroovySystem.getMetaClassRegistry().removeMetaClass(scriptClass);
        groovyClassLoader.clearCache();

        // Create script factory bean definition.
        GroovyScriptFactory groovyScriptFactory = new GroovyScriptFactory(scriptLocation);
        groovyScriptFactory.setBeanFactory(beanFactory);
        groovyScriptFactory.setBeanClassLoader(urlClassLoader);
        Object bean = groovyScriptFactory.getScriptedObject(scriptSource);
        if (bean == null) {
            //只有静态方法的groovy脚本(没有类声明)
            return;
        }

        // Tell Groovy we don't need any meta
        // information about these classes
        GroovySystem.getMetaClassRegistry().removeMetaClass(bean.getClass());
        groovyScriptFactory.getGroovyClassLoader().clearCache();

        String beanName = StringUtils.removeEnd(file.getName(), &quot;.groovy&quot;).toLowerCase();
        if (beanFactory.containsBean(beanName)) {
            beanFactory.destroySingleton(beanName); //移除单例bean
            removeInjectCache(context, bean); //移除注入缓存 否则Caused by: java.lang.IllegalArgumentException: object is not an instance of declaring class
        }
        beanFactory.registerSingleton(beanName, bean); //注册单例bean
        beanFactory.autowireBean(bean); //自动注入

    } else if (file.isDirectory()) {
        File[] subFiles = file.listFiles();
        for (File subFile : subFiles) {
            scanGroovyFiles(subFile, namespace);
        }
    }
}
&lt;/code&gt;&lt;/pre&gt;
&lt;/div&gt;

&lt;p&gt;groovy文件夹下第一级文件夹名称拼接namespacePrefix作为namespace，每个namespace分配一个ApplicationContext容器，每个namespace对应的bean都由各自的beanfactory加载注入，避免同名类加载导致的错误。同时groovy脚本更新后产生新的groovy bean之后，还需要移除之前的groovy bean，值得额外注意的是需要移除注入缓存，否则会报错：Caused by: java.lang.IllegalArgumentException: object is not an instance of declaring class
注意：由于我们不需要groovy的metaclass信息，这里对metaClass进行清除来进行优化&lt;/p&gt;

&lt;p&gt;最后，附上代码:https://github.com/Cuner/groovy-loader-v2)&lt;/p&gt;</content><author><name>{&quot;name&quot;=&gt;nil, &quot;job_title&quot;=&gt;nil, &quot;location&quot;=&gt;nil, &quot;email&quot;=&gt;nil, &quot;social_links&quot;=&gt;[{&quot;name&quot;=&gt;&quot;facebook&quot;, &quot;url&quot;=&gt;nil}, {&quot;name&quot;=&gt;&quot;github&quot;, &quot;url&quot;=&gt;&quot;https://github.com/Cuner&quot;}, {&quot;name&quot;=&gt;&quot;instagram&quot;, &quot;url&quot;=&gt;nil}, {&quot;name&quot;=&gt;&quot;linkedin&quot;, &quot;url&quot;=&gt;nil}, {&quot;name&quot;=&gt;&quot;stackoverflow&quot;, &quot;url&quot;=&gt;nil}, {&quot;name&quot;=&gt;&quot;twitter&quot;, &quot;url&quot;=&gt;nil}, {&quot;name&quot;=&gt;&quot;vk&quot;, &quot;url&quot;=&gt;nil}]}</name></author><category term="groovy" /><summary type="html">groovy loader背景 由于groovy动态语言的特性，使用方式与java一致，同时又特别适合与Spring的动态语言支持一起使用，所以基于java的groovy脚本的动态加载的使用场景还是比较多的</summary></entry><entry><title type="html">基于redis的分布式延时队列</title><link href="http://localhost:4000/blog/2018/05/30/delay-queue/" rel="alternate" type="text/html" title="基于redis的分布式延时队列" /><published>2018-05-30T00:00:00+08:00</published><updated>2018-05-30T00:00:00+08:00</updated><id>http://localhost:4000/blog/2018/05/30/delay-queue</id><content type="html" xml:base="http://localhost:4000/blog/2018/05/30/delay-queue/">&lt;p&gt;延时队列的使用场景非常多，目前集中式场景可以使用JDK自带的delayQueue，本文使用redis队列来实现两种分布式的延时队列，并进行了对比分析&lt;/p&gt;

&lt;h2 id=&quot;heading-1封装统一的队列消息结构&quot;&gt;1.封装统一的队列消息结构&lt;/h2&gt;
&lt;div class=&quot;highlighter-rouge&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;public class DelayMessage {

    /**
     * 正执行消息的token
     */
    private String tmpKey;

    /**
     * 消息内容
     */
    private String message;

    /**
     * 延迟时间 纳秒
     */
    private long delay;

    /**
     * 到期时间 纳秒
     */
    private long expire;

    /**
     * 创建时间 纳秒
     */
    private long registerTime;
    
    ...
}
&lt;/code&gt;&lt;/pre&gt;
&lt;/div&gt;

&lt;h2 id=&quot;heading-2-同步延时队列&quot;&gt;2. 同步延时队列&lt;/h2&gt;
&lt;p&gt;原理：通过LRANG获取队列头部元素，从而获得到期时间，当数据达到到期时间后，通过LPOP取出数据。并发情况下会加分布式锁，同一时刻只能有一个线程访问队列并阻塞等待数据准备完成(达到延时时间)。当线程获取到可以返回的数据后，才能释放锁。&lt;/p&gt;
&lt;div class=&quot;highlighter-rouge&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;public DelayMessage pop() {
    while (true) {
        Long waitTime = null;
        Jedis jedis = jedisPool.getResource();
        try {
            if (this.syn) {
                lock.lock(this.queueName);
            }
            //获取头部的数据
            List&amp;lt;String&amp;gt; dataList = jedis.lrange(this.queueName, 0L, 0L);
            if (CollectionUtils.isNotEmpty(dataList)) {
                String data = dataList.get(0);
                DelayMessage message = gson.fromJson(data, DelayMessage.class);
                if (message != null) {
                    long now = System.nanoTime();
                    if (message.getExpire() &amp;gt; now) {
                        //没有到期
                        waitTime = message.getExpire() - now;
                    } else {
                        jedis.lpop(this.queueName);
                        return message;
                    }
                }
            }

            if (waitTime != null) {
                try {
                    Thread.sleep(waitTime / 1000);
                } catch (InterruptedException e) {
                    //do nothing
                }
            }

        } finally {
            if (this.syn) {
                lock.unlock(this.queueName);
            }
            jedis.close();
        }
    }
}
&lt;/code&gt;&lt;/pre&gt;
&lt;/div&gt;
&lt;ul&gt;
  &lt;li&gt;基于redis，&lt;strong&gt;并发情况下会加分布式锁&lt;/strong&gt;，单线程场景（syn=false）性能较好， 并发场景性能较差&lt;/li&gt;
  &lt;li&gt;&lt;strong&gt;若在并发场景下，设置syn=false，会导致消息重复消费、消息丢失的情况&lt;/strong&gt;&lt;/li&gt;
  &lt;li&gt;支持delay时间的动态调整&lt;/li&gt;
&lt;/ul&gt;

&lt;h2 id=&quot;heading-3-并发延时队列&quot;&gt;3. 并发延时队列&lt;/h2&gt;
&lt;p&gt;原理：直接通过LPOP取出数据，当数据达到到期时间后立即返回，若未达到到期时间，线程sleep至到期时间后将数据返回。这样就允许队列在无分布式锁的情况下并行消费。
存在的问题：从数据LPOP移除队列到数据返回之间有一段时间间隔，如果系统在这段时间出现异常，比如宕机、重启等等，就会出现数据丢失的情况。为了避免此种情况，引入了ack的方式，在通过LPOP去除数据后，随机将数据存储到另外一个临时redis set中，在用户接受到消息并处理完成后手动执行ack方法后才将数据从临时set中移除。而在机器重启时，再将改临时set里面的数据重新put到延时队列中。&lt;/p&gt;
&lt;div class=&quot;highlighter-rouge&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;public DelayMessage pop() {
    while (true) {
        Long waitTime;
        Jedis jedis = jedisPool.getResource();
        try {
            // 取队列头部的消息
            String result = jedis.lpop(queueName);
            // 队列非空
            if (result != null) {
                //暂存此条消息，放入执行集合
                String tmpKey = null;
                if (!autoAck) {
                    tmpKey = this.setExeMsg(result);//解决宕机数据丢失
                }
                DelayMessage delayMessage = gson.fromJson(result, DelayMessage.class);
                if (delayMessage != null) {
                    if (delayMessage.getExpire() &amp;gt; System.nanoTime()) {
                        // 消息未到可执行状态,休眠等待
                        waitTime = delayMessage.getExpire() - System.nanoTime();
                        try {
                            Thread.sleep(waitTime);
                        } catch (InterruptedException e) {
                            // do nothing
                        }
                    }
                    delayMessage.setTmpKey(tmpKey);
                    return delayMessage;
                }
            }
        } finally {
            jedis.close();
        }
    }
}
&lt;/code&gt;&lt;/pre&gt;
&lt;/div&gt;

&lt;ul&gt;
  &lt;li&gt;基于redis，支持在&lt;strong&gt;无分布式锁&lt;/strong&gt;的情况下进行并发消费&lt;/li&gt;
  &lt;li&gt;autoAck为true时，吞吐量性能极好，autoAck为false，吞吐量会稍有下降&lt;/li&gt;
  &lt;li&gt;支持delay时间的动态调整&lt;/li&gt;
  &lt;li&gt;&lt;strong&gt;autoAck为false时，必须在处理完消息后手动调用ack方法，否则会导致应用重启后重新开始消费&lt;/strong&gt;&lt;/li&gt;
&lt;/ul&gt;

&lt;h2 id=&quot;heading-4性能对比&quot;&gt;4.性能对比&lt;/h2&gt;

&lt;ul&gt;
  &lt;li&gt;RedisConcurrentDelayQueue和RedisSynDelayQueue的简单对比，数据是线下单机环境测试数据&lt;/li&gt;
&lt;/ul&gt;

&lt;table&gt;
  &lt;thead&gt;
    &lt;tr&gt;
      &lt;th style=&quot;text-align: center&quot;&gt;队列种类&lt;/th&gt;
      &lt;th style=&quot;text-align: center&quot;&gt;消费线程数&lt;/th&gt;
      &lt;th style=&quot;text-align: center&quot;&gt;syn&lt;/th&gt;
      &lt;th style=&quot;text-align: center&quot;&gt;autoAck&lt;/th&gt;
      &lt;th style=&quot;text-align: center&quot;&gt;耗时&lt;/th&gt;
      &lt;th style=&quot;text-align: center&quot;&gt;消息丢失&lt;/th&gt;
      &lt;th style=&quot;text-align: center&quot;&gt;重复消费&lt;/th&gt;
    &lt;/tr&gt;
  &lt;/thead&gt;
  &lt;tbody&gt;
    &lt;tr&gt;
      &lt;td style=&quot;text-align: center&quot;&gt;RedisConcurrentDelayQueue&lt;/td&gt;
      &lt;td style=&quot;text-align: center&quot;&gt;1&lt;/td&gt;
      &lt;td style=&quot;text-align: center&quot;&gt;-&lt;/td&gt;
      &lt;td style=&quot;text-align: center&quot;&gt;false&lt;/td&gt;
      &lt;td style=&quot;text-align: center&quot;&gt;53936ms&lt;/td&gt;
      &lt;td style=&quot;text-align: center&quot;&gt;无&lt;/td&gt;
      &lt;td style=&quot;text-align: center&quot;&gt;无&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td style=&quot;text-align: center&quot;&gt;RedisConcurrentDelayQueue&lt;/td&gt;
      &lt;td style=&quot;text-align: center&quot;&gt;1&lt;/td&gt;
      &lt;td style=&quot;text-align: center&quot;&gt;-&lt;/td&gt;
      &lt;td style=&quot;text-align: center&quot;&gt;true&lt;/td&gt;
      &lt;td style=&quot;text-align: center&quot;&gt;13130ms&lt;/td&gt;
      &lt;td style=&quot;text-align: center&quot;&gt;消费进程关闭，正在处理的消息会丢失&lt;/td&gt;
      &lt;td style=&quot;text-align: center&quot;&gt;无&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td style=&quot;text-align: center&quot;&gt;RedisSynDelayQueue&lt;/td&gt;
      &lt;td style=&quot;text-align: center&quot;&gt;1&lt;/td&gt;
      &lt;td style=&quot;text-align: center&quot;&gt;true&lt;/td&gt;
      &lt;td style=&quot;text-align: center&quot;&gt;-&lt;/td&gt;
      &lt;td style=&quot;text-align: center&quot;&gt;55420ms&lt;/td&gt;
      &lt;td style=&quot;text-align: center&quot;&gt;无&lt;/td&gt;
      &lt;td style=&quot;text-align: center&quot;&gt;无&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td style=&quot;text-align: center&quot;&gt;RedisSynDelayQueue&lt;/td&gt;
      &lt;td style=&quot;text-align: center&quot;&gt;1&lt;/td&gt;
      &lt;td style=&quot;text-align: center&quot;&gt;false&lt;/td&gt;
      &lt;td style=&quot;text-align: center&quot;&gt;-&lt;/td&gt;
      &lt;td style=&quot;text-align: center&quot;&gt;20012ms&lt;/td&gt;
      &lt;td style=&quot;text-align: center&quot;&gt;无&lt;/td&gt;
      &lt;td style=&quot;text-align: center&quot;&gt;无&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td style=&quot;text-align: center&quot;&gt;RedisConcurrentDelayQueue&lt;/td&gt;
      &lt;td style=&quot;text-align: center&quot;&gt;10&lt;/td&gt;
      &lt;td style=&quot;text-align: center&quot;&gt;-&lt;/td&gt;
      &lt;td style=&quot;text-align: center&quot;&gt;false&lt;/td&gt;
      &lt;td style=&quot;text-align: center&quot;&gt;7279ms&lt;/td&gt;
      &lt;td style=&quot;text-align: center&quot;&gt;无&lt;/td&gt;
      &lt;td style=&quot;text-align: center&quot;&gt;无&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td style=&quot;text-align: center&quot;&gt;RedisConcurrentDelayQueue&lt;/td&gt;
      &lt;td style=&quot;text-align: center&quot;&gt;10&lt;/td&gt;
      &lt;td style=&quot;text-align: center&quot;&gt;-&lt;/td&gt;
      &lt;td style=&quot;text-align: center&quot;&gt;true&lt;/td&gt;
      &lt;td style=&quot;text-align: center&quot;&gt;1181ms&lt;/td&gt;
      &lt;td style=&quot;text-align: center&quot;&gt;消费进程关闭，正在处理的消息会丢失&lt;/td&gt;
      &lt;td style=&quot;text-align: center&quot;&gt;无&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td style=&quot;text-align: center&quot;&gt;RedisSynDelayQueue&lt;/td&gt;
      &lt;td style=&quot;text-align: center&quot;&gt;10&lt;/td&gt;
      &lt;td style=&quot;text-align: center&quot;&gt;true&lt;/td&gt;
      &lt;td style=&quot;text-align: center&quot;&gt;-&lt;/td&gt;
      &lt;td style=&quot;text-align: center&quot;&gt;61532ms&lt;/td&gt;
      &lt;td style=&quot;text-align: center&quot;&gt;无&lt;/td&gt;
      &lt;td style=&quot;text-align: center&quot;&gt;无&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td style=&quot;text-align: center&quot;&gt;RedisSynDelayQueue&lt;/td&gt;
      &lt;td style=&quot;text-align: center&quot;&gt;10&lt;/td&gt;
      &lt;td style=&quot;text-align: center&quot;&gt;false&lt;/td&gt;
      &lt;td style=&quot;text-align: center&quot;&gt;-&lt;/td&gt;
      &lt;td style=&quot;text-align: center&quot;&gt;-&lt;/td&gt;
      &lt;td style=&quot;text-align: center&quot;&gt;大量消息丢失&lt;/td&gt;
      &lt;td style=&quot;text-align: center&quot;&gt;大量重复消费&lt;/td&gt;
    &lt;/tr&gt;
  &lt;/tbody&gt;
&lt;/table&gt;

&lt;ol&gt;
  &lt;li&gt;若能接受系统重启、关闭时的少量消息丢失，推荐RedisConcurrentDelayQueue，并设置autoAck为true：性能最好，且消费线程越多，消费速度（吞吐量）也会相对越好&lt;/li&gt;
  &lt;li&gt;若不能接受消息丢失，在单机、单线程消费的场景下，可以选择RedisConcurrentDelayQueue（autoAck设置为false）RedisSynDelayQueue（syn设置为false）；&lt;/li&gt;
  &lt;li&gt;若不能接受消息丢失，且需要在多线程、分布式场景下消费，推荐推荐RedisConcurrentDelayQueue（autoAck设置为false），消费线程越多，消费速度（吞吐量）也会相对越好；&lt;/li&gt;
  &lt;li&gt;RedisSynDelayQueue在并发消费的场景下性能较差，不推荐使用。&lt;/li&gt;
&lt;/ol&gt;

&lt;h2 id=&quot;heading-5项目代码&quot;&gt;5.项目代码&lt;/h2&gt;
&lt;p&gt;代码托管在Github上，并附有使用demo，欢迎下载运行: https://github.com/Cuner/delay-queue&lt;/p&gt;

&lt;h2 id=&quot;heading-6切换思路&quot;&gt;6.切换思路&lt;/h2&gt;
&lt;p&gt;当有延时任务或者延时消息产生时，暂时将延时任务/消息存放至某个容器里面(可以是数据记录的方式存储在db，也可以存储在redis zset中等等)，然后采用定时器不断去轮训容器里面的各个延时任务/消息，当扫描获取到达到过期时间的延时任务/消息后，将其推送到消息队列中以供消费，推送成功后再将其从容器里移除。
值得注意的是，同一个达到到期时间的延时任务/消息，可能会被连续的两次扫描命中（延时任务/消息从容器移除有延时），最后导致消息重复消费。&lt;/p&gt;

&lt;p&gt;参考：&lt;a href=&quot;https://tech.youzan.com/queuing_delay/&quot;&gt;有赞延迟队列设计&lt;/a&gt;&lt;/p&gt;</content><author><name>{&quot;name&quot;=&gt;nil, &quot;job_title&quot;=&gt;nil, &quot;location&quot;=&gt;nil, &quot;email&quot;=&gt;nil, &quot;social_links&quot;=&gt;[{&quot;name&quot;=&gt;&quot;facebook&quot;, &quot;url&quot;=&gt;nil}, {&quot;name&quot;=&gt;&quot;github&quot;, &quot;url&quot;=&gt;&quot;https://github.com/Cuner&quot;}, {&quot;name&quot;=&gt;&quot;instagram&quot;, &quot;url&quot;=&gt;nil}, {&quot;name&quot;=&gt;&quot;linkedin&quot;, &quot;url&quot;=&gt;nil}, {&quot;name&quot;=&gt;&quot;stackoverflow&quot;, &quot;url&quot;=&gt;nil}, {&quot;name&quot;=&gt;&quot;twitter&quot;, &quot;url&quot;=&gt;nil}, {&quot;name&quot;=&gt;&quot;vk&quot;, &quot;url&quot;=&gt;nil}]}</name></author><category term="queue" /><summary type="html">延时队列的使用场景非常多，目前集中式场景可以使用JDK自带的delayQueue，本文使用redis队列来实现两种分布式的延时队列，并进行了对比分析</summary></entry><entry><title type="html">SPI框架（一）</title><link href="http://localhost:4000/blog/2018/05/24/spi-framework/" rel="alternate" type="text/html" title="SPI框架（一）" /><published>2018-05-24T00:00:00+08:00</published><updated>2018-05-24T00:00:00+08:00</updated><id>http://localhost:4000/blog/2018/05/24/spi-framework</id><content type="html" xml:base="http://localhost:4000/blog/2018/05/24/spi-framework/">&lt;p&gt;SPI的全名为Service Provider Interface。根据Java的SPI规范，我们可以定义一个服务接口，具体的实现由对应的实现者去提供，即Service Provider（服务提供者）。然后在使用的时候只要根据SPI的规范去获取对应的服务提供者的服务实现即可。简单来说，SPI就是一种为接口寻找服务的机制，基于这种机制，本文提出一种基于动态代理的spi框架的实现方式。&lt;/p&gt;

&lt;h2 id=&quot;heading-1-基于统一的接口&quot;&gt;1 基于统一的接口&lt;/h2&gt;
&lt;p&gt;该SPI框架的核心思想是通过JDK动态代理（代理对象必须为某个接口的实现），为接口寻找满足条件的服务实现。基于上述要求，需要提供一个统一的接口。&lt;/p&gt;
&lt;div class=&quot;highlighter-rouge&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;public interface SpiBase&amp;lt;T, R&amp;gt; {

    /**
     * 是否执行当前实现的条件
     * @param query
     * @return
     */
    boolean condition(T query);

    /**
     * 具体操作
     * @param query
     * @return
     */
    List&amp;lt;R&amp;gt; invoke(T query);

    /**
     * spi执行时候的配置
     * @param query
     * @return
     */
    SpiConfig config(T query);
}
&lt;/code&gt;&lt;/pre&gt;
&lt;/div&gt;

&lt;p&gt;作为框架，需要尽可能的符合各类场景&lt;/p&gt;
&lt;ul&gt;
  &lt;li&gt;提供condition方法以及模板类T参数，让用户自定义符合接口实现的要求&lt;/li&gt;
  &lt;li&gt;提供统一的invoke方法来统一服务的某一类行为&lt;/li&gt;
  &lt;li&gt;提供spi执行的config，用来扩展寻求实现的策略&lt;/li&gt;
&lt;/ul&gt;

&lt;div class=&quot;highlighter-rouge&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;public class SpiConfig {

    /**
     * 是否互斥
     * false:满足执行条件的其他实现也一并调用
     * true:当前实现满足执行要求并执行成功后直接返回，忽略满足执行条件的其他实现
     */
    private boolean mutex;

    /**
     * 优先值
     * 该值越高，执行优先级越高
     */
    private int priority;

    /**
     * 名称 作为标识
     */
    private String name;
    
    ....
}
&lt;/code&gt;&lt;/pre&gt;
&lt;/div&gt;

&lt;ul&gt;
  &lt;li&gt;参数mutex，决定了某个接口，当有多个满足条件的服务实现时的执行策略，是只选择优先级最高的服务实现去执行，还是说按照优先级顺序多个服务实现顺序执行后将结果合并返回（这也是为什么invoke方法返回list的原因）。&lt;/li&gt;
  &lt;li&gt;参数priority，决定某个服务实现的执行优先级，优先级越高，越先执行&lt;/li&gt;
&lt;/ul&gt;

&lt;h2 id=&quot;heading-2-获取所有用户自定义的服务实现并实例化&quot;&gt;2 获取所有用户自定义的服务实现并实例化&lt;/h2&gt;

&lt;p&gt;2.1 提供注解@BizSpi&lt;/p&gt;
&lt;div class=&quot;highlighter-rouge&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;@Target({ElementType.TYPE})//目标作用于类
@Retention(RetentionPolicy.RUNTIME)// 注解在class字节码文件中存在，在运行时可以通过反射获取到
@Documented
@Service
public @interface BizSpi {
}
&lt;/code&gt;&lt;/pre&gt;
&lt;/div&gt;

&lt;p&gt;为了方便的找到用户提供的服务实现类，框架约束用户在其提供的服务实现类上加上注解@BizSpi，当然所有的服务实现类都需要实现统一的接口SpiBase，也可以实现某个继承SpiBase接口的自定义接口。&lt;/p&gt;

&lt;p&gt;2.2 实例化服务实现并保存至内存&lt;/p&gt;
&lt;div class=&quot;highlighter-rouge&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;public class SpiManager implements ApplicationListener&amp;lt;ContextRefreshedEvent&amp;gt; {

    private static Map&amp;lt;Class, List&amp;lt;SpiBase&amp;gt;&amp;gt; spiProviderMap = new ConcurrentHashMap&amp;lt;Class, List&amp;lt;SpiBase&amp;gt;&amp;gt;();

    private static volatile boolean isLoaded = false;

    public void onApplicationEvent(ContextRefreshedEvent contextRefreshedEvent) {
        if (!isLoaded) {
            Map&amp;lt;String, Object&amp;gt; spiInstanceMap = contextRefreshedEvent.getApplicationContext().getBeansWithAnnotation(BizSpi.class);

            for (Object spiInstance : spiInstanceMap.values()) {
                Class spiInterface = spiInstance.getClass().getInterfaces()[0];
                if (spiProviderMap.containsKey(spiInterface) &amp;amp;&amp;amp; spiProviderMap.get(spiInterface).size() &amp;gt; 0) {
                    spiProviderMap.get(spiInterface).add((SpiBase) spiInstance);
                } else {
                    List&amp;lt;SpiBase&amp;gt; spiProviderList = new ArrayList&amp;lt;SpiBase&amp;gt;();
                    spiProviderList.add((SpiBase) spiInstance);
                    spiProviderMap.put(spiInterface, spiProviderList);
                }
            }

            for (List&amp;lt;SpiBase&amp;gt; spiProviderList : spiProviderMap.values()) {
                Collections.sort(spiProviderList, new Comparator&amp;lt;SpiBase&amp;gt;() {
                    public int compare(SpiBase spiBase1, SpiBase spiBase2) {
                        return spiBase2.config(null).getPriority() - spiBase1.config(null).getPriority();
                    }
                });
            }
        }
        isLoaded = true;
    }

    public static List&amp;lt;SpiBase&amp;gt; getSpiProviderMap(Class spiInterface) {
        return spiProviderMap.get(spiInterface);
    }

}
&lt;/code&gt;&lt;/pre&gt;
&lt;/div&gt;

&lt;p&gt;这里通过约束的注解@BizSpi来拿到所有服务实现实例化后的对象，通过spiProviderMap来保存管理，其中spiProviderMap的key的集合是所有服务实现所实现的第一级接口（可以是SpiBase，也可以是继承自SpiBase的自定义接口），value则是key代表的接口所对应的所有服务实现实例化后的对象列表（可以看到列表通过SpiConfig中的priority值进行了重排序）。&lt;/p&gt;

&lt;h2 id=&quot;heading-3动态代理&quot;&gt;3.动态代理&lt;/h2&gt;
&lt;div class=&quot;highlighter-rouge&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;public class SpiProviderFactory&amp;lt;T&amp;gt; implements FactoryBean&amp;lt;T&amp;gt; {

    private Logger logger = LoggerFactory.getLogger(SpiProviderFactory.class);

    private Class&amp;lt;T&amp;gt; targetClass;

    public T getObject() throws Exception {
        InvocationHandler invocationHandler = new InvocationHandler() {
            public Object invoke(Object proxy, Method method, Object[] args) throws Throwable {
                List&amp;lt;SpiBase&amp;gt; spiList = SpiManager.getSpiProviderMap(targetClass);

                // 支持组合,所以必须返回list; 每一个功能点实现也必须返回list
                List combinationResult = new ArrayList();
                for (SpiBase spi : spiList) {
                    if (SpiBase.class.isInstance(spi)) {
                        if (args != null &amp;amp;&amp;amp; spi.condition(args[0])) {
                            SpiConfig spiConfig = spi.config(args[0]);
                            List result = (List) method.invoke(spi, args);
                            if (result != null) {
                                combinationResult.addAll(result);
                                if (spiConfig.isMutex()) {
                                    break;
                                }
                            }
                        }
                    }
                }
                return combinationResult;
            }
        };
        return (T) Proxy.newProxyInstance(Thread.currentThread().getContextClassLoader(),
                new Class[]{targetClass},
                invocationHandler);
    }
   ...
}
&lt;/code&gt;&lt;/pre&gt;
&lt;/div&gt;

&lt;p&gt;这里用到了工厂，这里需要传入参数targetClass，因为我们需要代理的接口可能是继承了SpiBase的自定义接口。通过服务实现类提供的condition方法可以从spiProviderMap中找到满足条件的服务，在通过SpiConfig的中参数决定服务执行的策略，最终将结果返回。&lt;/p&gt;

&lt;h2 id=&quot;heading-4使用步骤&quot;&gt;4.使用步骤&lt;/h2&gt;
&lt;p&gt;1.继承SpiBase得到自定义的SPI接口(可以添加自定义方法)
2.为SPI接口提供多个服务实现类(注意类需要加上注解@BizSpi)，condition方法决定了服务是否满足执行条件，config方法返回的SpiConfig对象决定了服务执行的策略
3.spring配置&lt;/p&gt;
&lt;div class=&quot;highlighter-rouge&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;    &amp;lt;!--扫描spi框架--&amp;gt;
    &amp;lt;context:component-scan base-package=&quot;org.cuner.spi.framework&quot;/&amp;gt;

    &amp;lt;!--还需要扫描到你自己的服务实现类--&amp;gt;
    
    &amp;lt;bean id=&quot;demoSpi&quot; class=&quot;org.cuner.spi.framework.core.SpiProviderFactory&quot;&amp;gt;
        &amp;lt;property name=&quot;targetClass&quot; value=&quot;org.cuner.spi.framework.demo.api.demoSpi&quot;/&amp;gt;
    &amp;lt;/bean&amp;gt;
&lt;/code&gt;&lt;/pre&gt;
&lt;/div&gt;
&lt;p&gt;4.spring注入后使用&lt;/p&gt;
&lt;div class=&quot;highlighter-rouge&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;    @Resource(name = &quot;demoSpi&quot;)
    private DemoSpi demoSpi;
&lt;/code&gt;&lt;/pre&gt;
&lt;/div&gt;

&lt;p&gt;5.demo
代码托管在Github上，并附有使用demo，欢迎下载运行: https://github.com/Cuner/spi-framework&lt;/p&gt;</content><author><name>{&quot;name&quot;=&gt;nil, &quot;job_title&quot;=&gt;nil, &quot;location&quot;=&gt;nil, &quot;email&quot;=&gt;nil, &quot;social_links&quot;=&gt;[{&quot;name&quot;=&gt;&quot;facebook&quot;, &quot;url&quot;=&gt;nil}, {&quot;name&quot;=&gt;&quot;github&quot;, &quot;url&quot;=&gt;&quot;https://github.com/Cuner&quot;}, {&quot;name&quot;=&gt;&quot;instagram&quot;, &quot;url&quot;=&gt;nil}, {&quot;name&quot;=&gt;&quot;linkedin&quot;, &quot;url&quot;=&gt;nil}, {&quot;name&quot;=&gt;&quot;stackoverflow&quot;, &quot;url&quot;=&gt;nil}, {&quot;name&quot;=&gt;&quot;twitter&quot;, &quot;url&quot;=&gt;nil}, {&quot;name&quot;=&gt;&quot;vk&quot;, &quot;url&quot;=&gt;nil}]}</name></author><category term="SPI" /><summary type="html">SPI的全名为Service Provider Interface。根据Java的SPI规范，我们可以定义一个服务接口，具体的实现由对应的实现者去提供，即Service Provider（服务提供者）。然后在使用的时候只要根据SPI的规范去获取对应的服务提供者的服务实现即可。简单来说，SPI就是一种为接口寻找服务的机制，基于这种机制，本文提出一种基于动态代理的spi框架的实现方式。</summary></entry><entry><title type="html">lucene简介和索引原理</title><link href="http://localhost:4000/blog/2018/04/26/apache-lucene-intro-and-index/" rel="alternate" type="text/html" title="lucene简介和索引原理" /><published>2018-04-26T00:00:00+08:00</published><updated>2018-04-26T00:00:00+08:00</updated><id>http://localhost:4000/blog/2018/04/26/apache-lucene-intro-and-index</id><content type="html" xml:base="http://localhost:4000/blog/2018/04/26/apache-lucene-intro-and-index/">&lt;h1 id=&quot;heading-lucene简介和索引原理&quot;&gt;lucene简介和索引原理&lt;/h1&gt;

&lt;h2 id=&quot;heading-lucene简介&quot;&gt;Lucene简介&lt;/h2&gt;
&lt;p&gt;Lucene是一个高效，全Java实现、开源、高性能、功能完整、易拓展，支持分词以及各种查询方式（前缀、模糊、正则等）、打分高亮、列式存储（DocValues）
的全文检索库。仅支持纯文本文件的索引和搜索。&lt;/p&gt;

&lt;center&gt;&lt;img src=&quot;/assets/images/post/2018-04-26-apache-lucene-intro-and-index/lucene-intro.png&quot; width=&quot;500px&quot; /&gt;&lt;/center&gt;

&lt;h2 id=&quot;heading-lucene索引原理&quot;&gt;lucene索引原理&lt;/h2&gt;
&lt;p&gt;每个字符串都指向包含此字符串的文档(Document)链表，此文档链表称为倒排表&lt;/p&gt;

&lt;center&gt;&lt;img src=&quot;/assets/images/post/2018-04-26-apache-lucene-intro-and-index/index-construction.png&quot; width=&quot;500px&quot; /&gt;&lt;/center&gt;

&lt;h3 id=&quot;heading-索引创建过程&quot;&gt;索引创建过程&lt;/h3&gt;

&lt;center&gt;&lt;img src=&quot;/assets/images/post/2018-04-26-apache-lucene-intro-and-index/index-create-step.png&quot; width=&quot;700px&quot; /&gt;&lt;/center&gt;

&lt;p&gt;1.需要被索引的原文档(document)&lt;/p&gt;

&lt;p&gt;2.将原文档传给分词组件(Tokenizer)，分词后得到词元(Token)&lt;/p&gt;

&lt;p&gt;3.将得到的词元(Token)传给语言处理组件(Linguistic Processor)，进行一些语法转化：包括字母转为小写、缩减(复数变单数)、转变(过去时转变为词根)，将词语转化为词根(Term)&lt;/p&gt;

&lt;p&gt;4.将得到的词(Term)传给索引组件(Indexer)，得到词典和倒排链表(反向索引表)&lt;/p&gt;

&lt;p&gt;5.通过索引存储将索引写入硬盘&lt;/p&gt;

&lt;h3 id=&quot;heading-检索过程&quot;&gt;检索过程&lt;/h3&gt;

&lt;center&gt;&lt;img src=&quot;/assets/images/post/2018-04-26-apache-lucene-intro-and-index/index-search-step.png&quot; width=&quot;700px&quot; /&gt;&lt;/center&gt;

&lt;p&gt;1.用户输入查询语句&lt;/p&gt;

&lt;p&gt;2.对查询语句进行词法分析得到单词以及关键字(关键字有AND, NOT)，然后对得到的单词进行语言处理(同索引过程中的语言处理几乎相同)得到查询词根Term&lt;/p&gt;

&lt;p&gt;3.语法分析，根据查询语句的语法规则来形成一棵语法树。&lt;/p&gt;

&lt;p&gt;4.通过索引存储将索引读入到内存。&lt;/p&gt;

&lt;p&gt;5.利用查询树搜索索引，从而得到每个词(Term) 的文档链表，对文档链表进行交，差，并得到结果文档&lt;/p&gt;

&lt;p&gt;6.根据得到的文档和查询语句的相关性，对结果进行排序。(向量空间模型算法:通过各个关键词根在不同文档中的权重来比较文档与查询语句的相关性)&lt;/p&gt;

&lt;h3 id=&quot;heading-lucene索引基本概念&quot;&gt;lucene索引基本概念&lt;/h3&gt;

&lt;ul&gt;
  &lt;li&gt;索引(index)
    &lt;ul&gt;
      &lt;li&gt;在Lucene中一个索引是放在一个文件夹中的&lt;/li&gt;
    &lt;/ul&gt;
  &lt;/li&gt;
  &lt;li&gt;段(segment)
    &lt;ul&gt;
      &lt;li&gt;一个索引可以包含多个段，段与段之间是独立的，添加新文档可以生成新的段，不同的段可以合并&lt;/li&gt;
    &lt;/ul&gt;
  &lt;/li&gt;
  &lt;li&gt;文档(document)
    &lt;ul&gt;
      &lt;li&gt;文档是我们建索引的基本单位，不同的文档是保存在不同的段中的，一个段可以包含多篇文档&lt;/li&gt;
      &lt;li&gt;新添加的文档是单独保存在一个新生成的段中，随着段的合并，不同的文档合并到同一个段中&lt;/li&gt;
    &lt;/ul&gt;
  &lt;/li&gt;
  &lt;li&gt;域(field)
    &lt;ul&gt;
      &lt;li&gt;一篇文档包含不同类型的信息，可以分开索引，比如标题，时间，正文，作者等，都可以保存在不同的域里&lt;/li&gt;
    &lt;/ul&gt;
  &lt;/li&gt;
  &lt;li&gt;词(term)
    &lt;ul&gt;
      &lt;li&gt;词是索引的最小单位，是经过词法分析和语言处理后的字符串&lt;/li&gt;
    &lt;/ul&gt;
  &lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;Lucene的索引结构中，即保存了正向信息，也保存了反向信息&lt;/p&gt;
&lt;ul&gt;
  &lt;li&gt;正向信息：按层次保存了从索引，一直到词的包含关系：索引(Index) –&amp;gt; 段(segment) –&amp;gt; 文档(Document) –&amp;gt; 域(Field) –&amp;gt; 词(Term)，也即此索引包含了那些段，每个段包含了那些文档，每个文档包含了那些域，每个域包含了那些词&lt;/li&gt;
  &lt;li&gt;反向信息：保存了词典到倒排表的映射：词(Term) –&amp;gt; 文档(Document)&lt;/li&gt;
&lt;/ul&gt;

&lt;h3 id=&quot;heading-lucene结构&quot;&gt;lucene结构&lt;/h3&gt;
&lt;p&gt;全文索引绝大多数是通过倒排索引来做，倒排索引由两个部分组成，即词典和倒排表&lt;/p&gt;

&lt;h4 id=&quot;heading-索引结构&quot;&gt;索引结构&lt;/h4&gt;
&lt;p&gt;lucene从4开始大量使用的数据结构是FST（Finite State Transducer）。FST有两个优点：&lt;/p&gt;

&lt;p&gt;1）空间占用小。通过对词典中单词前缀和后缀的重复利用，压缩了存储空间，压缩率一般在3倍~20倍之间；&lt;/p&gt;

&lt;p&gt;2）查询速度快。O(len(str))的查询时间复杂度。&lt;/p&gt;

&lt;p&gt;3) 模糊查询支持比较好&lt;/p&gt;

&lt;p&gt;4）输入要求有序，更新较为困难&lt;/p&gt;

&lt;p&gt;索引文件：
我们往索引库里插入四个单词abd、abe、acf、acg，看看它的索引文件内容&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;tip部分，每列一个FST索引，所以会有多个FST，每个FST存放前缀和后缀块指针，这里前缀就为a、ab、ac&lt;/li&gt;
  &lt;li&gt;tim里面存放后缀块和词的其他信息如倒排表指针、TFDF等&lt;/li&gt;
  &lt;li&gt;doc文件里就为每个单词的倒排表。&lt;/li&gt;
&lt;/ul&gt;

&lt;center&gt;&lt;img src=&quot;/assets/images/post/2018-04-26-apache-lucene-intro-and-index/index-file-construction.png&quot; width=&quot;700px&quot; /&gt;&lt;/center&gt;

&lt;p&gt;所以它的检索过程分为三个步骤：&lt;/p&gt;
&lt;ol&gt;
  &lt;li&gt;内存加载tip文件，通过FST匹配前缀找到后缀词块位置。&lt;/li&gt;
  &lt;li&gt;根据词块位置，读取磁盘中tim文件中后缀块并找到后缀和相应的倒排表位置信息。&lt;/li&gt;
  &lt;li&gt;根据倒排表位置去doc文件中加载倒排表&lt;/li&gt;
&lt;/ol&gt;

&lt;center&gt;&lt;img src=&quot;/assets/images/post/2018-04-26-apache-lucene-intro-and-index/index-create-example.png&quot; width=&quot;700px&quot; /&gt;&lt;/center&gt;

&lt;ul&gt;
  &lt;li&gt;插入abd时，没有输出&lt;/li&gt;
  &lt;li&gt;插入abe时，计算出前缀ab，但此时不知道后续还不会有其他以ab为前缀的词，所以此时无输出。&lt;/li&gt;
  &lt;li&gt;插入acf时，因为是有序的，知道不会再有ab前缀的词了，这时就可以写tip和tim了，tim中写入后缀词块d、e和它们的倒排表位置ip_d,ip_e，tip中写入a，b和以ab为前缀的后缀词块位置&lt;/li&gt;
  &lt;li&gt;插入acg时，计算出和acf共享前缀ac，这时输入已经结束，所有数据写入磁盘。tim中写入后缀词块f、g和相对应的倒排表位置，tip中写入c和以ac为前缀的后缀词块位置&lt;/li&gt;
&lt;/ul&gt;

&lt;h4 id=&quot;heading-倒排表结构&quot;&gt;倒排表结构&lt;/h4&gt;
&lt;p&gt;Lucene现使用的倒排表结构叫&lt;a href=&quot;https://www.elastic.co/blog/frame-of-reference-and-roaring-bitmaps&quot;&gt;Frame of reference&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;数据压缩：
下图：将6个数字从原先的24bytes压缩到7bytes
注：step1到step2的得到的新数组是后尾数减去前位数得到的&lt;/p&gt;

&lt;center&gt;&lt;img src=&quot;/assets/images/post/2018-04-26-apache-lucene-intro-and-index/frame-of-reference.png&quot; width=&quot;500px&quot; /&gt;&lt;/center&gt;

&lt;p&gt;跳跃表加速合并:
因为布尔查询时，and 和or 操作都需要合并倒排表，这时就需要快速定位相同文档号，所以利用跳跃表来进行相同文档号查找&lt;/p&gt;

&lt;center&gt;&lt;img src=&quot;/assets/images/post/2018-04-26-apache-lucene-intro-and-index/skiplist_linklist_complete.png&quot; width=&quot;700px&quot; /&gt;&lt;/center&gt;

&lt;p&gt;&lt;a href=&quot;http://www.cnblogs.com/forfuture1978/archive/2010/04/04/1704258.html&quot;&gt;链表合并&lt;/a&gt;&lt;/p&gt;

&lt;h2 id=&quot;heading-番外篇&quot;&gt;番外篇&lt;/h2&gt;

&lt;h3 id=&quot;heading-fst原理解析&quot;&gt;&lt;a href=&quot;http://blog.jobbole.com/80669/&quot;&gt;FST原理解析&lt;/a&gt;&lt;/h3&gt;

&lt;h3 id=&quot;heading-跳跃表原理解析&quot;&gt;&lt;a href=&quot;https://www.cnblogs.com/George1994/p/7635731.html&quot;&gt;跳跃表原理解析&lt;/a&gt;&lt;/h3&gt;</content><author><name>{&quot;name&quot;=&gt;nil, &quot;job_title&quot;=&gt;nil, &quot;location&quot;=&gt;nil, &quot;email&quot;=&gt;nil, &quot;social_links&quot;=&gt;[{&quot;name&quot;=&gt;&quot;facebook&quot;, &quot;url&quot;=&gt;nil}, {&quot;name&quot;=&gt;&quot;github&quot;, &quot;url&quot;=&gt;&quot;https://github.com/Cuner&quot;}, {&quot;name&quot;=&gt;&quot;instagram&quot;, &quot;url&quot;=&gt;nil}, {&quot;name&quot;=&gt;&quot;linkedin&quot;, &quot;url&quot;=&gt;nil}, {&quot;name&quot;=&gt;&quot;stackoverflow&quot;, &quot;url&quot;=&gt;nil}, {&quot;name&quot;=&gt;&quot;twitter&quot;, &quot;url&quot;=&gt;nil}, {&quot;name&quot;=&gt;&quot;vk&quot;, &quot;url&quot;=&gt;nil}]}</name></author><category term="apache lucene" /><summary type="html">lucene简介和索引原理</summary></entry><entry><title type="html">HBASE的索引查询</title><link href="http://localhost:4000/blog/2017/12/25/hbase-search-index/" rel="alternate" type="text/html" title="HBASE的索引查询" /><published>2017-12-25T00:00:00+08:00</published><updated>2017-12-25T00:00:00+08:00</updated><id>http://localhost:4000/blog/2017/12/25/hbase-search-index</id><content type="html" xml:base="http://localhost:4000/blog/2017/12/25/hbase-search-index/">&lt;h3 id=&quot;heading-一级索引&quot;&gt;一级索引&lt;/h3&gt;
&lt;p&gt;在逻辑上，HBase的表数据按RowKey进行字典排序， RowKey实际上是数据表的一级索引，由于HBase本身没有二级索引机制，基于索引检索数据只能单纯地依靠RowKey。&lt;/p&gt;

&lt;h3 id=&quot;heading-热点写&quot;&gt;热点写&lt;/h3&gt;
&lt;p&gt;大部分场景下，我们的rowkey总是顺序增大的，存在比较明显的问题就是&lt;strong&gt;热点写&lt;/strong&gt;，我们总是向最大的start key所在的region写数据，其次，由于热点，我们总是往最大的start key的region写记录，之前分裂出来的region不会被写数据，他们都处于半满状态，这样的分布也是不利的。如果在写比较频繁的场景下，数据增长太快，split的次数也会增多，由于split是比较耗费资源的。&lt;/p&gt;

&lt;h3 id=&quot;heading-热点写的解决思路&quot;&gt;热点写的解决思路&lt;/h3&gt;
&lt;ul&gt;
  &lt;li&gt;随机散列(hash):hash就是rowkey前面由一串随机字符串组成，随机字符串生成方式可以由SHA或者MD5方式生成，那么新增的rowkey就不再是按顺序增大的了，就可以解决写热点问题&lt;/li&gt;
  &lt;li&gt;分区式:这种方式类似于mysql中的分表，结合当前的region数目对id取模作为rowkey的前缀。但是一旦region自然分裂，分裂出来的分区号会是一样的，会有部分热点写问题出现，一般通过增多预分区或者加入多级分区来避免这个问题，通过合理设定预分区可解决热点写问题，同时减少split带来的性能消耗。&lt;/li&gt;
&lt;/ul&gt;

&lt;h3 id=&quot;heading-一级索引的局限&quot;&gt;一级索引的局限&lt;/h3&gt;
&lt;p&gt;为了能支持多条件查询，开发者需要将所有可能作为查询条件的字段一一拼接到RowKey中，这是HBase开发中极为常见的做法，但是无论怎样设计，单一RowKey固有的局限性决定了它不可能有效地支持多条件查询。通常来说，RowKey只能针对条件中含有其首字段的查询给予令人满意的性能支持，在查询其他字段时，表现就差强人意了，在极端情况下某些字段的查询性能可能会退化为全表扫描的水平，这是因为字段在RowKey中的地位是不等价的，它们在RowKey中的排位决定了它们被检索时的性能表现，排序越靠前的字段在查询中越具有优势(类似于mysql联合索引的最左原则)，特别是首位字段具有特别的先发优势，如果查询中包含首位字段，检索时就可以通过首位字段的值确定RowKey的前缀部分，从而大幅度地收窄检索区间，如果不包含则只能在全体数据的RowKey上逐一查找，由此可以想见两者在性能上的差距.&lt;/p&gt;

&lt;h3 id=&quot;heading-二级索引的解决方案&quot;&gt;二级索引的解决方案&lt;/h3&gt;
&lt;p&gt;&lt;strong&gt;原理&lt;/strong&gt;：“二级多列索引”是针对目标记录的某个或某些列建立的“键-值”数据，以列的值为键，以记录的RowKey为值，当以这些列为条件进行查询时，引擎可以通过检索相应的“键-值”数据快速找到目标记录。由于HBase本身并没有索引机制，为了确保非侵入性，引擎将索引视为普通数据存放在数据表中，所以，如何解决索引与主数据的划分存储是引擎第一个需要处理的问题，为了能获得最佳的性能表现，我们并没有将主数据和索引分表储存，而是将它们存放在了同一张表里，通过给索引和主数据的RowKey添加特别设计的Hash前缀，实现了在Region切分时，索引能够跟随其主数据划归到同一Region上，即任意Region上的主数据其索引也必定驻留在同一Region上，这样我们就能把从索引抓取目标主数据的性能损失降低到最小。与此同时，特别设计的Hash前缀还在逻辑上把索引与主数据进行了自动的分离，当全体数据按RowKey排序时，排在前面的都是索引，我们称之为索引区，排在后面的均为主数据，我们称之为主数据区。最后，通过给索引和主数据分配不同的Column Family，又在物理存储上把它们隔离了起来。逻辑和物理上的双重隔离避免了将两类数据存放在同一张表里带来的副作用，防止了它们之间的相互干扰，降低了数据维护的复杂性，可以说这是在性能和可维护性上达到的最佳平衡。&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;方案：&lt;/strong&gt;&lt;/p&gt;
&lt;ul&gt;
  &lt;li&gt;将索引视为普通数据存放在数据表中（确保非侵入性）&lt;/li&gt;
  &lt;li&gt;将主数据和索引数据存放在同一张表里(为了能获得最佳的性能表现)
    &lt;ul&gt;
      &lt;li&gt;通过给索引和主数据的RowKey添加特别设计的Hash前缀，对Region完成预切分后(指定region数，禁止引擎自动切分)，索引能够跟随其主数据划归到同一Region上。（从索引抓取目标主数据的性能损失降低到最小）&lt;/li&gt;
      &lt;li&gt;特别设计的Hash前缀还在逻辑上把索引与主数据进行了自动的分离，当全体数据按RowKey排序时，排在前面的都是索引，我们称之为索引区，排在后面的均为主数据，我们称之为主数据区&lt;/li&gt;
      &lt;li&gt;通过给索引和主数据分配不同的Column Family，又在物理存储上把它们隔离了起来&lt;/li&gt;
    &lt;/ul&gt;
  &lt;/li&gt;
&lt;/ul&gt;

&lt;center&gt;&lt;img src=&quot;/assets/images/post/2017-12-25-hbase-search-index/index.png&quot; width=&quot;500&quot; /&gt;&lt;/center&gt;

&lt;ul&gt;
  &lt;li&gt;四位数字构成Hash前缀，范围从0000到9999，规划切分100个Region，则100个Region的RowKey区间分别为[0000,0099]，[0100,0199]，……，[9900,9999]&lt;/li&gt;
  &lt;li&gt;主数据的RowKey，它由四位Hash前缀和原始ID两部分组成，其中Hash前缀是由引擎分配的一个范围在0000到9999之间的随机值，通过这个随机的Hash前缀可以让主数据均匀地散列到所有的Region上&lt;/li&gt;
  &lt;li&gt;索引的RowKey，格式为：RegionStartKey-索引名-索引键-索引值&lt;/li&gt;
  &lt;li&gt;两种索引：a和b，索引a是为字段q1和q2设计的两列联合索引，索引b是为字段q2和q3设计的两列联合索引&lt;/li&gt;
  &lt;li&gt;假定需要查询满足条件q1=01 and q2=02的Sample记录，分析查询字段和索引匹配情况可知应使用索引a，也就是说我们首先确定了索引名，于是在Region 1上进行scan的区间将从主数据全集收窄至[0000-a, 0000-b)，接着拼接查询字段的值，我们得到了索引键：0102，scan区间又进一步收窄为[0000-a-0102, 0000-a-0103)，于是我们可以很快地找到0000-a-0102-0000|63af51b2这条索引，进而得到了索引值，也就是目标数据的RowKey：0000|63af51b2，通过在Region内执行Get操作，最终得到了目标数据&lt;/li&gt;
&lt;/ul&gt;</content><author><name>{&quot;name&quot;=&gt;nil, &quot;job_title&quot;=&gt;nil, &quot;location&quot;=&gt;nil, &quot;email&quot;=&gt;nil, &quot;social_links&quot;=&gt;[{&quot;name&quot;=&gt;&quot;facebook&quot;, &quot;url&quot;=&gt;nil}, {&quot;name&quot;=&gt;&quot;github&quot;, &quot;url&quot;=&gt;&quot;https://github.com/Cuner&quot;}, {&quot;name&quot;=&gt;&quot;instagram&quot;, &quot;url&quot;=&gt;nil}, {&quot;name&quot;=&gt;&quot;linkedin&quot;, &quot;url&quot;=&gt;nil}, {&quot;name&quot;=&gt;&quot;stackoverflow&quot;, &quot;url&quot;=&gt;nil}, {&quot;name&quot;=&gt;&quot;twitter&quot;, &quot;url&quot;=&gt;nil}, {&quot;name&quot;=&gt;&quot;vk&quot;, &quot;url&quot;=&gt;nil}]}</name></author><category term="hbase" /><summary type="html">一级索引 在逻辑上，HBase的表数据按RowKey进行字典排序， RowKey实际上是数据表的一级索引，由于HBase本身没有二级索引机制，基于索引检索数据只能单纯地依靠RowKey。</summary></entry><entry><title type="html">HBASE原理与架构</title><link href="http://localhost:4000/blog/2017/12/20/hbase-construction-theory/" rel="alternate" type="text/html" title="HBASE原理与架构" /><published>2017-12-20T00:00:00+08:00</published><updated>2017-12-20T00:00:00+08:00</updated><id>http://localhost:4000/blog/2017/12/20/hbase-construction-theory</id><content type="html" xml:base="http://localhost:4000/blog/2017/12/20/hbase-construction-theory/">&lt;p&gt;HBASE是一个构建在HDFS上的分布式列存储系统，比较起传统的关系型数据库的优点在于，可以实现高性能的并发读写操作。同时HBase不同于传统关系型数据库的面向行存储，HBase是面向列存储，列可以动态增加，列为空就不存储数据，能更好的节省存储空间。Hbase还会对数据进行透明切分，使得存储本身具有了水平伸缩性&lt;/p&gt;

&lt;h2 id=&quot;heading-hbase特点&quot;&gt;HBASE特点&lt;/h2&gt;
&lt;ul&gt;
  &lt;li&gt;数据量大:一个表可以有数十亿行，上百万列&lt;/li&gt;
  &lt;li&gt;无模式:每行都有一个可排序的主键和任意多的列，列可以根据需要动态的增加，同一张表中不同的行可以有截然不同的列&lt;/li&gt;
  &lt;li&gt;面向列：面向列（族）的存储和权限控制，列（族）独立检索&lt;/li&gt;
  &lt;li&gt;稀疏:空（null）列并不占用存储空间，表可以设计的非常稀疏；&lt;/li&gt;
  &lt;li&gt;数据多版本:每个单元中的数据可以有多个版本，默认情况下版本号自动分配，是单元格插入时的时间戳&lt;/li&gt;
  &lt;li&gt;数据类型单一:Hbase中的数据都是字符串，没有类型。&lt;/li&gt;
&lt;/ul&gt;

&lt;h2 id=&quot;heading-hbase数据模型&quot;&gt;HBASE数据模型&lt;/h2&gt;
&lt;center&gt;&lt;img src=&quot;/assets/images/post/2017-12-20-hbase-construction-theory/hbase-data-model.png&quot; width=&quot;500px&quot; /&gt;&lt;/center&gt;

&lt;ul&gt;
  &lt;li&gt;行健(Rowkey):是Byte array，是表中每条记录的“主键”，方便快速查找，Rowkey的设计非常重要(检索方式)&lt;/li&gt;
  &lt;li&gt;版本(version):每条记录可动态添加Version Number，类型为Long，默认值是系统时间戳，可由用户自定义&lt;/li&gt;
  &lt;li&gt;列族(Column Family):拥有一个名称，包含一个或者多个相关列&lt;/li&gt;
  &lt;li&gt;列(Colume):属于某一个Column Family，格式:familyName:columnName&lt;/li&gt;
  &lt;li&gt;值(value)&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;Table在水平方向有一个或者多个Column Family组成，一个Column Family中可以由任意多个Column组成，即Column Family支持动态扩展，无需预先定义Column的数量以及类型，所有Column均以二进制格式存储，用户需要自行进行类型转换&lt;/p&gt;

&lt;h2 id=&quot;heading-hbase物理模型&quot;&gt;HBASE物理模型&lt;/h2&gt;

&lt;h3 id=&quot;heading-物理存储&quot;&gt;物理存储&lt;/h3&gt;

&lt;ul&gt;
  &lt;li&gt;Table中所有行都按照row key的字典序排列&lt;/li&gt;
  &lt;li&gt;Table在行的方向上分割为多个Region(相当于一个region对应某张表的startRowkey到endRowKey的数据)&lt;/li&gt;
  &lt;li&gt;Region按大小分割的，每个表开始只有一个region，随着数据增多，region不断增大，当增大到一个阀值的时候，region就会等分会两个新的region，之后会有越来越多的region&lt;/li&gt;
  &lt;li&gt;Region是Hbase中分布式存储和负载均衡的最小单元，不同Region分布到不同RegionServer上&lt;/li&gt;
&lt;/ul&gt;

&lt;center&gt;&lt;img src=&quot;/assets/images/post/2017-12-20-hbase-construction-theory/hbase-table-region.png&quot; width=&quot;500px&quot; /&gt;&lt;/center&gt;

&lt;ul&gt;
  &lt;li&gt;Region虽然是分布式存储的最小单元，但并不是存储的最小单元。Region由一个或者多个Store组成，每个store保存一个columns family；每个Strore又由一个memStore和0至多个StoreFile(基于Hfile实现)组成；memStore存储在内存中，StoreFile存储在HDFS上。&lt;/li&gt;
&lt;/ul&gt;

&lt;center&gt;&lt;img src=&quot;/assets/images/post/2017-12-20-hbase-construction-theory/hbase-region-store.png&quot; width=&quot;500px&quot; /&gt;&lt;/center&gt;

&lt;h3 id=&quot;heading-hbase架构以及基本组件&quot;&gt;HBASE架构以及基本组件&lt;/h3&gt;

&lt;center&gt;&lt;img src=&quot;/assets/images/post/2017-12-20-hbase-construction-theory/hbase-construction.jpg&quot; width=&quot;500px&quot; /&gt;&lt;/center&gt;

&lt;ul&gt;
  &lt;li&gt;&lt;strong&gt;Client&lt;/strong&gt;:包含访问HBase的接口，并维护cache来加快对HBase的访问(比如region的位置信息)；使用HBase RPC机制与HMaster和HRegionServer进行通信，Client与HMaster进行通信进行管理类操作，Client与HRegionServer进行数据读写类操作&lt;/li&gt;
  &lt;li&gt;&lt;strong&gt;Master&lt;/strong&gt;
    &lt;ul&gt;
      &lt;li&gt;为Region server分配region&lt;/li&gt;
      &lt;li&gt;负责Region server的负载均衡&lt;/li&gt;
      &lt;li&gt;发现失效的Region server并重新分配其上的region&lt;/li&gt;
      &lt;li&gt;管理用户对table的增删改查操作&lt;/li&gt;
    &lt;/ul&gt;
  &lt;/li&gt;
  &lt;li&gt;&lt;strong&gt;Region Server&lt;/strong&gt;
    &lt;ul&gt;
      &lt;li&gt;Regionserver维护region，处理对这些region的IO请求&lt;/li&gt;
      &lt;li&gt;Regionserver负责切分在运行过程中变得过大的region&lt;/li&gt;
    &lt;/ul&gt;
  &lt;/li&gt;
  &lt;li&gt;&lt;strong&gt;Zookeeper&lt;/strong&gt;
    &lt;ul&gt;
      &lt;li&gt;通过选举，保证任何时候，集群中只有一个master，Master与RegionServers启动时会向ZooKeeper注册（避免master单点问题）&lt;/li&gt;
      &lt;li&gt;存贮所有Region的寻址入口&lt;/li&gt;
      &lt;li&gt;实时监控Region server的上线和下线信息。并实时通知给Master&lt;/li&gt;
      &lt;li&gt;存储HBase的schema和table元数据&lt;/li&gt;
      &lt;li&gt;默认情况下，HBase 管理ZooKeeper 实例，比如， 启动或者停止ZooKeeper&lt;/li&gt;
    &lt;/ul&gt;
  &lt;/li&gt;
&lt;/ul&gt;

&lt;center&gt;&lt;img src=&quot;/assets/images/post/2017-12-20-hbase-construction-theory/hbase-master-regionserver.png&quot; width=&quot;500px&quot; /&gt;&lt;/center&gt;

&lt;h2 id=&quot;heading-hbase写入过程&quot;&gt;HBASE写入过程&lt;/h2&gt;

&lt;p&gt;Client写入 -&amp;gt; 存入MemStore，一直到MemStore满 -&amp;gt; Flush成一个StoreFile，直至增长到一定阈值 -&amp;gt; 触发Compact合并操作 -&amp;gt; 多个StoreFile合并成一个StoreFile，同时进行版本合并和数据删除 -&amp;gt; 当StoreFiles Compact后，逐步形成越来越大的StoreFile -&amp;gt; 单个StoreFile大小超过一定阈值后，触发Split操作，把当前Region Split成2个Region，Region会下线，新Split出的2个孩子Region会被HMaster分配到相应的HRegionServer上，使得原先1个Region的压力得以分流到2个Region上
由此过程可知，HBase只是增加数据，有所得更新和删除操作，都是在Compact阶段做的，所以，用户写操作只需要进入到内存即可立即返回，从而保证I/O高性能&lt;/p&gt;

&lt;h2 id=&quot;heading-hbase容灾日志恢复&quot;&gt;HBASE容灾(日志恢复)&lt;/h2&gt;

&lt;center&gt;&lt;img src=&quot;/assets/images/post/2017-12-20-hbase-construction-theory/hbase-hlog.png&quot; width=&quot;500px&quot; /&gt;&lt;/center&gt;
&lt;p&gt;每次用户执行写入操作，首先是把Log写入到HLog中，HLog是标准的Hadoop Sequence File，由于Log数据量小，而且是顺序写，速度非常快；同时把数据写入到内存MemStore中，成功后返回给Client，所以对Client来说，HBase写的速度非常快，因为数据只要写入到内存中，就算成功了。接着检查MemStore是否已满，如果满了，就把内存中的MemStore Flush到磁盘上，形成一个新的StoreFile。HLog文件定期会滚动出新的，并删除旧的文件（已持久化到StoreFile中的数据）。当HRegionServer意外终止后，HMaster会通过Zookeeper感知到，HMaster首先会处理遗留的 HLog文件，将其中不同Region的Log数据进行拆分，分别放到相应region的目录下，然后再将失效的region重新分配，领取 到这些region的HRegionServer在Load Region的过程中，会发现有历史HLog需要处理，因此会Replay HLog中的数据到MemStore中，然后flush到StoreFiles，完成数据恢复&lt;/p&gt;

&lt;h2 id=&quot;heading-hbase容错性&quot;&gt;HBASE容错性&lt;/h2&gt;

&lt;ul&gt;
  &lt;li&gt;&lt;strong&gt;master容错&lt;/strong&gt;:Zookeeper重新选择一个新的Master
    &lt;ul&gt;
      &lt;li&gt;无Master过程中，数据读取仍照常进行&lt;/li&gt;
      &lt;li&gt;无master过程中，region切分、负载均衡等无法进行&lt;/li&gt;
    &lt;/ul&gt;
  &lt;/li&gt;
  &lt;li&gt;&lt;strong&gt;regionServer容错&lt;/strong&gt;:定时向Zookeeper汇报心跳，如果一旦时间内未出现心跳，Master将该RegionServer上的Region重新分配到其他RegionServer上，失效服务器上“预写”日志由主服务器进行分割并派送给新的RegionServer&lt;/li&gt;
  &lt;li&gt;&lt;strong&gt;zookeeper容错&lt;/strong&gt;:Zookeeper是一个可靠地服务，一般配置3或5个Zookeeper实例&lt;/li&gt;
&lt;/ul&gt;

&lt;h2 id=&quot;heading-hbase检索和扫描如何找到某条记录对应的regionserver&quot;&gt;HBASE检索和扫描：如何找到某条记录对应的regionServer&lt;/h2&gt;

&lt;p&gt;ROOT与META表
Hbase中有两张特殊表，ROOT和META
META：记录了用户表的Region信息，可以有多个region
ROOT：记录了META表的Region信息，ROOT中只有一个region
Zookeeper中记录了ROOT表的location
客户端访问数据的流程： 
Client -&amp;gt; Zookeeper -&amp;gt; -ROOT- -&amp;gt; .META. -&amp;gt; 用户数据表&lt;/p&gt;</content><author><name>{&quot;name&quot;=&gt;nil, &quot;job_title&quot;=&gt;nil, &quot;location&quot;=&gt;nil, &quot;email&quot;=&gt;nil, &quot;social_links&quot;=&gt;[{&quot;name&quot;=&gt;&quot;facebook&quot;, &quot;url&quot;=&gt;nil}, {&quot;name&quot;=&gt;&quot;github&quot;, &quot;url&quot;=&gt;&quot;https://github.com/Cuner&quot;}, {&quot;name&quot;=&gt;&quot;instagram&quot;, &quot;url&quot;=&gt;nil}, {&quot;name&quot;=&gt;&quot;linkedin&quot;, &quot;url&quot;=&gt;nil}, {&quot;name&quot;=&gt;&quot;stackoverflow&quot;, &quot;url&quot;=&gt;nil}, {&quot;name&quot;=&gt;&quot;twitter&quot;, &quot;url&quot;=&gt;nil}, {&quot;name&quot;=&gt;&quot;vk&quot;, &quot;url&quot;=&gt;nil}]}</name></author><category term="hbase" /><summary type="html">HBASE是一个构建在HDFS上的分布式列存储系统，比较起传统的关系型数据库的优点在于，可以实现高性能的并发读写操作。同时HBase不同于传统关系型数据库的面向行存储，HBase是面向列存储，列可以动态增加，列为空就不存储数据，能更好的节省存储空间。Hbase还会对数据进行透明切分，使得存储本身具有了水平伸缩性</summary></entry><entry><title type="html">HDFS分布式文件系统</title><link href="http://localhost:4000/blog/2017/12/05/hdfs-theory/" rel="alternate" type="text/html" title="HDFS分布式文件系统" /><published>2017-12-05T00:00:00+08:00</published><updated>2017-12-05T00:00:00+08:00</updated><id>http://localhost:4000/blog/2017/12/05/hdfs-theory</id><content type="html" xml:base="http://localhost:4000/blog/2017/12/05/hdfs-theory/">&lt;h2 id=&quot;heading-hdfs设计理念&quot;&gt;HDFS设计理念&lt;/h2&gt;

&lt;p&gt;Hadoop分布式文件系统(HDFS)被设计成适合运行在通用硬件上的分布式文件系统，HDFS是一个高度容错性的系统，适合部署在廉价的机器上。HDFS能提供高吞吐量的数据访问，非常适合大规模数据集上的应用。&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;&lt;b&gt;存储超大文件:&lt;/b&gt;运行在HDFS上的应用具有很大的数据集。HDFS上的一个典型文件大小一般都在G字节至T字节。因此，HDFS被调节以支持大文件存储。它能提供整体上高的数据传输带宽，能在一个集群里扩展到数百个节点。一个单一的HDFS实例应该能支撑数以千万计的文件。&lt;/li&gt;
  &lt;li&gt;&lt;b&gt;一次写入、多次读取:&lt;/b&gt;HDFS存储的数据集作为hadoop的分析对象。在数据集生成后，长时间在此数据集上进行各种分析。每次分析都将设计该数据集的大部分数据甚至全部数据，比之数据访问的低延迟问题，更关键的在于数据访问的高吞吐量，因此读取整个数据集的时间延迟比读取第一条记录的时间延迟更重要。&lt;/li&gt;
  &lt;li&gt;&lt;b&gt;运行在普通廉价的服务器上:&lt;/b&gt;HDFS设计理念之一就是让它能运行在普通的硬件之上，即便硬件出现故障，也可以通过容错策略(错误检测和快速、自动的恢复)来保证数据的高可用。&lt;/li&gt;
&lt;/ul&gt;

&lt;h2 id=&quot;heading-hdfs基本概念&quot;&gt;HDFS基本概念&lt;/h2&gt;
&lt;p&gt;HDFS暴露了文件系统的名字空间，用户能够以文件的形式在上面存储数据。从内部看，一个文件其实被分成一个或多个数据块，这些块存储在一组Datanode上。Namenode执行文件系统的名字空间操作，比如打开、关闭、重命名文件或目录。它也负责确定数据块到具体Datanode节点的映射。Datanode负责处理文件系统客户端的读写请求。在Namenode的统一调度下进行数据块的创建、删除和复制&lt;/p&gt;
&lt;ul&gt;
  &lt;li&gt;&lt;b&gt;数据块(block):&lt;/b&gt;大文件会被分割成多个block进行存储，block大小默认为64MB。每一个block会在多个datanode上存储多份副本，默认是3份。&lt;/li&gt;
  &lt;li&gt;&lt;b&gt;namenode:&lt;/b&gt;namenode是一个中心服务器，负责管理文件目录、文件和block的对应关系以及block和datanode的对应关系。&lt;/li&gt;
  &lt;li&gt;&lt;b&gt;datanode:&lt;/b&gt;datanode就负责存储了，当然大部分容错机制都是在datanode上实现的。&lt;/li&gt;
&lt;/ul&gt;

&lt;h2 id=&quot;heading-hdfs基本架构图&quot;&gt;HDFS基本架构图&lt;/h2&gt;
&lt;center&gt;&lt;img src=&quot;/assets/images/post/2017-12-05-hdfs-theory/hdfs-construction.png&quot; width=&quot;500px&quot; /&gt;&lt;/center&gt;
&lt;p&gt;Rack 是指机架的意思，一个block的三个副本通常会保存到两个或者两个以上的机柜中（当然是机柜中的服务器），这样做的目的是做防灾容错。&lt;/p&gt;

&lt;p&gt;每个Datanode节点周期性地向Namenode发送心跳信号。网络割裂可能导致一部分Datanode跟Namenode失去联系。Namenode通过心跳信号的缺失来检测这一情况，并将这些近期不再发送心跳信号Datanode标记为宕机，不会再将新的IO请求发给它们。任何存储在宕机Datanode上的数据将不再有效。Datanode的宕机可能会引起一些数据块的副本系数低于指定值，Namenode不断地检测这些需要复制的数据块，一旦发现就启动复制操作。在下列情况下，可能需要重新复制：某个Datanode节点失效，某个副本遭到损坏，Datanode上的硬盘错误，或者文件的副本系数增大。&lt;/p&gt;

&lt;h2 id=&quot;heading-hdfs写文件流程&quot;&gt;HDFS写文件流程&lt;/h2&gt;
&lt;center&gt;&lt;img src=&quot;/assets/images/post/2017-12-05-hdfs-theory/hdfs-write.png&quot; width=&quot;500px&quot; /&gt;&lt;/center&gt;

&lt;p&gt;当客户端向HDFS文件写入数据的时候，一开始是写到本地临时文件中。假设该文件的副本系数设置为3，当本地临时文件累积到一个数据块的大小时，客户端会从Namenode获取一个Datanode列表用于存放副本。然后客户端开始向第一个Datanode传输数据，第一个Datanode一小部分一小部分(4 KB)地接收数据，将每一部分写入本地仓库，并同时传输该部分到列表中第二个Datanode节点。第二个Datanode也是这样，一小部分一小部分地接收数据，写入本地仓库，并同时传给第三个Datanode。最后，第三个Datanode接收数据并存储在本地。因此，Datanode能流水线式地从前一个节点接收数据，并在同时转发给下一个节点，数据以流水线的方式从前一个Datanode复制到下一个。
【ps】另一种数据写入的方式是采用多路写，也就是同时别写入到三个Datanode里面。管道写需要时间去完成，所以它有很高的延迟，但是它能更好地利用网络带宽；多路写有着比较低的延迟，因为客户端只需要等待最慢的DataNode确认（假设其余都已成功确认）。但是写入需要共享发送服务器的网络带宽，这对于有着很高负载的系统来说是一个瓶颈。&lt;/p&gt;

&lt;h2 id=&quot;heading-hdfs读文件流程&quot;&gt;HDFS读文件流程&lt;/h2&gt;
&lt;center&gt;&lt;img src=&quot;/assets/images/post/2017-12-05-hdfs-theory/hdfs-read.png&quot; width=&quot;500px&quot; /&gt;&lt;/center&gt;</content><author><name>{&quot;name&quot;=&gt;nil, &quot;job_title&quot;=&gt;nil, &quot;location&quot;=&gt;nil, &quot;email&quot;=&gt;nil, &quot;social_links&quot;=&gt;[{&quot;name&quot;=&gt;&quot;facebook&quot;, &quot;url&quot;=&gt;nil}, {&quot;name&quot;=&gt;&quot;github&quot;, &quot;url&quot;=&gt;&quot;https://github.com/Cuner&quot;}, {&quot;name&quot;=&gt;&quot;instagram&quot;, &quot;url&quot;=&gt;nil}, {&quot;name&quot;=&gt;&quot;linkedin&quot;, &quot;url&quot;=&gt;nil}, {&quot;name&quot;=&gt;&quot;stackoverflow&quot;, &quot;url&quot;=&gt;nil}, {&quot;name&quot;=&gt;&quot;twitter&quot;, &quot;url&quot;=&gt;nil}, {&quot;name&quot;=&gt;&quot;vk&quot;, &quot;url&quot;=&gt;nil}]}</name></author><category term="hdfs" /><summary type="html">HDFS设计理念</summary></entry><entry><title type="html">Spring AOP代理</title><link href="http://localhost:4000/blog/2017/06/29/spring-aop-proxy/" rel="alternate" type="text/html" title="Spring AOP代理" /><published>2017-06-29T00:00:00+08:00</published><updated>2017-06-29T00:00:00+08:00</updated><id>http://localhost:4000/blog/2017/06/29/spring-aop-proxy</id><content type="html" xml:base="http://localhost:4000/blog/2017/06/29/spring-aop-proxy/">&lt;h2 id=&quot;heading-一spring-aop代理的相关属性&quot;&gt;一、Spring AOP代理的相关属性&lt;/h2&gt;

&lt;ul&gt;
  &lt;li&gt;开启AOP自动代理&lt;/li&gt;
&lt;/ul&gt;

&lt;div class=&quot;highlighter-rouge&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;&amp;lt;aop:aspect-autoproxy /&amp;gt;
&lt;/code&gt;&lt;/pre&gt;
&lt;/div&gt;

&lt;ul&gt;
  &lt;li&gt;proxy-target-class:强调spring应该使用那种代理方式：JDK动态代理和CGLIB
    &lt;ul&gt;
      &lt;li&gt;JDK动态代理：代理对象必须为某个接口的实现，它是通过在运行期间创建一个接口的实现类来完成对目标对象的代理【默认属性值为false，即使用的是JDK动态代理】&lt;/li&gt;
      &lt;li&gt;CGLIB代理：原理类似于JDK代理，不同之处在于运行期间生成的代理对象是针对目标类扩展的子类，CGLIB是高效代码生成包，底层是依靠ASM（字节码编辑类库）操作字节码实现的，性能比JDK强。&lt;/li&gt;
      &lt;li&gt;使用CGLIB代理会出现的问题:无法通知Final方法，因为他们不允许被覆盖；还需要将CGLIB二进制包放入classpath下面；强制使用CGLIB代理需要将proxy-target-class设置为true&lt;/li&gt;
    &lt;/ul&gt;
  &lt;/li&gt;
  &lt;li&gt;expose-proxy:目标对象内部的自我调用将无法实施切面中的增强&lt;/li&gt;
&lt;/ul&gt;

&lt;h2 id=&quot;heading-二aop代理无法切入同类调用方法的问题&quot;&gt;二、AOP代理无法切入同类调用方法的问题&lt;/h2&gt;

&lt;div class=&quot;highlighter-rouge&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;@Service
public class Service {  
  
    //这个方法调用被切的方法,在外部被调用 
    public void callMethodA() {  
        ......  
        callMethodB();  
        ......  
    }  
      
    //Aop切入的方法 
    public void callMethodB() {  
        ......  
    }  
} 

@Aspect
@Service
public class Aspect {
    @After(&quot;execution(* Service.callMethodB(..))&quot;)  
    public void after() {  
        Logger.info(&quot;after call and do something.&quot;);
    }  
}  

//调用方式
service.callMethodA();

//spring配置
&amp;lt;aop:aspect-autoproxy proxy-target-class=&quot;true&quot;/&amp;gt;
&lt;/code&gt;&lt;/pre&gt;
&lt;/div&gt;

&lt;p&gt;上述的调用方式是根本无法进去切面的，在callMethodA()方法中调用callMethodB()相当于调用this.callMethodB()，此处的this指向目标对象，并不是调用代理对象的callMethodB()方法，解决方式如下两点&lt;/p&gt;
&lt;ul&gt;
  &lt;li&gt;强制使用AOP代理&lt;/li&gt;
&lt;/ul&gt;

&lt;div class=&quot;highlighter-rouge&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;//spring配置
&amp;lt;aop:aspectj-autoproxy proxy-target-class=&quot;true&quot; expose-proxy=&quot;true&quot; /&amp;gt;

//调用callMethodB()
((Service)AopContext.currentProxy()).callMethodB();
&lt;/code&gt;&lt;/pre&gt;
&lt;/div&gt;

&lt;ul&gt;
  &lt;li&gt;通过spring上下文获取代理类&lt;/li&gt;
&lt;/ul&gt;

&lt;div class=&quot;highlighter-rouge&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;//spring配置
&amp;lt;aop:aspectj-autoproxy proxy-target-class=&quot;true&quot;/&amp;gt;

//调用callMethodB()
applicationContext.getBean(&quot;service&quot;).callMethodB();
&lt;/code&gt;&lt;/pre&gt;
&lt;/div&gt;

&lt;p&gt;PS:使用第一种方式的时候要注意获取代理对象时的强制转换:使用默认的JDK动态代理的方式需要转换为接口，使用CGLIB代理的方式可以直接使用实现类的类型；同时代理对象使用的方法需要是public修饰的方法；spring自带的@transactional注解在使用中也有上述问题，该注解默认使用CGLIB代理。&lt;/p&gt;</content><author><name>{&quot;name&quot;=&gt;nil, &quot;job_title&quot;=&gt;nil, &quot;location&quot;=&gt;nil, &quot;email&quot;=&gt;nil, &quot;social_links&quot;=&gt;[{&quot;name&quot;=&gt;&quot;facebook&quot;, &quot;url&quot;=&gt;nil}, {&quot;name&quot;=&gt;&quot;github&quot;, &quot;url&quot;=&gt;&quot;https://github.com/Cuner&quot;}, {&quot;name&quot;=&gt;&quot;instagram&quot;, &quot;url&quot;=&gt;nil}, {&quot;name&quot;=&gt;&quot;linkedin&quot;, &quot;url&quot;=&gt;nil}, {&quot;name&quot;=&gt;&quot;stackoverflow&quot;, &quot;url&quot;=&gt;nil}, {&quot;name&quot;=&gt;&quot;twitter&quot;, &quot;url&quot;=&gt;nil}, {&quot;name&quot;=&gt;&quot;vk&quot;, &quot;url&quot;=&gt;nil}]}</name></author><category term="aop" /><summary type="html">一、Spring AOP代理的相关属性</summary></entry></feed>