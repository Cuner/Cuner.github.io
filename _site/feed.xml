<?xml version="1.0" encoding="utf-8"?><feed xmlns="http://www.w3.org/2005/Atom" xml:lang="en"><generator uri="https://jekyllrb.com/" version="3.5.2">Jekyll</generator><link href="http://localhost:4000/feed.xml" rel="self" type="application/atom+xml" /><link href="http://localhost:4000/" rel="alternate" type="text/html" hreflang="en" /><updated>2018-02-11T16:53:21+08:00</updated><id>http://localhost:4000/</id><title type="html">Tobi7</title><subtitle>Tobi7's blog</subtitle><author><name>{&quot;name&quot;=&gt;nil, &quot;job_title&quot;=&gt;nil, &quot;location&quot;=&gt;nil, &quot;email&quot;=&gt;nil, &quot;social_links&quot;=&gt;[{&quot;name&quot;=&gt;&quot;facebook&quot;, &quot;url&quot;=&gt;nil}, {&quot;name&quot;=&gt;&quot;github&quot;, &quot;url&quot;=&gt;&quot;https://github.com/Tobi7&quot;}, {&quot;name&quot;=&gt;&quot;instagram&quot;, &quot;url&quot;=&gt;nil}, {&quot;name&quot;=&gt;&quot;linkedin&quot;, &quot;url&quot;=&gt;nil}, {&quot;name&quot;=&gt;&quot;stackoverflow&quot;, &quot;url&quot;=&gt;nil}, {&quot;name&quot;=&gt;&quot;twitter&quot;, &quot;url&quot;=&gt;nil}, {&quot;name&quot;=&gt;&quot;vk&quot;, &quot;url&quot;=&gt;nil}]}</name></author><entry><title type="html">HBASE的索引查询</title><link href="http://localhost:4000/blog/2017/12/25/hbase-search-index/" rel="alternate" type="text/html" title="HBASE的索引查询" /><published>2017-12-25T00:00:00+08:00</published><updated>2017-12-25T00:00:00+08:00</updated><id>http://localhost:4000/blog/2017/12/25/hbase-search-index</id><content type="html" xml:base="http://localhost:4000/blog/2017/12/25/hbase-search-index/">&lt;h3 id=&quot;heading-一级索引&quot;&gt;一级索引&lt;/h3&gt;
&lt;p&gt;在逻辑上，HBase的表数据按RowKey进行字典排序， RowKey实际上是数据表的一级索引，由于HBase本身没有二级索引机制，基于索引检索数据只能单纯地依靠RowKey。&lt;/p&gt;

&lt;h3 id=&quot;heading-热点写&quot;&gt;热点写&lt;/h3&gt;
&lt;p&gt;大部分场景下，我们的rowkey总是顺序增大的，存在比较明显的问题就是&lt;strong&gt;热点写&lt;/strong&gt;，我们总是向最大的start key所在的region写数据，其次，由于热点，我们总是往最大的start key的region写记录，之前分裂出来的region不会被写数据，他们都处于半满状态，这样的分布也是不利的。如果在写比较频繁的场景下，数据增长太快，split的次数也会增多，由于split是比较耗费资源的。&lt;/p&gt;

&lt;h3 id=&quot;heading-热点写的解决思路&quot;&gt;热点写的解决思路&lt;/h3&gt;
&lt;ul&gt;
  &lt;li&gt;随机散列(hash):hash就是rowkey前面由一串随机字符串组成，随机字符串生成方式可以由SHA或者MD5方式生成，那么新增的rowkey就不再是按顺序增大的了，就可以解决写热点问题&lt;/li&gt;
  &lt;li&gt;分区式:这种方式类似于mysql中的分表，结合当前的region数目对id取模作为rowkey的前缀。但是一旦region自然分裂，分裂出来的分区号会是一样的，会有部分热点写问题出现，一般通过增多预分区或者加入多级分区来避免这个问题，通过合理设定预分区可解决热点写问题，同时减少split带来的性能消耗。&lt;/li&gt;
&lt;/ul&gt;

&lt;h3 id=&quot;heading-一级索引的局限&quot;&gt;一级索引的局限&lt;/h3&gt;
&lt;p&gt;由于HBase本身没有二级索引机制，基于索引检索数据只能单纯地依靠RowKey，为了能支持多条件查询，开发者需要将所有可能作为查询条件的字段一一拼接到RowKey中，这是HBase开发中极为常见的做法，但是无论怎样设计，单一RowKey固有的局限性决定了它不可能有效地支持多条件查询。通常来说，RowKey只能针对条件中含有其首字段的查询给予令人满意的性能支持，在查询其他字段时，表现就差强人意了，因为字段在RowKey中的地位是不等价的，它们在RowKey中的排位决定了它们被检索时的性能表现，排序越靠前的字段在查询中越具有优势(类似于mysql联合索引的最左原则)&lt;/p&gt;

&lt;h3 id=&quot;heading-二级索引的解决方案&quot;&gt;二级索引的解决方案&lt;/h3&gt;
&lt;p&gt;&lt;strong&gt;原理&lt;/strong&gt;：“二级多列索引”是针对目标记录的某个或某些列建立的“键-值”数据，以列的值为键，以记录的RowKey为值，当以这些列为条件进行查询时，引擎可以通过检索相应的“键-值”数据快速找到目标记录。&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;方案：&lt;/strong&gt;&lt;/p&gt;
&lt;ul&gt;
  &lt;li&gt;将索引视为普通数据存放在数据表中（确保非侵入性）&lt;/li&gt;
  &lt;li&gt;将主数据和索引数据存放在同一张表里(为了能获得最佳的性能表现)
    &lt;ul&gt;
      &lt;li&gt;通过给索引和主数据的RowKey添加特别设计的Hash前缀，对Region完成预切分后(指定region数，禁止引擎自动切分)，索引能够跟随其主数据划归到同一Region上。（从索引抓取目标主数据的性能损失降低到最小）&lt;/li&gt;
      &lt;li&gt;特别设计的Hash前缀还在逻辑上把索引与主数据进行了自动的分离，当全体数据按RowKey排序时，排在前面的都是索引，我们称之为索引区，排在后面的均为主数据，我们称之为主数据区&lt;/li&gt;
      &lt;li&gt;通过给索引和主数据分配不同的Column Family，又在物理存储上把它们隔离了起来&lt;/li&gt;
    &lt;/ul&gt;
  &lt;/li&gt;
&lt;/ul&gt;

&lt;center&gt;&lt;img src=&quot;/assets/images/post/2017-12-25-hbase-search-index/index.png&quot; width=&quot;500&quot; /&gt;&lt;/center&gt;

&lt;ul&gt;
  &lt;li&gt;四位数字构成Hash前缀，范围从0000到9999，规划切分100个Region，则100个Region的RowKey区间分别为[0000,0099]，[0100,0199]，……，[9900,9999]&lt;/li&gt;
  &lt;li&gt;主数据的RowKey，它由四位Hash前缀和原始ID两部分组成，其中Hash前缀是由引擎分配的一个范围在0000到9999之间的随机值，通过这个随机的Hash前缀可以让主数据均匀地散列到所有的Region上&lt;/li&gt;
  &lt;li&gt;索引的RowKey，格式为：RegionStartKey-索引名-索引键-索引值&lt;/li&gt;
  &lt;li&gt;两种索引：a和b，索引a是为字段q1和q2设计的两列联合索引，索引b是为字段q2和q3设计的两列联合索引&lt;/li&gt;
  &lt;li&gt;由索引找到对应的rowkey之后，直接在本地的region执行get操作，改操作执行效率是非常高的&lt;/li&gt;
&lt;/ul&gt;</content><author><name>{&quot;name&quot;=&gt;nil, &quot;job_title&quot;=&gt;nil, &quot;location&quot;=&gt;nil, &quot;email&quot;=&gt;nil, &quot;social_links&quot;=&gt;[{&quot;name&quot;=&gt;&quot;facebook&quot;, &quot;url&quot;=&gt;nil}, {&quot;name&quot;=&gt;&quot;github&quot;, &quot;url&quot;=&gt;&quot;https://github.com/Tobi7&quot;}, {&quot;name&quot;=&gt;&quot;instagram&quot;, &quot;url&quot;=&gt;nil}, {&quot;name&quot;=&gt;&quot;linkedin&quot;, &quot;url&quot;=&gt;nil}, {&quot;name&quot;=&gt;&quot;stackoverflow&quot;, &quot;url&quot;=&gt;nil}, {&quot;name&quot;=&gt;&quot;twitter&quot;, &quot;url&quot;=&gt;nil}, {&quot;name&quot;=&gt;&quot;vk&quot;, &quot;url&quot;=&gt;nil}]}</name></author><category term="hbase" /><summary type="html">一级索引 在逻辑上，HBase的表数据按RowKey进行字典排序， RowKey实际上是数据表的一级索引，由于HBase本身没有二级索引机制，基于索引检索数据只能单纯地依靠RowKey。</summary></entry><entry><title type="html">HBASE原理与架构</title><link href="http://localhost:4000/blog/2017/12/20/hbase-construction-theory/" rel="alternate" type="text/html" title="HBASE原理与架构" /><published>2017-12-20T00:00:00+08:00</published><updated>2017-12-20T00:00:00+08:00</updated><id>http://localhost:4000/blog/2017/12/20/hbase-construction-theory</id><content type="html" xml:base="http://localhost:4000/blog/2017/12/20/hbase-construction-theory/">&lt;p&gt;HBASE是一个构建在HDFS上的分布式列存储系统，比较起传统的关系型数据库的优点在于，可以实现高性能的并发读写操作。同时HBase不同于传统关系型数据库的面向行存储，HBase是面向列存储，列可以动态增加，列为空就不存储数据，能更好的节省存储空间。Hbase还会对数据进行透明切分，使得存储本身具有了水平伸缩性&lt;/p&gt;

&lt;h2 id=&quot;heading-hbase特点&quot;&gt;HBASE特点&lt;/h2&gt;
&lt;ul&gt;
  &lt;li&gt;数据量大:一个表可以有数十亿行，上百万列&lt;/li&gt;
  &lt;li&gt;无模式:每行都有一个可排序的主键和任意多的列，列可以根据需要动态的增加，同一张表中不同的行可以有截然不同的列&lt;/li&gt;
  &lt;li&gt;面向列：面向列（族）的存储和权限控制，列（族）独立检索&lt;/li&gt;
  &lt;li&gt;稀疏:空（null）列并不占用存储空间，表可以设计的非常稀疏；&lt;/li&gt;
  &lt;li&gt;数据多版本:每个单元中的数据可以有多个版本，默认情况下版本号自动分配，是单元格插入时的时间戳&lt;/li&gt;
  &lt;li&gt;数据类型单一:Hbase中的数据都是字符串，没有类型。&lt;/li&gt;
&lt;/ul&gt;

&lt;h2 id=&quot;heading-hbase数据模型&quot;&gt;HBASE数据模型&lt;/h2&gt;
&lt;center&gt;&lt;img src=&quot;/assets/images/post/2017-12-20-hbase-construction-theory/hbase-data-model.png&quot; width=&quot;500px&quot; /&gt;&lt;/center&gt;

&lt;ul&gt;
  &lt;li&gt;行健(Rowkey):是Byte array，是表中每条记录的“主键”，方便快速查找，Rowkey的设计非常重要(检索方式)&lt;/li&gt;
  &lt;li&gt;版本(version):每条记录可动态添加Version Number，类型为Long，默认值是系统时间戳，可由用户自定义&lt;/li&gt;
  &lt;li&gt;列族(Column Family):拥有一个名称，包含一个或者多个相关列&lt;/li&gt;
  &lt;li&gt;列(Colume):属于某一个Column Family，格式:familyName:columnName&lt;/li&gt;
  &lt;li&gt;值(value)&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;Table在水平方向有一个或者多个Column Family组成，一个Column Family中可以由任意多个Column组成，即Column Family支持动态扩展，无需预先定义Column的数量以及类型，所有Column均以二进制格式存储，用户需要自行进行类型转换&lt;/p&gt;

&lt;h2 id=&quot;heading-hbase物理模型&quot;&gt;HBASE物理模型&lt;/h2&gt;

&lt;h3 id=&quot;heading-物理存储&quot;&gt;物理存储&lt;/h3&gt;

&lt;ul&gt;
  &lt;li&gt;Table中所有行都按照row key的字典序排列&lt;/li&gt;
  &lt;li&gt;Table在行的方向上分割为多个Region(相当于一个region对应某张表的startRowkey到endRowKey的数据)&lt;/li&gt;
  &lt;li&gt;Region按大小分割的，每个表开始只有一个region，随着数据增多，region不断增大，当增大到一个阀值的时候，region就会等分会两个新的region，之后会有越来越多的region&lt;/li&gt;
  &lt;li&gt;Region是Hbase中分布式存储和负载均衡的最小单元，不同Region分布到不同RegionServer上&lt;/li&gt;
&lt;/ul&gt;

&lt;center&gt;&lt;img src=&quot;/assets/images/post/2017-12-20-hbase-construction-theory/hbase-table-region.png&quot; width=&quot;500px&quot; /&gt;&lt;/center&gt;

&lt;ul&gt;
  &lt;li&gt;Region虽然是分布式存储的最小单元，但并不是存储的最小单元。Region由一个或者多个Store组成，每个store保存一个columns family；每个Strore又由一个memStore和0至多个StoreFile(基于Hfile实现)组成；memStore存储在内存中，StoreFile存储在HDFS上。&lt;/li&gt;
&lt;/ul&gt;

&lt;center&gt;&lt;img src=&quot;/assets/images/post/2017-12-20-hbase-construction-theory/hbase-region-store.png&quot; width=&quot;500px&quot; /&gt;&lt;/center&gt;

&lt;h3 id=&quot;heading-hbase架构以及基本组件&quot;&gt;HBASE架构以及基本组件&lt;/h3&gt;

&lt;center&gt;&lt;img src=&quot;/assets/images/post/2017-12-20-hbase-construction-theory/hbase-construction.jpg&quot; width=&quot;500px&quot; /&gt;&lt;/center&gt;

&lt;ul&gt;
  &lt;li&gt;&lt;strong&gt;Client&lt;/strong&gt;:包含访问HBase的接口，并维护cache来加快对HBase的访问(比如region的位置信息)；使用HBase RPC机制与HMaster和HRegionServer进行通信，Client与HMaster进行通信进行管理类操作，Client与HRegionServer进行数据读写类操作&lt;/li&gt;
  &lt;li&gt;&lt;strong&gt;Master&lt;/strong&gt;
    &lt;ul&gt;
      &lt;li&gt;为Region server分配region&lt;/li&gt;
      &lt;li&gt;负责Region server的负载均衡&lt;/li&gt;
      &lt;li&gt;发现失效的Region server并重新分配其上的region&lt;/li&gt;
      &lt;li&gt;管理用户对table的增删改查操作&lt;/li&gt;
    &lt;/ul&gt;
  &lt;/li&gt;
  &lt;li&gt;&lt;strong&gt;Region Server&lt;/strong&gt;
    &lt;ul&gt;
      &lt;li&gt;Regionserver维护region，处理对这些region的IO请求&lt;/li&gt;
      &lt;li&gt;Regionserver负责切分在运行过程中变得过大的region&lt;/li&gt;
    &lt;/ul&gt;
  &lt;/li&gt;
  &lt;li&gt;&lt;strong&gt;Zookeeper&lt;/strong&gt;
    &lt;ul&gt;
      &lt;li&gt;通过选举，保证任何时候，集群中只有一个master，Master与RegionServers启动时会向ZooKeeper注册（避免master单点问题）&lt;/li&gt;
      &lt;li&gt;存贮所有Region的寻址入口&lt;/li&gt;
      &lt;li&gt;实时监控Region server的上线和下线信息。并实时通知给Master&lt;/li&gt;
      &lt;li&gt;存储HBase的schema和table元数据&lt;/li&gt;
      &lt;li&gt;默认情况下，HBase 管理ZooKeeper 实例，比如， 启动或者停止ZooKeeper&lt;/li&gt;
    &lt;/ul&gt;
  &lt;/li&gt;
&lt;/ul&gt;

&lt;center&gt;&lt;img src=&quot;/assets/images/post/2017-12-20-hbase-construction-theory/hbase-master-regionserver.png&quot; width=&quot;500px&quot; /&gt;&lt;/center&gt;

&lt;h2 id=&quot;heading-hbase写入过程&quot;&gt;HBASE写入过程&lt;/h2&gt;

&lt;p&gt;Client写入 -&amp;gt; 存入MemStore，一直到MemStore满 -&amp;gt; Flush成一个StoreFile，直至增长到一定阈值 -&amp;gt; 触发Compact合并操作 -&amp;gt; 多个StoreFile合并成一个StoreFile，同时进行版本合并和数据删除 -&amp;gt; 当StoreFiles Compact后，逐步形成越来越大的StoreFile -&amp;gt; 单个StoreFile大小超过一定阈值后，触发Split操作，把当前Region Split成2个Region，Region会下线，新Split出的2个孩子Region会被HMaster分配到相应的HRegionServer上，使得原先1个Region的压力得以分流到2个Region上
由此过程可知，HBase只是增加数据，有所得更新和删除操作，都是在Compact阶段做的，所以，用户写操作只需要进入到内存即可立即返回，从而保证I/O高性能&lt;/p&gt;

&lt;h2 id=&quot;heading-hbase容灾日志恢复&quot;&gt;HBASE容灾(日志恢复)&lt;/h2&gt;

&lt;center&gt;&lt;img src=&quot;/assets/images/post/2017-12-20-hbase-construction-theory/hbase-hlog.png&quot; width=&quot;500px&quot; /&gt;&lt;/center&gt;
&lt;p&gt;每次用户执行写入操作，首先是把Log写入到HLog中，HLog是标准的Hadoop Sequence File，由于Log数据量小，而且是顺序写，速度非常快；同时把数据写入到内存MemStore中，成功后返回给Client，所以对Client来说，HBase写的速度非常快，因为数据只要写入到内存中，就算成功了。接着检查MemStore是否已满，如果满了，就把内存中的MemStore Flush到磁盘上，形成一个新的StoreFile。HLog文件定期会滚动出新的，并删除旧的文件（已持久化到StoreFile中的数据）。当HRegionServer意外终止后，HMaster会通过Zookeeper感知到，HMaster首先会处理遗留的 HLog文件，将其中不同Region的Log数据进行拆分，分别放到相应region的目录下，然后再将失效的region重新分配，领取 到这些region的HRegionServer在Load Region的过程中，会发现有历史HLog需要处理，因此会Replay HLog中的数据到MemStore中，然后flush到StoreFiles，完成数据恢复&lt;/p&gt;

&lt;h2 id=&quot;heading-hbase容错性&quot;&gt;HBASE容错性&lt;/h2&gt;

&lt;ul&gt;
  &lt;li&gt;&lt;strong&gt;master容错&lt;/strong&gt;:Zookeeper重新选择一个新的Master
    &lt;ul&gt;
      &lt;li&gt;无Master过程中，数据读取仍照常进行&lt;/li&gt;
      &lt;li&gt;无master过程中，region切分、负载均衡等无法进行&lt;/li&gt;
    &lt;/ul&gt;
  &lt;/li&gt;
  &lt;li&gt;&lt;strong&gt;regionServer容错&lt;/strong&gt;:定时向Zookeeper汇报心跳，如果一旦时间内未出现心跳，Master将该RegionServer上的Region重新分配到其他RegionServer上，失效服务器上“预写”日志由主服务器进行分割并派送给新的RegionServer&lt;/li&gt;
  &lt;li&gt;&lt;strong&gt;zookeeper容错&lt;/strong&gt;:Zookeeper是一个可靠地服务，一般配置3或5个Zookeeper实例&lt;/li&gt;
&lt;/ul&gt;

&lt;h2 id=&quot;heading-hbase检索和扫描如何找到某条记录对应的regionserver&quot;&gt;HBASE检索和扫描：如何找到某条记录对应的regionServer&lt;/h2&gt;

&lt;p&gt;ROOT与META表
Hbase中有两张特殊表，ROOT和META
META：记录了用户表的Region信息，可以有多个region
ROOT：记录了META表的Region信息，ROOT中只有一个region
Zookeeper中记录了ROOT表的location
客户端访问数据的流程： 
Client -&amp;gt; Zookeeper -&amp;gt; -ROOT- -&amp;gt; .META. -&amp;gt; 用户数据表&lt;/p&gt;</content><author><name>{&quot;name&quot;=&gt;nil, &quot;job_title&quot;=&gt;nil, &quot;location&quot;=&gt;nil, &quot;email&quot;=&gt;nil, &quot;social_links&quot;=&gt;[{&quot;name&quot;=&gt;&quot;facebook&quot;, &quot;url&quot;=&gt;nil}, {&quot;name&quot;=&gt;&quot;github&quot;, &quot;url&quot;=&gt;&quot;https://github.com/Tobi7&quot;}, {&quot;name&quot;=&gt;&quot;instagram&quot;, &quot;url&quot;=&gt;nil}, {&quot;name&quot;=&gt;&quot;linkedin&quot;, &quot;url&quot;=&gt;nil}, {&quot;name&quot;=&gt;&quot;stackoverflow&quot;, &quot;url&quot;=&gt;nil}, {&quot;name&quot;=&gt;&quot;twitter&quot;, &quot;url&quot;=&gt;nil}, {&quot;name&quot;=&gt;&quot;vk&quot;, &quot;url&quot;=&gt;nil}]}</name></author><category term="hbase" /><summary type="html">HBASE是一个构建在HDFS上的分布式列存储系统，比较起传统的关系型数据库的优点在于，可以实现高性能的并发读写操作。同时HBase不同于传统关系型数据库的面向行存储，HBase是面向列存储，列可以动态增加，列为空就不存储数据，能更好的节省存储空间。Hbase还会对数据进行透明切分，使得存储本身具有了水平伸缩性</summary></entry><entry><title type="html">HDFS分布式文件系统</title><link href="http://localhost:4000/blog/2017/12/05/hdfs-theory/" rel="alternate" type="text/html" title="HDFS分布式文件系统" /><published>2017-12-05T00:00:00+08:00</published><updated>2017-12-05T00:00:00+08:00</updated><id>http://localhost:4000/blog/2017/12/05/hdfs-theory</id><content type="html" xml:base="http://localhost:4000/blog/2017/12/05/hdfs-theory/">&lt;h2 id=&quot;heading-hdfs设计理念&quot;&gt;HDFS设计理念&lt;/h2&gt;

&lt;p&gt;Hadoop分布式文件系统(HDFS)被设计成适合运行在通用硬件上的分布式文件系统，HDFS是一个高度容错性的系统，适合部署在廉价的机器上。HDFS能提供高吞吐量的数据访问，非常适合大规模数据集上的应用。&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;&lt;b&gt;存储超大文件:&lt;/b&gt;运行在HDFS上的应用具有很大的数据集。HDFS上的一个典型文件大小一般都在G字节至T字节。因此，HDFS被调节以支持大文件存储。它能提供整体上高的数据传输带宽，能在一个集群里扩展到数百个节点。一个单一的HDFS实例应该能支撑数以千万计的文件。&lt;/li&gt;
  &lt;li&gt;&lt;b&gt;一次写入、多次读取:&lt;/b&gt;HDFS存储的数据集作为hadoop的分析对象。在数据集生成后，长时间在此数据集上进行各种分析。每次分析都将设计该数据集的大部分数据甚至全部数据，比之数据访问的低延迟问题，更关键的在于数据访问的高吞吐量，因此读取整个数据集的时间延迟比读取第一条记录的时间延迟更重要。&lt;/li&gt;
  &lt;li&gt;&lt;b&gt;运行在普通廉价的服务器上:&lt;/b&gt;HDFS设计理念之一就是让它能运行在普通的硬件之上，即便硬件出现故障，也可以通过容错策略(错误检测和快速、自动的恢复)来保证数据的高可用。&lt;/li&gt;
&lt;/ul&gt;

&lt;h2 id=&quot;heading-hdfs基本概念&quot;&gt;HDFS基本概念&lt;/h2&gt;
&lt;p&gt;HDFS暴露了文件系统的名字空间，用户能够以文件的形式在上面存储数据。从内部看，一个文件其实被分成一个或多个数据块，这些块存储在一组Datanode上。Namenode执行文件系统的名字空间操作，比如打开、关闭、重命名文件或目录。它也负责确定数据块到具体Datanode节点的映射。Datanode负责处理文件系统客户端的读写请求。在Namenode的统一调度下进行数据块的创建、删除和复制&lt;/p&gt;
&lt;ul&gt;
  &lt;li&gt;&lt;b&gt;数据块(block):&lt;/b&gt;大文件会被分割成多个block进行存储，block大小默认为64MB。每一个block会在多个datanode上存储多份副本，默认是3份。&lt;/li&gt;
  &lt;li&gt;&lt;b&gt;namenode:&lt;/b&gt;namenode是一个中心服务器，负责管理文件目录、文件和block的对应关系以及block和datanode的对应关系。&lt;/li&gt;
  &lt;li&gt;&lt;b&gt;datanode:&lt;/b&gt;datanode就负责存储了，当然大部分容错机制都是在datanode上实现的。&lt;/li&gt;
&lt;/ul&gt;

&lt;h2 id=&quot;heading-hdfs基本架构图&quot;&gt;HDFS基本架构图&lt;/h2&gt;
&lt;center&gt;&lt;img src=&quot;/assets/images/post/2017-12-05-hdfs-theory/hdfs-construction.png&quot; width=&quot;500px&quot; /&gt;&lt;/center&gt;
&lt;p&gt;Rack 是指机架的意思，一个block的三个副本通常会保存到两个或者两个以上的机柜中（当然是机柜中的服务器），这样做的目的是做防灾容错。&lt;/p&gt;

&lt;p&gt;每个Datanode节点周期性地向Namenode发送心跳信号。网络割裂可能导致一部分Datanode跟Namenode失去联系。Namenode通过心跳信号的缺失来检测这一情况，并将这些近期不再发送心跳信号Datanode标记为宕机，不会再将新的IO请求发给它们。任何存储在宕机Datanode上的数据将不再有效。Datanode的宕机可能会引起一些数据块的副本系数低于指定值，Namenode不断地检测这些需要复制的数据块，一旦发现就启动复制操作。在下列情况下，可能需要重新复制：某个Datanode节点失效，某个副本遭到损坏，Datanode上的硬盘错误，或者文件的副本系数增大。&lt;/p&gt;

&lt;h2 id=&quot;heading-hdfs写文件流程&quot;&gt;HDFS写文件流程&lt;/h2&gt;
&lt;center&gt;&lt;img src=&quot;/assets/images/post/2017-12-05-hdfs-theory/hdfs-write.png&quot; width=&quot;500px&quot; /&gt;&lt;/center&gt;

&lt;p&gt;当客户端向HDFS文件写入数据的时候，一开始是写到本地临时文件中。假设该文件的副本系数设置为3，当本地临时文件累积到一个数据块的大小时，客户端会从Namenode获取一个Datanode列表用于存放副本。然后客户端开始向第一个Datanode传输数据，第一个Datanode一小部分一小部分(4 KB)地接收数据，将每一部分写入本地仓库，并同时传输该部分到列表中第二个Datanode节点。第二个Datanode也是这样，一小部分一小部分地接收数据，写入本地仓库，并同时传给第三个Datanode。最后，第三个Datanode接收数据并存储在本地。因此，Datanode能流水线式地从前一个节点接收数据，并在同时转发给下一个节点，数据以流水线的方式从前一个Datanode复制到下一个。
【ps】另一种数据写入的方式是采用多路写，也就是同时别写入到三个Datanode里面。管道写需要时间去完成，所以它有很高的延迟，但是它能更好地利用网络带宽；多路写有着比较低的延迟，因为客户端只需要等待最慢的DataNode确认（假设其余都已成功确认）。但是写入需要共享发送服务器的网络带宽，这对于有着很高负载的系统来说是一个瓶颈。&lt;/p&gt;

&lt;h2 id=&quot;heading-hdfs读文件流程&quot;&gt;HDFS读文件流程&lt;/h2&gt;
&lt;center&gt;&lt;img src=&quot;/assets/images/post/2017-12-05-hdfs-theory/hdfs-read.png&quot; width=&quot;500px&quot; /&gt;&lt;/center&gt;</content><author><name>{&quot;name&quot;=&gt;nil, &quot;job_title&quot;=&gt;nil, &quot;location&quot;=&gt;nil, &quot;email&quot;=&gt;nil, &quot;social_links&quot;=&gt;[{&quot;name&quot;=&gt;&quot;facebook&quot;, &quot;url&quot;=&gt;nil}, {&quot;name&quot;=&gt;&quot;github&quot;, &quot;url&quot;=&gt;&quot;https://github.com/Tobi7&quot;}, {&quot;name&quot;=&gt;&quot;instagram&quot;, &quot;url&quot;=&gt;nil}, {&quot;name&quot;=&gt;&quot;linkedin&quot;, &quot;url&quot;=&gt;nil}, {&quot;name&quot;=&gt;&quot;stackoverflow&quot;, &quot;url&quot;=&gt;nil}, {&quot;name&quot;=&gt;&quot;twitter&quot;, &quot;url&quot;=&gt;nil}, {&quot;name&quot;=&gt;&quot;vk&quot;, &quot;url&quot;=&gt;nil}]}</name></author><category term="hdfs" /><summary type="html">HDFS设计理念</summary></entry><entry><title type="html">Spring AOP代理</title><link href="http://localhost:4000/blog/2017/06/29/spring-aop-proxy/" rel="alternate" type="text/html" title="Spring AOP代理" /><published>2017-06-29T00:00:00+08:00</published><updated>2017-06-29T00:00:00+08:00</updated><id>http://localhost:4000/blog/2017/06/29/spring-aop-proxy</id><content type="html" xml:base="http://localhost:4000/blog/2017/06/29/spring-aop-proxy/">&lt;h2 id=&quot;heading-一spring-aop代理的相关属性&quot;&gt;一、Spring AOP代理的相关属性&lt;/h2&gt;

&lt;ul&gt;
  &lt;li&gt;开启AOP自动代理&lt;/li&gt;
&lt;/ul&gt;

&lt;div class=&quot;highlighter-rouge&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;&amp;lt;aop:aspect-autoproxy /&amp;gt;
&lt;/code&gt;&lt;/pre&gt;
&lt;/div&gt;

&lt;ul&gt;
  &lt;li&gt;proxy-target-class:强调spring应该使用那种代理方式：JDK动态代理和CGLIB
    &lt;ul&gt;
      &lt;li&gt;JDK动态代理：代理对象必须为某个接口的实现，它是通过在运行期间创建一个接口的实现类来完成对目标对象的代理【默认属性值为false，即使用的是JDK动态代理】&lt;/li&gt;
      &lt;li&gt;CGLIB代理：原理类似于JDK代理，不同之处在于运行期间生成的代理对象是针对目标类扩展的子类，CGLIB是高效代码生成包，底层是依靠ASM（字节码编辑类库）操作字节码实现的，性能比JDK强。&lt;/li&gt;
      &lt;li&gt;使用CGLIB代理会出现的问题:无法通知Final方法，因为他们不允许被覆盖；还需要将CGLIB二进制包放入classpath下面；强制使用CGLIB代理需要将proxy-target-class设置为true&lt;/li&gt;
    &lt;/ul&gt;
  &lt;/li&gt;
  &lt;li&gt;expose-proxy:目标对象内部的自我调用将无法实施切面中的增强&lt;/li&gt;
&lt;/ul&gt;

&lt;h2 id=&quot;heading-二aop代理无法切入同类调用方法的问题&quot;&gt;二、AOP代理无法切入同类调用方法的问题&lt;/h2&gt;

&lt;div class=&quot;highlighter-rouge&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;@Service
public class Service {  
  
    //这个方法调用被切的方法,在外部被调用 
    public void callMethodA() {  
        ......  
        callMethodB();  
        ......  
    }  
      
    //Aop切入的方法 
    public void callMethodB() {  
        ......  
    }  
} 

@Aspect
@Service
public class Aspect {
    @After(&quot;execution(* Service.callMethodB(..))&quot;)  
    public void after() {  
        Logger.info(&quot;after call and do something.&quot;);
    }  
}  

//调用方式
service.callMethodA();

//spring配置
&amp;lt;aop:aspect-autoproxy proxy-target-class=&quot;true&quot;/&amp;gt;
&lt;/code&gt;&lt;/pre&gt;
&lt;/div&gt;

&lt;p&gt;上述的调用方式是根本无法进去切面的，在callMethodA()方法中调用callMethodB()相当于调用this.callMethodB()，此处的this指向目标对象，并不是调用代理对象的callMethodB()方法，解决方式如下两点&lt;/p&gt;
&lt;ul&gt;
  &lt;li&gt;强制使用AOP代理&lt;/li&gt;
&lt;/ul&gt;

&lt;div class=&quot;highlighter-rouge&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;//spring配置
&amp;lt;aop:aspectj-autoproxy proxy-target-class=&quot;true&quot; expose-proxy=&quot;true&quot; /&amp;gt;

//调用callMethodB()
((Service)AopContext.currentProxy()).callMethodB();
&lt;/code&gt;&lt;/pre&gt;
&lt;/div&gt;

&lt;ul&gt;
  &lt;li&gt;通过spring上下文获取代理类&lt;/li&gt;
&lt;/ul&gt;

&lt;div class=&quot;highlighter-rouge&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;//spring配置
&amp;lt;aop:aspectj-autoproxy proxy-target-class=&quot;true&quot;/&amp;gt;

//调用callMethodB()
applicationContext.getBean(&quot;service&quot;).callMethodB();
&lt;/code&gt;&lt;/pre&gt;
&lt;/div&gt;

&lt;p&gt;PS:使用第一种方式的时候要注意获取代理对象时的强制转换:使用默认的JDK动态代理的方式需要转换为接口，使用CGLIB代理的方式可以直接使用实现类的类型；同时代理对象使用的方法需要是public修饰的方法；spring自带的@transactional注解在使用中也有上述问题，该注解默认使用CGLIB代理。&lt;/p&gt;</content><author><name>{&quot;name&quot;=&gt;nil, &quot;job_title&quot;=&gt;nil, &quot;location&quot;=&gt;nil, &quot;email&quot;=&gt;nil, &quot;social_links&quot;=&gt;[{&quot;name&quot;=&gt;&quot;facebook&quot;, &quot;url&quot;=&gt;nil}, {&quot;name&quot;=&gt;&quot;github&quot;, &quot;url&quot;=&gt;&quot;https://github.com/Tobi7&quot;}, {&quot;name&quot;=&gt;&quot;instagram&quot;, &quot;url&quot;=&gt;nil}, {&quot;name&quot;=&gt;&quot;linkedin&quot;, &quot;url&quot;=&gt;nil}, {&quot;name&quot;=&gt;&quot;stackoverflow&quot;, &quot;url&quot;=&gt;nil}, {&quot;name&quot;=&gt;&quot;twitter&quot;, &quot;url&quot;=&gt;nil}, {&quot;name&quot;=&gt;&quot;vk&quot;, &quot;url&quot;=&gt;nil}]}</name></author><category term="aop" /><summary type="html">一、Spring AOP代理的相关属性</summary></entry><entry><title type="html">数据库主从复制</title><link href="http://localhost:4000/blog/2017/05/15/database-master-slave-syn/" rel="alternate" type="text/html" title="数据库主从复制" /><published>2017-05-15T00:00:00+08:00</published><updated>2017-05-15T00:00:00+08:00</updated><id>http://localhost:4000/blog/2017/05/15/database-master-slave-syn</id><content type="html" xml:base="http://localhost:4000/blog/2017/05/15/database-master-slave-syn/">&lt;p&gt;复制过程中一个服务器充当主服务器，而一个或多个其它服务器充当从服务器。&lt;/p&gt;

&lt;h2 id=&quot;heading-一异步复制&quot;&gt;一、异步复制&lt;/h2&gt;
&lt;ul&gt;
  &lt;li&gt;MySQL的异步复制是MySQL自带的数据同步功能，在公司里面也是也就最为常见的。&lt;/li&gt;
  &lt;li&gt;Master服务器中需要开启二进制日志 binlog ，从服务器需要开启中继日志 relay-log 。&lt;/li&gt;
  &lt;li&gt;二进制日志binlog的主要功能是：记录数据库的变更内容；二进制日志在备份还原的时候至关重要。&lt;/li&gt;
  &lt;li&gt;中继日志relay-log则是从服务器中开启，作用是从主服务器的二进制日志中复制，并在在从服务器本地执行一次，达到与主服务器内容一致的效果。&lt;/li&gt;
  &lt;li&gt;一般MySQL复制是放在内网中进行的，因为MySQL的同步并没有进行加密。而且相比较于在公网传输，在内网中丢包的概率较低，带宽也高。&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;&lt;strong&gt;复制过程：&lt;/strong&gt;&lt;/p&gt;
&lt;ol&gt;
  &lt;li&gt;该过程的第一部分就是master记录二进制日志。在每个事务更新数据完成之前，master在二进制日志中记录这些改变。MySQL将事务串行的写入二进制日志，即使事务中的语句都是交叉执行的。在事件写入二进制日志完成后，master通知存储引擎提交事务。&lt;/li&gt;
  &lt;li&gt;下一步就是slave将master的binary log拷贝到它自己的中继日志。首先，slave开始一个工作线程——I/O线程。I/O线程在master上打开一个普通的连接，然后开始binlog dump process（根据从服务器在日志中读取的最后一次成功更新的位置）。Binlog dump process从master的二进制日志中读取事件，如果已经跟上master，它会睡眠并等待master产生新的事件。I/O线程将这些事件写入中继日志。&lt;/li&gt;
  &lt;li&gt;SQL slave thread（SQL从线程）处理该过程的最后一步。SQL线程从中继日志读取事件，并重放其中的事件而更新slave的数据，使其与master中的数据一致。只要该线程与I/O线程保持一致，中继日志通常会位于OS的缓存中，所以中继日志的开销很小。&lt;/li&gt;
&lt;/ol&gt;

&lt;p&gt;此外，在master中也有一个工作线程（I/O线程）：和其它MySQL的连接一样，slave在master中打开一个连接也会使得master开始一个线程。复制过程有一个很重要的限制——复制在slave上是串行化的，也就是说master上的并行更新操作不能在slave上并行操作。&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;/assets/images/post/2017-05-15-database-master-slave-sync/master-slave-sync.png&quot; alt=&quot;master-slave-sync.png&quot; /&gt;&lt;/p&gt;

&lt;h2 id=&quot;heading-二半同步复制&quot;&gt;二、半同步复制&lt;/h2&gt;
&lt;ul&gt;
  &lt;li&gt;与传统的异步复制相比，半同步复制在多个Slave节点中会选取一个节点进行半同步复制。也就是说，当Master提交一个事务的时候，在这个半同步复制的Slave端返回一个同步完成的Ack包之后，服务器才会向用户返回事务提交成功，而其他的节点则是采用传统的异步复制方式进行同步。&lt;/li&gt;
  &lt;li&gt;半同步是复制是基于异步复制之上进行的，也就是说配置半同步复制之前需要先配置到异步复制。&lt;/li&gt;
  &lt;li&gt;半同步复制可以保证在主节点发生故障的时候，总有一个节点的数据与主节点一样。这样在进行切换的时候，可以更加快速地把这个Slave节点设置成主节点来使用。&lt;/li&gt;
&lt;/ul&gt;

&lt;h2 id=&quot;heading-三binlog-格式&quot;&gt;三、binlog 格式&lt;/h2&gt;

&lt;h3 id=&quot;heading-statement每一条会修改数据的sql都会记录在binlog中&quot;&gt;statement:每一条会修改数据的sql都会记录在binlog中&lt;/h3&gt;

&lt;ul&gt;
  &lt;li&gt;
    &lt;p&gt;优点：不需要记录每一行的变化，减少了binlog日志量，节约了IO，提高性能。(相比row能节约多少性能与日志量，这个取决于应用的SQL情况，正常同一条记录修改或者插入row格式所产生的日志量还小于Statement产生的日志量，但是考虑到如果带条件的update操作，以及整表删除，alter表等操作，ROW格式会产生大量日志，因此在考虑是否使用ROW格式日志时应该跟据应用的实际情况，其所产生的日志量会增加多少，以及带来的IO性能问题。)&lt;/p&gt;
  &lt;/li&gt;
  &lt;li&gt;
    &lt;p&gt;缺点：由于记录的只是执行语句，为了这些语句能在slave上正确运行，因此还必须记录每条语句在执行的时候的一些相关信息(时间等)，以保证所有语句能在slave得到和在master端执行时候相同的结果。&lt;/p&gt;
  &lt;/li&gt;
&lt;/ul&gt;

&lt;h3 id=&quot;heading-row不记录sql语句上下文相关信息仅保存哪条记录被修改&quot;&gt;Row:不记录sql语句上下文相关信息，仅保存哪条记录被修改&lt;/h3&gt;

&lt;ul&gt;
  &lt;li&gt;
    &lt;p&gt;优点：binlog中可以不记录执行的sql语句的上下文相关的信息，仅需要记录那一条记录被修改成什么了。所以rowlevel的日志内容会非常清楚的记录下每一行数据修改的细节。而且不会出现某些特定情况下的存储过程，或function，以及trigger的调用和触发无法被正确复制的问题&lt;/p&gt;
  &lt;/li&gt;
  &lt;li&gt;
    &lt;p&gt;缺点：所有的执行的语句当记录到日志中的时候，都将以每行记录的修改来记录，这样可能会产生大量的日志内容,比如一条update语句，修改多条记录，则binlog中每一条修改都会有记录，这样造成binlog日志量会很大，特别是当执行alter table之类的语句的时候，由于表结构修改，每条记录都发生改变，那么该表每一条记录都会记录到日志中。&lt;/p&gt;
  &lt;/li&gt;
&lt;/ul&gt;

&lt;h3 id=&quot;heading-mixedlevel-是以上两种level的混合使用&quot;&gt;Mixedlevel: 是以上两种level的混合使用。&lt;/h3&gt;

&lt;ul&gt;
  &lt;li&gt;一般的语句修改使用statment格式保存binlog，如一些函数，statement无法完成主从复制的操作，则采用row格式保存binlog,MySQL会根据执行的每一条具体的sql语句来区分对待记录的日志形式，也就是在Statement和Row之间选择一种.新版本的MySQL中队row level模式也被做了优化，并不是所有的修改都会以row level来记录，像遇到表结构变更的时候就会以statement模式来记录。至于update或者delete等修改数据的语句，还是会记录所有行的变更。&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;注：所以当数据库在采取异步复制的同步策略时，如果当binlog的格式是Row的情况下存在【在主库更新十条记录之后，从库只更新了5条】的情况&lt;/p&gt;</content><author><name>{&quot;name&quot;=&gt;nil, &quot;job_title&quot;=&gt;nil, &quot;location&quot;=&gt;nil, &quot;email&quot;=&gt;nil, &quot;social_links&quot;=&gt;[{&quot;name&quot;=&gt;&quot;facebook&quot;, &quot;url&quot;=&gt;nil}, {&quot;name&quot;=&gt;&quot;github&quot;, &quot;url&quot;=&gt;&quot;https://github.com/Tobi7&quot;}, {&quot;name&quot;=&gt;&quot;instagram&quot;, &quot;url&quot;=&gt;nil}, {&quot;name&quot;=&gt;&quot;linkedin&quot;, &quot;url&quot;=&gt;nil}, {&quot;name&quot;=&gt;&quot;stackoverflow&quot;, &quot;url&quot;=&gt;nil}, {&quot;name&quot;=&gt;&quot;twitter&quot;, &quot;url&quot;=&gt;nil}, {&quot;name&quot;=&gt;&quot;vk&quot;, &quot;url&quot;=&gt;nil}]}</name></author><category term="mysql" /><summary type="html">复制过程中一个服务器充当主服务器，而一个或多个其它服务器充当从服务器。</summary></entry><entry><title type="html">数据库锁机制</title><link href="http://localhost:4000/blog/2017/03/29/database-lock-mechanism/" rel="alternate" type="text/html" title="数据库锁机制" /><published>2017-03-29T00:00:00+08:00</published><updated>2017-03-29T00:00:00+08:00</updated><id>http://localhost:4000/blog/2017/03/29/database-lock-mechanism</id><content type="html" xml:base="http://localhost:4000/blog/2017/03/29/database-lock-mechanism/">&lt;h1 id=&quot;heading-数据库锁机制&quot;&gt;数据库锁机制&lt;/h1&gt;

&lt;h2 id=&quot;heading-为什么需要锁&quot;&gt;为什么需要锁&lt;/h2&gt;

&lt;ul&gt;
  &lt;li&gt;死锁问题&lt;/li&gt;
  &lt;li&gt;并发问题导致的不正确数据的读取和存储，破坏数据一致性
    &lt;ol&gt;
      &lt;li&gt;丢失更新：当两个或多个事务选择同一行，然后基于最初选定的值更新该行时，由于每个事务都不知道其他事务的存在，就会发生丢失更新问题－－最后的更新覆盖了由其他事务所做的更新。例如，两个编辑人员制作了同一文档的电子副本。每个编辑人员独立地更改其副本，然后保存更改后的副本，这样就覆盖了原始文档。最后保存其更改副本的编辑人员覆盖另一个编辑人员所做的更改。如果在一个编辑人员完成并提交事务之前，另一个编辑人员不能访问同一文件，则可避免此问题&lt;/li&gt;
      &lt;li&gt;脏读：一个事务正在对一条记录做修改，在这个事务完成并提交前，这条记录的数据就处于不一致状态；这时，另一个事务也来读取同一条记录，如果不加控制，第二个事务读取了这些“脏”数据，并据此做进一步的处理，就会产生未提交的数据依赖关系。这种现象被形象地叫做&quot;脏读&quot;。&lt;/li&gt;
      &lt;li&gt;不可重复读：一个事务在读取某些数据后的某个时间，再次读取以前读过的数据，却发现其读出的数据已经发生了改变、或某些记录已经被删除了！这种现象就叫做“不可重复读”。&lt;/li&gt;
      &lt;li&gt;幻读：一个事务按相同的查询条件重新读取以前检索过的数据，却发现其他事务插入了满足其查询条件的新数据，这种现象就称为“幻读”。&lt;/li&gt;
    &lt;/ol&gt;
  &lt;/li&gt;
&lt;/ul&gt;

&lt;h2 id=&quot;heading-锁的分类&quot;&gt;锁的分类&lt;/h2&gt;

&lt;h3 id=&quot;heading-数据库维度&quot;&gt;数据库维度&lt;/h3&gt;

&lt;ul&gt;
  &lt;li&gt;共享锁:&lt;br /&gt;
用于不更改或不更新数据的操作（只读操作）。共享锁允许并发事务读取同一个资源，数据资源上存在共享锁时，任何其他事务不允许修改数据&lt;/li&gt;
  &lt;li&gt;排它锁:&lt;br /&gt;
用于数据修改，确保不会同时多重更新同一数据。资源上存在排他锁时，其他任何事务不允许给资源上锁，当资源上有其他锁时，也无法对其加上排它锁&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;PS：只有共享锁与共享锁相互兼容，共享锁与排它锁、排它锁之间都互不兼容&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;
    &lt;p&gt;意向锁&lt;/p&gt;
  &lt;/li&gt;
  &lt;li&gt;
    &lt;p&gt;更新锁&lt;/p&gt;
    &lt;ol&gt;
      &lt;li&gt;用于可更新的资源中，防止多个会话在读取、锁定以及随后可能进行的资源更新时发生的死锁问题。&lt;/li&gt;
      &lt;li&gt;通常形式的死锁：一般一个更新模式由一个事务组成，此事务读取记录，获取资源的共享锁，然后修改行，此操作要求锁转换为排它锁。如果两个事务同时获得了资源上的共享锁，然后试图同时更新数据，则一个事务尝试将锁转换为排它锁。由于一个事务的排它锁与另一事务的共享锁的不兼容，从共享锁到排它锁的转换必须要等待一段时间，发送锁等待。而第二个事务同时也试图获取排它锁进行更新。由于两个事务都要转化为排它锁，并且每个事务都要等待另一个事务释放掉共享锁，因此发生死锁&lt;/li&gt;
      &lt;li&gt;更新锁一次只有一个事务可以获取资源的更新锁。如果事务修改资源，那么更新锁转化为排它锁，否则转化为共享锁。当资源上存在更新锁时，允许资源被读取（即更新锁与共享锁兼容），但不允许资源被修改&lt;/li&gt;
      &lt;li&gt;一般来说，在执行UPDATE操作时，SQL SERVER会使用到更新锁而不是依次加上共享锁和排它锁，已经回避了这种通常形式的死锁，更新锁与意向锁相互兼容&lt;/li&gt;
    &lt;/ol&gt;
  &lt;/li&gt;
&lt;/ul&gt;

&lt;h3 id=&quot;heading-锁机制&quot;&gt;锁机制&lt;/h3&gt;

&lt;table&gt;
  &lt;thead&gt;
    &lt;tr&gt;
      &lt;th&gt;DBMS&lt;/th&gt;
      &lt;th&gt;SELECT&lt;/th&gt;
      &lt;th&gt;UPDATE&lt;/th&gt;
      &lt;th&gt;INSERT&lt;/th&gt;
      &lt;th&gt;DELETE&lt;/th&gt;
    &lt;/tr&gt;
  &lt;/thead&gt;
  &lt;tbody&gt;
    &lt;tr&gt;
      &lt;td&gt;MySQL(InnoDB)&lt;/td&gt;
      &lt;td&gt;不加锁&lt;/td&gt;
      &lt;td&gt;排它锁&lt;/td&gt;
      &lt;td&gt;排它锁&lt;/td&gt;
      &lt;td&gt;排它锁&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td&gt;SQL SERVER&lt;/td&gt;
      &lt;td&gt;共享锁&lt;/td&gt;
      &lt;td&gt;更新锁&lt;/td&gt;
      &lt;td&gt;排它锁&lt;/td&gt;
      &lt;td&gt;排它锁&lt;/td&gt;
    &lt;/tr&gt;
  &lt;/tbody&gt;
&lt;/table&gt;

&lt;p&gt;这两种锁机制的区别在于MySQL的查询与更新操作互相不阻塞；而SQL SERVER的更新锁转化成排它锁之前，其查询与更新操作互相不阻塞，当更新锁要转化为排它锁时，需要等待共享锁的释放，当更新锁转化为排它锁后，查询数据需要等待排它锁的释放。&lt;/p&gt;

&lt;p&gt;参考：&lt;br /&gt;
&lt;a href=&quot;http://blog.csdn.net/samjustin1/article/details/52210125&quot;&gt;数据库锁机制&lt;/a&gt;&lt;br /&gt;
&lt;a href=&quot;http://blog.chinaunix.net/uid-24111901-id-2627857.html&quot;&gt;InnoDB锁机制&lt;/a&gt;&lt;br /&gt;
&lt;a href=&quot;http://blog.itpub.net/13651903/viewspace-1091664/&quot;&gt;SQL SERVER锁机制&lt;/a&gt;&lt;/p&gt;

&lt;h3 id=&quot;heading-程序员思想维度&quot;&gt;程序员思想维度&lt;/h3&gt;
&lt;ul&gt;
  &lt;li&gt;悲观锁
    &lt;ol&gt;
      &lt;li&gt;悲观并发控制（又名“悲观锁”，Pessimistic Concurrency Control，缩写“PCC”）是一种并发控制的方法。它可以阻止一个事务以影响其他用户的方式来修改数据。如果一个事务执行的操作都某行数据应用了锁，那只有当这个事务把锁释放，其他事务才能够执行与该锁冲突的操作。悲观锁的实现，往往依靠数据库提供的锁机制。悲观并发控制主要用于数据争用激烈的环境，以及发生并发冲突时使用锁保护数据的成本要低于回滚事务的成本的环境中。&lt;/li&gt;
      &lt;li&gt;悲观并发控制实际上是“先取锁再访问”的保守策略，为数据处理的安全提供了保证。但是在效率方面，处理加锁的机制会让数据库产生额外的开销，还有增加产生死锁的机会；另外，在只读型事务处理中由于不会产生冲突，也没必要使用锁，这样做只能增加系统负载；还有会降低了并行性，一个事务如果锁定了某行数据，其他事务就必须等待该事务处理完才可以处理那行数&lt;/li&gt;
    &lt;/ol&gt;
  &lt;/li&gt;
  &lt;li&gt;乐观锁
    &lt;ol&gt;
      &lt;li&gt;乐观并发控制（又名“乐观锁”，Optimistic Concurrency Control，缩写“OCC”）是一种并发控制的方法。它假设多用户并发的事务在处理时不会彼此互相影响，各事务能够在不产生锁的情况下处理各自影响的那部分数据。在提交数据更新之前，每个事务会先检查在该事务读取数据后，有没有其他事务又修改了该数据。如果其他事务有更新的话，正在提交的事务会进行回滚。&lt;/li&gt;
      &lt;li&gt;乐观并发控制相信事务之间的数据竞争(data race)的概率是比较小的，因此尽可能直接做下去，直到提交的时候才去锁定，所以不会主动产生任何锁和死锁。但是在并发量高的情况下，可能导致某次数据修改多次重试，影响单次成功操作的时间。&lt;/li&gt;
      &lt;li&gt;数据版本实现乐观锁：实现数据版本有两种方式，第一种是使用版本号，第二种是使用时间戳。使用版本号时，可以在数据初始化时指定一个版本号，每次对数据的更新操作都对版本号执行+1操作。并判断当前版本号是不是该数据的最新的版本号。
        &lt;div class=&quot;highlighter-rouge&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;update table 
set date=1,version=version+1
where id=#{id} and version=#{version};
&lt;/code&gt;&lt;/pre&gt;
        &lt;/div&gt;
      &lt;/li&gt;
    &lt;/ol&gt;
  &lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;参考：&lt;br /&gt;
&lt;a href=&quot;http://www.open-open.com/lib/view/open1452046967245.html&quot;&gt;乐观锁与悲观锁&lt;/a&gt;&lt;/p&gt;

&lt;h2 id=&quot;heading-乐观锁另一种实现方式cas&quot;&gt;乐观锁另一种实现方式CAS&lt;/h2&gt;

&lt;p&gt;CAS是项乐观锁技术，当多个线程尝试使用CAS同时更新同一个变量时，只有其中一个线程能更新变量的值，而其它线程都失败，失败的线程并不会被挂起，而是被告知这次竞争中失败，并可以再次尝试。&lt;/p&gt;

&lt;p&gt;CAS 操作包含三个操作数 —— 内存位置（V）、预期原值（A）和新值(B)。如果内存位置的值与预期原值相匹配，那么处理器会自动将该位置值更新为新值。否则，处理器不做任何操作。无论哪种情况，它都会在 CAS 指令之前返回该位置的值。CAS 有效地说明了“我认为位置 V 应该包含值 A；如果包含该值，则将 B 放到这个位置；否则，不要更改该位置，只告诉我这个位置现在的值即可。”这其实和乐观锁的冲突检查+数据更新的原理是一样的。&lt;/p&gt;

&lt;p&gt;java.util.concurrent(J.U.C)就是建立在CAS之上的。相对于对于synchronized这种阻塞算法，CAS是非阻塞算法的一种常见实现。所以J.U.C在性能上有了很大的提升。&lt;/p&gt;
&lt;div class=&quot;highlighter-rouge&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;public class AtomicInteger extends Number implements java.io.Serializable {
    private volatile int value;  
 
    public final int get() {  
        return value;  
    }  
 
    public final int getAndIncrement() {  
        for (;;) {  
            int current = get();  
            int next = current + 1;  
            if (compareAndSet(current, next))  
                return current;  
        }  
    }  
 
    public final boolean compareAndSet(int expect, int update) {  
        return unsafe.compareAndSwapInt(this, valueOffset, expect, update);  
    }  
}
&lt;/code&gt;&lt;/pre&gt;
&lt;/div&gt;

&lt;p&gt;参考：&lt;br /&gt;
&lt;a href=&quot;http://www.importnew.com/20472.html&quot;&gt;乐观锁的一种实现方式—CAS&lt;/a&gt;&lt;/p&gt;

&lt;h2 id=&quot;heading-案例1初审统计数据迁移&quot;&gt;案例1：初审统计数据迁移&lt;/h2&gt;

&lt;ul&gt;
  &lt;li&gt;迁移背景&lt;br /&gt;
原有的统计方式采用的是实时count的方法获取统计数据，造成的问题是查询慢且无法获取长时间段的统计数据（sql超时）、无法获取某日统计数据的快照（前一天的待审核数据会变成今天的审核通过数据）&lt;/li&gt;
  &lt;li&gt;采用迁移方式&lt;br /&gt;
使用raptor迁移平台，扫描审核记录表，取出累计统计数据后进行加1操作，然后更新到统计表中。由于平台特性，数据迁移过程具有高并发性，由于强行采用先读取后更新的方式，会造成丢失更新的情况，于是这里考虑采用CAS&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;step 1:&lt;/p&gt;
&lt;div class=&quot;highlighter-rouge&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;select id,passCount,rejectCount,hideCount,warnCount,waitCount 
from book.TradeItemAuditCount 
where type = #{type} and date = #{date} and editor = #{editor} 
and isDeleted = 0 limit 1

&lt;/code&gt;&lt;/pre&gt;
&lt;/div&gt;
&lt;p&gt;step 2:【失败重试】&lt;/p&gt;
&lt;div class=&quot;highlighter-rouge&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;update book.TradeItemAuditCount 
set passCount = #{passCount} , rejectCount = #{rejectCount} , hideCount = #{hideCount} , warnCount = #{warnCount} , waitCount = #{waitCount} , updated = #{updated}
where id = #{id} and passCount = #{oldPassCount} and rejectCount = #{oldRejectCount} and hideCount = #{oldHideCount} and warnCount = #{oldWarnCount} and waitCount = #{oldWaitCount}
and isDeleted = 0 limit 1
&lt;/code&gt;&lt;/pre&gt;
&lt;/div&gt;

&lt;ul&gt;
  &lt;li&gt;处理结果&lt;br /&gt;
一共扫描审核结果4335668条数据，对重试次数超过100的更新操作进行记录，发现更新操作出现大部分的重试，任务本身DB写操作的qps较低【都不需要通过控制台限制速率..】&lt;/li&gt;
&lt;/ul&gt;

&lt;h2 id=&quot;heading-案例2商品库存&quot;&gt;案例2：商品库存&lt;/h2&gt;
&lt;ul&gt;
  &lt;li&gt;商品库存与上述案例1一致，都是对数据记录进行加减操作，发现库存的更新方式如下：
    &lt;div class=&quot;highlighter-rouge&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;update 库存表
set stock=stock-1
where id=#{id}
&lt;/code&gt;&lt;/pre&gt;
    &lt;/div&gt;
  &lt;/li&gt;
  &lt;li&gt;
    &lt;p&gt;直接使用数据库的排它锁就简单的避免了并发导致的丢失更新问题，之前提到的一次只有一个事务拥有资源的排它锁，并发的更新操作都试图占有资源的排它锁，当资源上存在排它锁时，其他更新操作需要等待锁的释放&lt;/p&gt;
  &lt;/li&gt;
  &lt;li&gt;相比案例1的解决方案，案例2的解决方式直接使用了MySQL InnoDB更新操作本身就拥有的排它锁，不需要额外的开销，而案例1不必要的查询操作以及多次的重试操作严重影响到了数据迁移的性能，所以案例1是反面例子..&lt;/li&gt;
&lt;/ul&gt;

&lt;h2 id=&quot;heading-案例3商品打标&quot;&gt;案例3：商品打标&lt;/h2&gt;
&lt;ul&gt;
  &lt;li&gt;随着上打标的qps上涨，出现达标更新数据丢失的情况
    &lt;div class=&quot;highlighter-rouge&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;&lt;span class=&quot;p&quot;&gt;{&lt;/span&gt;&lt;span class=&quot;nt&quot;&gt;&quot;tags&quot;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;:&lt;/span&gt;&lt;span class=&quot;s2&quot;&gt;&quot;16,32,233,22&quot;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt;&lt;span class=&quot;nt&quot;&gt;&quot;itemState&quot;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;:&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;1&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt;&lt;span class=&quot;nt&quot;&gt;&quot;hd&quot;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;:&lt;/span&gt;&lt;span class=&quot;s2&quot;&gt;&quot;ai:4|nd:18&quot;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt;&lt;span class=&quot;nt&quot;&gt;&quot;au&quot;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;:&lt;/span&gt;&lt;span class=&quot;s2&quot;&gt;&quot;baoming&quot;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;}&lt;/span&gt;&lt;span class=&quot;w&quot;&gt;
&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;
    &lt;/div&gt;
  &lt;/li&gt;
  &lt;li&gt;处理方案
    &lt;ol&gt;
      &lt;li&gt;乐观锁：采用CAS
        &lt;div class=&quot;highlighter-rouge&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;update TradeItem
set extra=#{extra}
where tradeItemId=#{tradeItemId} and extra=#{oldExtra}
&lt;/code&gt;&lt;/pre&gt;
        &lt;/div&gt;
        &lt;p&gt;这里使用长字符串做更新条件，会影响到SQL性能？？？&lt;/p&gt;
      &lt;/li&gt;
      &lt;li&gt;乐观锁：采用数据版本 
 表中新增version字段标识数据版本，作为数据更新的检查方式
        &lt;div class=&quot;highlighter-rouge&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;update TradeItem
set extra=#{extra} , version=version+1
where tradeItemId=#{tradeItemId} and version=#{version}
&lt;/code&gt;&lt;/pre&gt;
        &lt;/div&gt;
        &lt;p&gt;此方案改造较大，还需要为表新增字段，而且采用乐观锁拥有这一律的弊端：重试带来的时间代价，一旦并发量上涨，某次更新操作的重试次数也会随之上涨，直接影响到暴露服务的响应时间。【限制重试次数能够一定程度上控制更新操作的响应时间，但是仍然会出现更新丢失的现象（让调用方进行重试操作，分摊单次请求的响应时间？）】&lt;/p&gt;
      &lt;/li&gt;
      &lt;li&gt;悲观锁&lt;br /&gt;
更新丢失的根本原因是执行查询、修改两个操作之间数据被另一事务修改了，单纯的UPDATE操作其实也是进行着先查询后修改的操作，没有产生更新丢失是因为数据上存在排它锁（sql server则是更新锁），在执行期间并不允许其他修改。同理我们将要打标的商品记录加上排它锁或者更新锁就能解决问题。&lt;br /&gt;
MySQL:
        &lt;div class=&quot;highlighter-rouge&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;start transaction;
SELECT extra
FROM TradeItem 
WHERE tradeItemId=#{tradeItemId}
FOR UPDATE;
UPDATE TradeItem 
SET extra = bdo.AddTag(tag,extra)
WHERE tradeItemId=#{tradeItemId};
commit;
&lt;/code&gt;&lt;/pre&gt;
        &lt;/div&gt;
        &lt;p&gt;SQL SERVER:&lt;/p&gt;
        &lt;div class=&quot;highlighter-rouge&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;BEGIN TRANSACTION --开始一个事务
SELECT extra
FROM TradeItem WITH (UPDLOCK)
WHERE tradeItemId=#{tradeItemId}
UPDATE TradeItem 
SET extra = bdo.AddTag(tag,extra)
WHERE tradeItemId=#{tradeItemId}
COMMIT TRANSACTION --提交事务
&lt;/code&gt;&lt;/pre&gt;
        &lt;/div&gt;
        &lt;p&gt;该方案避免了重试带来的开销，同时使用排它锁（更新锁）也没有额外增加锁的开销【直接把commit写到sql里面会被raptor拦截，只能使用dateSource.getConnection设置自动提交为false后提交】&lt;/p&gt;
      &lt;/li&gt;
    &lt;/ol&gt;
  &lt;/li&gt;
&lt;/ul&gt;

&lt;h2 id=&quot;heading-悲观锁乐观锁的取舍&quot;&gt;悲观锁乐观锁的取舍&lt;/h2&gt;</content><author><name>{&quot;name&quot;=&gt;nil, &quot;job_title&quot;=&gt;nil, &quot;location&quot;=&gt;nil, &quot;email&quot;=&gt;nil, &quot;social_links&quot;=&gt;[{&quot;name&quot;=&gt;&quot;facebook&quot;, &quot;url&quot;=&gt;nil}, {&quot;name&quot;=&gt;&quot;github&quot;, &quot;url&quot;=&gt;&quot;https://github.com/Tobi7&quot;}, {&quot;name&quot;=&gt;&quot;instagram&quot;, &quot;url&quot;=&gt;nil}, {&quot;name&quot;=&gt;&quot;linkedin&quot;, &quot;url&quot;=&gt;nil}, {&quot;name&quot;=&gt;&quot;stackoverflow&quot;, &quot;url&quot;=&gt;nil}, {&quot;name&quot;=&gt;&quot;twitter&quot;, &quot;url&quot;=&gt;nil}, {&quot;name&quot;=&gt;&quot;vk&quot;, &quot;url&quot;=&gt;nil}]}</name></author><category term="mysql" /><summary type="html">数据库锁机制</summary></entry></feed>