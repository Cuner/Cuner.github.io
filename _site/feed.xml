<?xml version="1.0" encoding="utf-8"?><feed xmlns="http://www.w3.org/2005/Atom" xml:lang="en"><generator uri="https://jekyllrb.com/" version="3.7.4">Jekyll</generator><link href="http://localhost:4000/feed.xml" rel="self" type="application/atom+xml" /><link href="http://localhost:4000/" rel="alternate" type="text/html" hreflang="en" /><updated>2018-11-19T17:51:02+08:00</updated><id>http://localhost:4000/</id><title type="html">Cuner</title><subtitle>No zero day.</subtitle><author><name>{&quot;name&quot;=&gt;nil, &quot;job_title&quot;=&gt;nil, &quot;location&quot;=&gt;nil, &quot;email&quot;=&gt;nil, &quot;social_links&quot;=&gt;[{&quot;name&quot;=&gt;&quot;facebook&quot;, &quot;url&quot;=&gt;nil}, {&quot;name&quot;=&gt;&quot;github&quot;, &quot;url&quot;=&gt;&quot;https://github.com/Cuner&quot;}, {&quot;name&quot;=&gt;&quot;instagram&quot;, &quot;url&quot;=&gt;nil}, {&quot;name&quot;=&gt;&quot;linkedin&quot;, &quot;url&quot;=&gt;nil}, {&quot;name&quot;=&gt;&quot;stackoverflow&quot;, &quot;url&quot;=&gt;nil}, {&quot;name&quot;=&gt;&quot;twitter&quot;, &quot;url&quot;=&gt;nil}, {&quot;name&quot;=&gt;&quot;vk&quot;, &quot;url&quot;=&gt;nil}]}</name></author><entry><title type="html">J.U.C之AQS队列同步器</title><link href="http://localhost:4000/blog/2018/11/09/java-concurrent-util-AQS/" rel="alternate" type="text/html" title="J.U.C之AQS队列同步器" /><published>2018-11-09T00:00:00+08:00</published><updated>2018-11-09T00:00:00+08:00</updated><id>http://localhost:4000/blog/2018/11/09/java-concurrent-util-AQS</id><content type="html" xml:base="http://localhost:4000/blog/2018/11/09/java-concurrent-util-AQS/">&lt;h1 id=&quot;heading-1简介&quot;&gt;1.简介&lt;/h1&gt;
&lt;p&gt;队列同步器AbstractQueuedSynchronizer（简称同步器），是用来构建同步组件（包括同步容器以及同步工具）的基本框架，也是java.concurrent.util包的实现核心。它使用了一个int类型的成员变量来表示同步状态（J.U.C同样提供了AbstractQueuedLongSynchronizer，它使用long类型的成员变量来表示同步状态），通过内置的的FIFO队列来完成资源的获取线程的排队工作。
同步器的主要使用方式是继承，子类通过继承同步器并实现抽象方法来管理同步状态（基于模本方法模式）。子类被推荐定义为自定义同步组件的静态内部类（作为代理配合实现同步组件），同步器自身没有实现任何同步接口，它仅仅定义了同步状态的获取与释放来供自定义同步组件使用，同步器既可以独占式的获取同步状态也可以共享式的获取同步状态。&lt;/p&gt;

&lt;h1 id=&quot;heading-2队列同步器的接口&quot;&gt;2.队列同步器的接口&lt;/h1&gt;
&lt;p&gt;同步器的设计是基于模板方法模式的，子类需要继承同步器并重写指定的方法，而后将同步器组合在自定义同步组件的实现中（委托模式），并调用同步器的模板方法，这些模板方法将会调用同步器子类中重写的方法&lt;/p&gt;

&lt;h2 id=&quot;heading-21访问修改同步状态&quot;&gt;2.1.访问、修改同步状态&lt;/h2&gt;
&lt;ul&gt;
  &lt;li&gt;int getState()：获取当前同步状态&lt;/li&gt;
  &lt;li&gt;void setState(int newState)：设置当前同步状态&lt;/li&gt;
  &lt;li&gt;boolean compareAndSetState(int expect, int update)：使用CAS设置当前同步状态&lt;/li&gt;
&lt;/ul&gt;

&lt;h2 id=&quot;heading-22同步器可重写方法&quot;&gt;2.2.同步器可重写方法&lt;/h2&gt;

&lt;p&gt;&lt;strong&gt;独占式&lt;/strong&gt;&lt;/p&gt;
&lt;ul&gt;
  &lt;li&gt;boolean tryAcquire(int arg)：独占式获取同步状态，实现该方法需要查询当前同步状态并判断是否符合预期，然后同步CAS设置同步状态。&lt;/li&gt;
  &lt;li&gt;boolean tryRelease(int arg)：独占式释放同步状态，等待获取同步状态的线程将有机会获取同步状态。&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;&lt;strong&gt;共享式&lt;/strong&gt;&lt;/p&gt;
&lt;ul&gt;
  &lt;li&gt;int tryAcquireShared(int arg)：共享式获取同步状态，返回大于等于0表示获取成功，反之获取失败。&lt;/li&gt;
  &lt;li&gt;boolean tryReleaseShared(int arg)：共享式释放同步状态。&lt;/li&gt;
  &lt;li&gt;boolean isHeldExclusively()：当前同步器是否被当前线程独占&lt;/li&gt;
&lt;/ul&gt;

&lt;h2 id=&quot;heading-23同步器提供的模板方法&quot;&gt;2.3.同步器提供的模板方法&lt;/h2&gt;

&lt;p&gt;&lt;strong&gt;独占式&lt;/strong&gt;&lt;/p&gt;
&lt;ul&gt;
  &lt;li&gt;void acquire(int arg)：独占式获取同步状态，如果当前线程获取同步状态成功，则返回，否则将会进入同步队列等待，该方法将会调用重写的tryAcquire(int arg)方法&lt;/li&gt;
  &lt;li&gt;void acquireInterruptibly(int arg)：与acquire(int arg)方法相同，但是该方法响应中断，当前线程未获取到同步状态而进入到同步队列中，如果当前线程被中断，则抛出InterruptedException并返回。&lt;/li&gt;
  &lt;li&gt;boolean tryAcquireNanos(int arg, long nanosTimeout)：在acquireInterruptibly(int arg)基础上增加了超时限制，如果当前线程在超时时间内没有获取到同步状态，那么将返回false，如果获取到了则返回true。&lt;/li&gt;
  &lt;li&gt;boolean release(int arg)：独占式的释放同步状态，该方法会在释放同步状态之后，将同步队列中第一个节点包含的线程唤醒。&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;&lt;strong&gt;共享式&lt;/strong&gt;&lt;/p&gt;
&lt;ul&gt;
  &lt;li&gt;void acquireShared(int arg)：共享式的获取同步状态，如果当前线程未获取到同步状态，将会进入同步队列等待，与独占式的获取主要区别在于同一时刻能够有多个线程获取到同步状态。&lt;/li&gt;
  &lt;li&gt;void acquireSharedInterruptibly(int arg)：与acquireShared(int arg)方法相同，该方法响应中断。&lt;/li&gt;
  &lt;li&gt;boolean tryAcquireSharedNanos(int arg, long nanosTimeout)：在acquireSharedInterruptibly(int arg)方法的基础上增加了超时限制。&lt;/li&gt;
  &lt;li&gt;boolean releaseShared(int arg)：共享式的释放同步状态。&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;&lt;strong&gt;查询同步队列中等待线程情况&lt;/strong&gt;&lt;/p&gt;
&lt;ul&gt;
  &lt;li&gt;Thread getFirstQueuedThread()：获取在同步队列中等待的第一个线程。&lt;/li&gt;
  &lt;li&gt;boolean isQueued(Thread thread)：判断该线程是否处于同步队列中。&lt;/li&gt;
  &lt;li&gt;boolean apparentlyFirstQueuedIsExclusive()：判断同步队列中的第一个线程是否在等待独占式获取同步状态&lt;/li&gt;
  &lt;li&gt;final boolean hasQueuedPredecessors()：同步队列中，当前线程对应的节点是否有前驱节点。&lt;/li&gt;
  &lt;li&gt;int getQueueLength()：获取同步队列长度。&lt;/li&gt;
  &lt;li&gt;Collection&lt;Thread&gt; getQueuedThreads()：获取等待在同步队列上的线程集合。&lt;/Thread&gt;&lt;/li&gt;
  &lt;li&gt;Collection&lt;Thread&gt; getExclusiveQueuedThreads()：获取等待在同步队列上等待独占式获取同步状态的线程集合。&lt;/Thread&gt;&lt;/li&gt;
  &lt;li&gt;Collection&lt;Thread&gt; getSharedQueuedThreads()：获取等待在同步队列上等待共享式获取同步状态的线程集合。&lt;/Thread&gt;&lt;/li&gt;
&lt;/ul&gt;

&lt;h1 id=&quot;heading-3队列同步器的实现分析&quot;&gt;3.队列同步器的实现分析&lt;/h1&gt;

&lt;h2 id=&quot;heading-31同步队列&quot;&gt;3.1同步队列&lt;/h2&gt;
&lt;p&gt;同步器依赖内部的同步队列（一个FIFO双向队列）来完成同步状态的管理，当前线程获取同步状态失败时，同步器会将当前线程以及等待状态等信息构造成一个节点（Node），并将其加入到同步队列中，同时会阻塞当前线程，当同步状态释放是，会把首节点中的线程唤醒，使其再次尝试获取同步状态。&lt;/p&gt;

&lt;h3 id=&quot;heading-311节点&quot;&gt;3.1.1.节点&lt;/h3&gt;
&lt;p&gt;同步队列中的节点（Node）用来保存获取同步状态失败的线程引用、等待状态以及前驱和后继节点。&lt;/p&gt;

&lt;div class=&quot;highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;static final class Node {
    static final Node SHARED = new Node();//标识共享式节点，对应的线程等待共享式获取同步状态
    static final Node EXCLUSIVE = null;//标识独占式节点，对应的线程等待独占式获取同步状态

    /** waitStatus value to indicate thread has cancelled */
    /** 由于在同步队列中等待的线程等待超时或被中断，需要从队列中取消等待，节点进入该状态后将不会变化 */
    static final int CANCELLED =  1;
    
    /** waitStatus value to indicate successor's thread needs unparking */
    /** 后继节点的线程处于等待状态，而当前节点的线程如果释放了同步状态或者被取消，将会通知后继节点，使后继节点的线程得以运行 */
    static final int SIGNAL    = -1;
    
    /** waitStatus value to indicate thread is waiting on condition */
    /** 节点在等待队列中，节点的线程在等待condition上，当其他线程对Condition调用了signal()方法后，该节点将会从等待队列中转移到同步队列中，加入到对同步状态的获取中 */
    static final int CONDITION = -2;
    
    /**
     * waitStatus value to indicate the next acquireShared should
     * unconditionally propagate
     */
     /** 表示下一次共享式同步状态获取将会无条件地被传播下去 */
    static final int PROPAGATE = -3;
    
    volatile int waitStatus;//对应上述多种状态值，其中0表示初始值
    
    volatile Node prev;//前驱节点

    volatile Node next;//后继节点

    volatile Thread thread;//获取同步状态的线程

    Node nextWaiter;//等待队列中的后继节点。在同步队列中，该字段用来标识当前节点的类型（共享or独占）

    final boolean isShared() {
        return nextWaiter == SHARED;
    }

    final Node predecessor() throws NullPointerException {
        Node p = prev;
        if (p == null)
            throw new NullPointerException();
        else
            return p;
    }

    Node() {    // Used to establish initial head or SHARED marker
    }

    Node(Thread thread, Node mode) {     // Used by addWaiter
        this.nextWaiter = mode;
        this.thread = thread;
    }

    Node(Thread thread, int waitStatus) { // Used by Condition
        this.waitStatus = waitStatus;
        this.thread = thread;
    }
}
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;p&gt;主意：Node节点不仅用在同步队列中，AbstractQueuedSynchronizer中的Condition中的等待队列也是使用Node节点构建，所以其中有些字段在两种队列的共用，需要注意区分，Condition将在后文阐述。&lt;/p&gt;

&lt;h3 id=&quot;heading-312队列&quot;&gt;3.1.2.队列&lt;/h3&gt;
&lt;p&gt;节点是构成同步队列的基础，同步器拥有首节点（head）和尾节点（tail），没有成功获取同步状态的线程将会成为节点加入该队列的尾部。&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;同步队列的基本结构
同步器包含了两个节点类型的引用，一个指向首节点，一个指向尾节点。&lt;/li&gt;
&lt;/ul&gt;

&lt;center&gt;&lt;img src=&quot;/assets/images/post/2018-11-09-java-concurrent-util-AQS/queue.jpg&quot; width=&quot;500px&quot; /&gt;&lt;/center&gt;

&lt;ul&gt;
  &lt;li&gt;节点加入到同步队列中
当一个线程成功的获取了同步状态，其他线程无法获取到同步状态，需要被构造成节点并加入到同步队列中，而加入这个队列的过程必须保证是线程安全的，因此同步器提供了一个基于CAS设置尾节点的方法：compareAndSetTail(Node expect, Node update)。&lt;/li&gt;
&lt;/ul&gt;

&lt;center&gt;&lt;img src=&quot;/assets/images/post/2018-11-09-java-concurrent-util-AQS/setHead.jpg&quot; width=&quot;500px&quot; /&gt;&lt;/center&gt;

&lt;ul&gt;
  &lt;li&gt;首节点的设置
同步队列遵循FIFO，首节点是获取同步状态成功的节点，首节点的线程在释放同步状态时，会唤醒后继节点，而后继节点将会在获取同步状态成功的同时将自己设置为首节点，由于只有一个线程能获取到同步状态，因此头结点的设置不需要CAS来保证。&lt;/li&gt;
&lt;/ul&gt;

&lt;center&gt;&lt;img src=&quot;/assets/images/post/2018-11-09-java-concurrent-util-AQS/setTail.jpg&quot; width=&quot;500px&quot; /&gt;&lt;/center&gt;

&lt;h2 id=&quot;heading-32独占式同步状态的获取与释放&quot;&gt;3.2.独占式同步状态的获取与释放&lt;/h2&gt;

&lt;h3 id=&quot;heading-321acquire方法&quot;&gt;3.2.1.acquire方法&lt;/h3&gt;

&lt;div class=&quot;highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;public final void acquire(int arg) {
    if (!tryAcquire(arg) &amp;amp;&amp;amp;
            acquireQueued(addWaiter(Node.EXCLUSIVE), arg))
        selfInterrupt();
}
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;
&lt;p&gt;上述代码主要完成了同步状态获取、节点构造、加入同步队列以及再同步队列中自旋等待等相关工作：首先调用自定义同步器实现的tryAcquire(int arg)方法，该方法保证线程安全地获取同步状态，如果同步状态获取失败，则构造独占式同步节点，并通过addWaiter(Node node)方法将该节点加入到同步队列的尾部，最后调用acquireQueued(Node node, int arg)方法，使得该节点以“死循环”的方式获取同步状态（这里我们也叫做自旋）。如果获取不到则阻塞当前线程，而被阻塞线程的唤醒主要依靠前驱节点的出队或阻塞线程被中断来实现。&lt;/p&gt;

&lt;div class=&quot;highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;private Node addWaiter(Node mode) {
    Node node = new Node(Thread.currentThread(), mode);
    // Try the fast path of enq; backup to full enq on failure
    Node pred = tail;
    if (pred != null) {
        node.prev = pred;
        if (compareAndSetTail(pred, node)) {
            pred.next = node;
            return node;
        }
    }
    enq(node);
    return node;
}

private Node enq(final Node node) {
    for (;;) {
        Node t = tail;
        if (t == null) { // Must initialize
            if (compareAndSetHead(new Node()))
                tail = head;
        } else {
            node.prev = t;
            if (compareAndSetTail(t, node)) {
                t.next = node;
                return t;
            }
        }
    }
}
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;p&gt;节点进入同步队列之后，就进入了一个自旋的过程，每个节点都在观察自己，当条件满足且获取到了同步状态之后，就从这个自旋状态退出。&lt;/p&gt;

&lt;div class=&quot;highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;final boolean acquireQueued(final Node node, int arg) {
    boolean failed = true;
    try {
        boolean interrupted = false;
        for (;;) {
            final Node p = node.predecessor();//获取前驱节点
            if (p == head &amp;amp;&amp;amp; tryAcquire(arg)) {//前驱节点是首节点时 尝试获取同步状态
                setHead(node);
                p.next = null; // help GC
                failed = false;
                return interrupted;
            }
            if (shouldParkAfterFailedAcquire(p, node) &amp;amp;&amp;amp;
                    parkAndCheckInterrupt())
                interrupted = true;
        }
    } finally {
        if (failed)
            cancelAcquire(node);
    }
}

/** 当获取同步状态失败后 是否需要阻塞当前线程：
当前驱节点等待状态是SIGNAL时，返回true，
阻塞后等待前驱节点唤醒 */
private static boolean shouldParkAfterFailedAcquire(Node pred, Node node) {
    int ws = pred.waitStatus;
    if (ws == Node.SIGNAL)
        return true;
    if (ws &amp;gt; 0) {
        do {//处理等待状态为删除的节点
            node.prev = pred = pred.prev;
        } while (pred.waitStatus &amp;gt; 0);
        pred.next = node;
    } else {
        compareAndSetWaitStatus(pred, ws, Node.SIGNAL);
    }
    return false;
}

/** 阻塞当前线程并检查是否中断 */
private final boolean parkAndCheckInterrupt() {
    LockSupport.park(this);//阻塞当前线程
    return Thread.interrupted();
}

private void cancelAcquire(Node node) {
    if (node == null)
        return;

    node.thread = null;

    // Skip cancelled predecessors
    Node pred = node.prev;
    while (pred.waitStatus &amp;gt; 0)
        node.prev = pred = pred.prev;

    Node predNext = pred.next;

    node.waitStatus = Node.CANCELLED;

    // If we are the tail, remove ourselves.
    if (node == tail &amp;amp;&amp;amp; compareAndSetTail(node, pred)) {
        compareAndSetNext(pred, predNext, null);
    } else {
        // If successor needs signal, try to set pred's next-link
        // so it will get one. Otherwise wake it up to propagate.
        int ws;
        if (pred != head &amp;amp;&amp;amp;
                ((ws = pred.waitStatus) == Node.SIGNAL ||
                        (ws &amp;lt;= 0 &amp;amp;&amp;amp; compareAndSetWaitStatus(pred, ws, Node.SIGNAL))) &amp;amp;&amp;amp;
                pred.thread != null) {
            Node next = node.next;
            if (next != null &amp;amp;&amp;amp; next.waitStatus &amp;lt;= 0)
                compareAndSetNext(pred, predNext, next);
        } else {
            unparkSuccessor(node);
        }

        node.next = node; // help GC
    }
}
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;p&gt;头节点是成功获取同步状态的节点，而头节点释放同步状态后，将会唤醒后继节点，后继节点的线程被唤醒后需要检查自己的前驱节点是否为首节点，这样也保证了队列的“先进先出”原则&lt;/p&gt;

&lt;h4 id=&quot;heading-acquireinterruptibly方法&quot;&gt;acquireInterruptibly方法&lt;/h4&gt;
&lt;h4 id=&quot;heading-tryacquirenanos方法&quot;&gt;tryAcquireNanos方法&lt;/h4&gt;
&lt;h4 id=&quot;heading-release方法&quot;&gt;release方法&lt;/h4&gt;

&lt;h3 id=&quot;heading-共享式同步状态的获取与释放&quot;&gt;共享式同步状态的获取与释放&lt;/h3&gt;

&lt;h4 id=&quot;heading-acquireshared方法&quot;&gt;acquireShared方法&lt;/h4&gt;
&lt;h4 id=&quot;heading-acquiresharedinterruptibly方法&quot;&gt;acquireSharedInterruptibly方法&lt;/h4&gt;
&lt;h4 id=&quot;heading-tryacquiresharednanos方法&quot;&gt;tryAcquireSharedNanos方法&lt;/h4&gt;
&lt;h4 id=&quot;heading-releaseshared方法&quot;&gt;releaseShared方法&lt;/h4&gt;

&lt;h3 id=&quot;heading-condition&quot;&gt;Condition&lt;/h3&gt;</content><author><name>{&quot;name&quot;=&gt;nil, &quot;job_title&quot;=&gt;nil, &quot;location&quot;=&gt;nil, &quot;email&quot;=&gt;nil, &quot;social_links&quot;=&gt;[{&quot;name&quot;=&gt;&quot;facebook&quot;, &quot;url&quot;=&gt;nil}, {&quot;name&quot;=&gt;&quot;github&quot;, &quot;url&quot;=&gt;&quot;https://github.com/Cuner&quot;}, {&quot;name&quot;=&gt;&quot;instagram&quot;, &quot;url&quot;=&gt;nil}, {&quot;name&quot;=&gt;&quot;linkedin&quot;, &quot;url&quot;=&gt;nil}, {&quot;name&quot;=&gt;&quot;stackoverflow&quot;, &quot;url&quot;=&gt;nil}, {&quot;name&quot;=&gt;&quot;twitter&quot;, &quot;url&quot;=&gt;nil}, {&quot;name&quot;=&gt;&quot;vk&quot;, &quot;url&quot;=&gt;nil}]}</name></author><category term="J.U.C" /><summary type="html">1.简介 队列同步器AbstractQueuedSynchronizer（简称同步器），是用来构建同步组件（包括同步容器以及同步工具）的基本框架，也是java.concurrent.util包的实现核心。它使用了一个int类型的成员变量来表示同步状态（J.U.C同样提供了AbstractQueuedLongSynchronizer，它使用long类型的成员变量来表示同步状态），通过内置的的FIFO队列来完成资源的获取线程的排队工作。 同步器的主要使用方式是继承，子类通过继承同步器并实现抽象方法来管理同步状态（基于模本方法模式）。子类被推荐定义为自定义同步组件的静态内部类（作为代理配合实现同步组件），同步器自身没有实现任何同步接口，它仅仅定义了同步状态的获取与释放来供自定义同步组件使用，同步器既可以独占式的获取同步状态也可以共享式的获取同步状态。</summary></entry><entry><title type="html">paxos与raft一致性协议</title><link href="http://localhost:4000/blog/2018/10/21/raft-diff-paxos/" rel="alternate" type="text/html" title="paxos与raft一致性协议" /><published>2018-10-21T00:00:00+08:00</published><updated>2018-10-21T00:00:00+08:00</updated><id>http://localhost:4000/blog/2018/10/21/raft-diff-paxos</id><content type="html" xml:base="http://localhost:4000/blog/2018/10/21/raft-diff-paxos/">&lt;h1 id=&quot;heading-一致性协议&quot;&gt;一致性协议&lt;/h1&gt;
&lt;p&gt;一致性协议简单来说，是一种保障集群中所有机器上的数据达到一致的协议。最直观的最好理解的一致性协议，例如2PC、3PC，便是在做数据操作时，对集群中的所有机器同时做数据操作，仅当集群中的全部机器操作成功后，所有机器保证一致后，该数据操作才成功，否则只要有一台机器因为网络等其他原因导致数据操作失败，该数据操作就会失败，其他操作成功的机器也会全部进行数据回滚。
上述一致性协议虽然简单，但相对保守，且无法应对机器宕机、网络分区等故障问题。针对这种情况，paxos以及raft等一致性协议应运而生。
新一代的一致性协议有如下特点：&lt;/p&gt;
&lt;ul&gt;
  &lt;li&gt;采取过半原则：即当集群中大于一半的机器认同该数据操作，且数据操作成功后，该数据操作被集群认可（因为任何两个多数派集合中至少有一个成员是公共的）&lt;/li&gt;
  &lt;li&gt;允许集群中出现部分机器不一致性，且时刻异步进行着机器之前数据的同步&lt;/li&gt;
  &lt;li&gt;选举出leader协助集群中机器间数据的同步&lt;/li&gt;
  &lt;li&gt;在出现机器宕机或者网络分区后，集群仍能正常工作，且保证集群一致性，同时当机器重启或者网络恢复后，也能保证集群一致性（利用持久化数据存储）&lt;/li&gt;
&lt;/ul&gt;

&lt;h1 id=&quot;heading-paxos以及raft介绍&quot;&gt;paxos以及raft介绍&lt;/h1&gt;
&lt;p&gt;下面是关于两种一致性协议的相关论文的详细讲解，这里就不再赘述&lt;/p&gt;
&lt;ul&gt;
  &lt;li&gt;PAXOS
    &lt;ul&gt;
      &lt;li&gt;&lt;a href=&quot;https://www.jianshu.com/p/6d01a8d2df9f&quot;&gt;《Paxos Made Simple》论文翻译&lt;/a&gt;&lt;/li&gt;
      &lt;li&gt;&lt;a href=&quot;/assets/pdf/paxos-simple1.pdf&quot;&gt;《Paxos Made Simple》原文&lt;/a&gt;&lt;/li&gt;
    &lt;/ul&gt;
  &lt;/li&gt;
  &lt;li&gt;RAFT
    &lt;ul&gt;
      &lt;li&gt;&lt;a href=&quot;http://www.infoq.com/cn/articles/raft-paper&quot;&gt;《In search of an Understandable Consensus Algorithm (Extended Version)》中文翻译&lt;/a&gt;&lt;/li&gt;
      &lt;li&gt;&lt;a href=&quot;/assets/pdf/raft.pdf&quot;&gt;《In search of an Understandable Consensus Algorithm (Extended Version)》原文&lt;/a&gt;&lt;/li&gt;
      &lt;li&gt;&lt;a href=&quot;http://thesecretlivesofdata.com/raft/&quot;&gt;Raft Understandable Distributed Consensus&lt;/a&gt;&lt;/li&gt;
      &lt;li&gt;&lt;a href=&quot;https://github.com/coreos/etcd/tree/master/raft#usage&quot;&gt;raft implementation by Go&lt;/a&gt;&lt;/li&gt;
    &lt;/ul&gt;
  &lt;/li&gt;
&lt;/ul&gt;

&lt;h1 id=&quot;heading-paxos以及raft异同这里的paxos指的是multi-paxos&quot;&gt;paxos以及raft异同（这里的paxos指的是Multi-Paxos）&lt;/h1&gt;

&lt;h2 id=&quot;heading-相同点&quot;&gt;相同点&lt;/h2&gt;
&lt;ul&gt;
  &lt;li&gt;保障一致性：一个日志一旦被提交(得到多数派的赞成），就不会丢失，也不可能更改&lt;/li&gt;
  &lt;li&gt;协议都使用一个唯一的整数作为标识符来标明leader的合法性，paxos叫做proposer-id，ZAB叫epoch，VR叫view，raft叫term。&lt;/li&gt;
  &lt;li&gt;在同一个时刻，都只会存在一个合法的leader&lt;/li&gt;
  &lt;li&gt;都是利用了同一个性质：两个多数派集合之间存在一个公共成员&lt;/li&gt;
&lt;/ul&gt;

&lt;h2 id=&quot;heading-差异点&quot;&gt;差异点&lt;/h2&gt;
&lt;p&gt;1.理论与实践&lt;/p&gt;
&lt;ul&gt;
  &lt;li&gt;paxos是理论上的一致性协议，虽然高效但是难以理解，难以在实际环境中实现，而一些paxos实现的一致性系统最终也产生一些偏离；&lt;/li&gt;
  &lt;li&gt;raft相对来说更加易于理解，且能很好的运用到实际中。&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;2.特点&lt;/p&gt;
&lt;ul&gt;
  &lt;li&gt;paxos的特点在与从一个提案被提出到被接受分为两个阶段，第一个阶段去询问值，第二阶段根据询问的结果提出值。这两个阶段是无法分割的，两个阶段的每个细节都是精心设计的，相互关联，共同保障了协议的一致性&lt;/li&gt;
  &lt;li&gt;raft的特点在于使用算法分解，将协议分为领导选取、日志复制和安全性和减少状态（相对于Paxos，Raft 减少了非确定性的程度和服务器互相不一致的方式）&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;3.领导人的定位&lt;/p&gt;
&lt;ul&gt;
  &lt;li&gt;paxos一致性协议中，没有领导人也能很好的工作，领导人选举仅仅是性能优化的手段，而且不是一致性所必须要求&lt;/li&gt;
  &lt;li&gt;raft一致性协议中，使用领导人选举作为一致性协议里必不可少的部分，并且将尽可能多的功能集中到了领导人身上。这样就简化了对日志复制的管理，使得算法更加容易理解。另外Raft 尽可能的减少了非领导人的功能。例如，Raft 中日志条目都遵循着从领导人发送给其他人这一个方向：附加条目 RPC 是向外发送的。在 VR 中，日志条目的流动是双向的（领导人可以在选举过程中接收日志）；这就导致了额外的机制和复杂性。&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;4.领导选取&lt;br /&gt;
都是用心跳机制来保证追随者实时感应到当前领导人，心跳丢失则表明领导人宕机&lt;/p&gt;
&lt;ul&gt;
  &lt;li&gt;paxos协议未给领导选取提出独立的选举方案，针对领导人选举的独立的机制可以是任意强一致算法，当然也可以是paxos&lt;/li&gt;
  &lt;li&gt;raft通过选举超时(随机超时避免重复瓜分选票)来随机选取领导人，一台服务器最多能给一个候选人投票，同时为了保证安全性，宕机后的重新选举需要选举有效的含有所有被提价日志条目的机器：只有追随者机器上的日志和候选人机器上的日志一样新，追随者才能给候选人投票。&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;5.大多数一致性协议中仅使用leader主节点来集中处理事务请求&lt;/p&gt;
&lt;ul&gt;
  &lt;li&gt;使用paxos实现的一致性集群中Hyperspace 只有一台leader对外提供服务，其他机器只做数据备份&lt;/li&gt;
  &lt;li&gt;raft随机挑选一个服务器进行通信。如果第一次挑选的服务器不是领导人，那么那个服务器会拒绝客户端的请求并且提供它最近接收到的领导人的信息&lt;/li&gt;
  &lt;li&gt;zk集群中其他follower能够接受客户端请求，但是仅仅只是接受，然后把请求转发给leader&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;6.提案提交&lt;/p&gt;
&lt;ul&gt;
  &lt;li&gt;paxos从提案被提出到提交需要经过两个阶段，多个提案可以并发同时完成第一个初审阶段，然后串行的按序完成阶段二，两个阶段leader都需要与集群中大部分机器完成通信，且需要集群中过半机器审核通过&lt;/li&gt;
  &lt;li&gt;raft从提案被提出到提交，是提案对应的日志从leader复制到集群中剩余机器的过程(通过rpc)，当该日志复制到集群中的过半机器后，该提案才能被提交。提案的提交具有强顺序性(串行完成提交)&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;7.日志条目&lt;/p&gt;
&lt;ul&gt;
  &lt;li&gt;paxos有指令空缺，宕机后重新选举得到的领导人若在日志上有指令空缺，可通过二阶段提交从其它节点获取已经被提交的日志来填补指令空缺。&lt;/li&gt;
  &lt;li&gt;raft的日志条目具有强顺序性，强调日志的连续性，不允许出现空洞，领导人永远不会覆盖或者删除自己的日志，它只会增加条目，新选举出的Leader已经拥有全部的可以被提交的日志&lt;/li&gt;
&lt;/ul&gt;

&lt;h1 id=&quot;heading-混淆概念&quot;&gt;混淆概念&lt;/h1&gt;

&lt;p&gt;raft以及paxos协议中针对每个提案，都有一个全局唯一的递增id，用来表示某个提案的唯一性，这里的提案可以对应为客户端的一次请求或者一条指令。而paxos协议中，每个提案对应一个编号以及提案值，这里的编号与上述的提案id不同，该编号的概念存在于某个提案A从提出到被决策的生命周期中(在该生命中期中自增且唯一)，也可以理解为某个提案A被提出者提出的字数编号，例如序列为100的提案被第一次提出、被第二次提出。&lt;/p&gt;</content><author><name>{&quot;name&quot;=&gt;nil, &quot;job_title&quot;=&gt;nil, &quot;location&quot;=&gt;nil, &quot;email&quot;=&gt;nil, &quot;social_links&quot;=&gt;[{&quot;name&quot;=&gt;&quot;facebook&quot;, &quot;url&quot;=&gt;nil}, {&quot;name&quot;=&gt;&quot;github&quot;, &quot;url&quot;=&gt;&quot;https://github.com/Cuner&quot;}, {&quot;name&quot;=&gt;&quot;instagram&quot;, &quot;url&quot;=&gt;nil}, {&quot;name&quot;=&gt;&quot;linkedin&quot;, &quot;url&quot;=&gt;nil}, {&quot;name&quot;=&gt;&quot;stackoverflow&quot;, &quot;url&quot;=&gt;nil}, {&quot;name&quot;=&gt;&quot;twitter&quot;, &quot;url&quot;=&gt;nil}, {&quot;name&quot;=&gt;&quot;vk&quot;, &quot;url&quot;=&gt;nil}]}</name></author><category term="consensus" /><summary type="html">一致性协议 一致性协议简单来说，是一种保障集群中所有机器上的数据达到一致的协议。最直观的最好理解的一致性协议，例如2PC、3PC，便是在做数据操作时，对集群中的所有机器同时做数据操作，仅当集群中的全部机器操作成功后，所有机器保证一致后，该数据操作才成功，否则只要有一台机器因为网络等其他原因导致数据操作失败，该数据操作就会失败，其他操作成功的机器也会全部进行数据回滚。 上述一致性协议虽然简单，但相对保守，且无法应对机器宕机、网络分区等故障问题。针对这种情况，paxos以及raft等一致性协议应运而生。 新一代的一致性协议有如下特点： 采取过半原则：即当集群中大于一半的机器认同该数据操作，且数据操作成功后，该数据操作被集群认可（因为任何两个多数派集合中至少有一个成员是公共的） 允许集群中出现部分机器不一致性，且时刻异步进行着机器之前数据的同步 选举出leader协助集群中机器间数据的同步 在出现机器宕机或者网络分区后，集群仍能正常工作，且保证集群一致性，同时当机器重启或者网络恢复后，也能保证集群一致性（利用持久化数据存储）</summary></entry><entry><title type="html">基于配置的流程管理框架</title><link href="http://localhost:4000/blog/2018/08/04/flow-framework/" rel="alternate" type="text/html" title="基于配置的流程管理框架" /><published>2018-08-04T00:00:00+08:00</published><updated>2018-08-04T00:00:00+08:00</updated><id>http://localhost:4000/blog/2018/08/04/flow-framework</id><content type="html" xml:base="http://localhost:4000/blog/2018/08/04/flow-framework/">&lt;h1 id=&quot;heading-介绍&quot;&gt;介绍&lt;/h1&gt;
&lt;p&gt;通用的流程编排框架，将整个流程以xml配置文件的形式管理起来：定义流程、管理上下文、控制流程的流转（按条件或者顺序），各个流程节点的执行（同步或者异步）。同时对每个流程节点进行监控以及统计，完成对流程的整体把控。&lt;/p&gt;

&lt;h1 id=&quot;heading-基本概念&quot;&gt;基本概念&lt;/h1&gt;

&lt;ul&gt;
  &lt;li&gt;flow:数据流程对象&lt;/li&gt;
  &lt;li&gt;step:流程的子步骤，也叫流程节点&lt;/li&gt;
  &lt;li&gt;action:流程中各个步骤执行的操作&lt;/li&gt;
  &lt;li&gt;subflow:子流程，一个流程节点可以执行操作；也可以执行某个子流程&lt;/li&gt;
&lt;/ul&gt;

&lt;h1 id=&quot;heading-用法&quot;&gt;用法&lt;/h1&gt;

&lt;h2 id=&quot;heading-1定义流程的输入与输出&quot;&gt;1.定义流程的输入与输出&lt;/h2&gt;

&lt;ul&gt;
  &lt;li&gt;定义输入为Data&lt;/li&gt;
  &lt;li&gt;定义输出为Result&lt;/li&gt;
&lt;/ul&gt;

&lt;h2 id=&quot;heading-2定义步骤子节点&quot;&gt;2.定义步骤（子节点）&lt;/h2&gt;

&lt;p&gt;所有的子节点需要实现接口org.cuner.flowframework.core.Action&amp;lt;Data, Result&amp;gt;&lt;/p&gt;

&lt;div class=&quot;highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;public class Action1 implements Action&amp;lt;Data, Result&amp;gt; {
    @Override
    public void execute(FlowContext&amp;lt;Data, Result&amp;gt; context) {
        if (context.getResult() == null) {
            context.setResult(new Result());
        }
        context.setParameter(&quot;param&quot;, 1);
        context.getResult().setResult(context.getData().getData());
        System.out.println(&quot;----------flow: &quot; +  context.getFlowName() + &quot; step: &quot; + context.getStepName() + &quot; action: &quot; + this.getClass().getSimpleName() + &quot;----------&quot;);
    }
}
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;p&gt;同时保证启动后，将所有action注入到spring容器中&lt;/p&gt;

&lt;div class=&quot;highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;&amp;lt;bean id=&quot;action1&quot; class=&quot;org.cuner.flowframework.test.action.Action1&quot;/&amp;gt;
&amp;lt;bean id=&quot;action2&quot; class=&quot;org.cuner.flowframework.test.action.Action2&quot;/&amp;gt;
&amp;lt;bean id=&quot;action3&quot; class=&quot;org.cuner.flowframework.test.action.Action3&quot;/&amp;gt;
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;h2 id=&quot;heading-3通过xml配置定义流程&quot;&gt;3.通过xml配置定义流程&lt;/h2&gt;

&lt;p&gt;详细的配置结构请查看xsd文件&lt;/p&gt;
&lt;ul&gt;
  &lt;li&gt;&lt;code class=&quot;highlighter-rouge&quot;&gt;flows&lt;/code&gt;标签为root标签，可包含多个&lt;code class=&quot;highlighter-rouge&quot;&gt;flow&lt;/code&gt;标签&lt;/li&gt;
  &lt;li&gt;&lt;code class=&quot;highlighter-rouge&quot;&gt;flow&lt;/code&gt;标签标识一个流程，可以是一个主流程也可以是一个子流程，拥有name属性代表流程名称（流程名字要求全局唯一），可包含多个&lt;code class=&quot;highlighter-rouge&quot;&gt;step&lt;/code&gt;标签&lt;/li&gt;
  &lt;li&gt;&lt;code class=&quot;highlighter-rouge&quot;&gt;step&lt;/code&gt;标签标识一个步骤（流程节点）
    &lt;ul&gt;
      &lt;li&gt;包含零或一个&lt;code class=&quot;highlighter-rouge&quot;&gt;condition类&lt;/code&gt;标签，标识该步骤的执行条件，若没有则默认执行&lt;/li&gt;
      &lt;li&gt;包含零或多个&lt;code class=&quot;highlighter-rouge&quot;&gt;conditionTransition&lt;/code&gt;标签，标识状态的流转，若没有则默认流转到配置文件中下一个步骤&lt;/li&gt;
      &lt;li&gt;name属性：标识步骤名称&lt;/li&gt;
      &lt;li&gt;asyn属性：标识是否异步执行&lt;/li&gt;
      &lt;li&gt;action属性：标识步骤执行的操作，关联Action接口某个实现类的bean id&lt;/li&gt;
      &lt;li&gt;subflow属性：标识步骤所代表的子流程（action属性和subflow属性只能存在一者）&lt;/li&gt;
    &lt;/ul&gt;
  &lt;/li&gt;
  &lt;li&gt;&lt;code class=&quot;highlighter-rouge&quot;&gt;condition类标签&lt;/code&gt;
    &lt;ul&gt;
      &lt;li&gt;&lt;code class=&quot;highlighter-rouge&quot;&gt;condition&lt;/code&gt;标签：
        &lt;ul&gt;
          &lt;li&gt;属性key：为输入对象Data的某个属性&lt;/li&gt;
          &lt;li&gt;value：与输入对象Data的某个属性值相比较的值&lt;/li&gt;
          &lt;li&gt;comparator：关系运算符（eq、ne、gt、lt、ge、le、ln）&lt;/li&gt;
        &lt;/ul&gt;
      &lt;/li&gt;
      &lt;li&gt;&lt;code class=&quot;highlighter-rouge&quot;&gt;expCondition&lt;/code&gt;标签，拥有express属性，值为判断条件的表达式，如 data == &quot;test&quot;，其中data为输入对象Data的一个属性&lt;/li&gt;
      &lt;li&gt;&lt;code class=&quot;highlighter-rouge&quot;&gt;andCondtion&lt;/code&gt;标签，包含多个condition类标签，对多个condition的结果做与操作&lt;/li&gt;
      &lt;li&gt;&lt;code class=&quot;highlighter-rouge&quot;&gt;orCondtion&lt;/code&gt;标签，包含多个condition类标签，对多个condition的结果做或操作&lt;/li&gt;
    &lt;/ul&gt;
  &lt;/li&gt;
  &lt;li&gt;&lt;code class=&quot;highlighter-rouge&quot;&gt;conditionTransition&lt;/code&gt;标签
    &lt;ul&gt;
      &lt;li&gt;包含一个&lt;code class=&quot;highlighter-rouge&quot;&gt;condition&lt;/code&gt;标签，判断是否符合状态流程的条件&lt;/li&gt;
      &lt;li&gt;包含一个to属性：标识状态流转的下一个节点&lt;/li&gt;
    &lt;/ul&gt;
  &lt;/li&gt;
&lt;/ul&gt;

&lt;div class=&quot;highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;&lt;span class=&quot;cp&quot;&gt;&amp;lt;?xml version=&quot;1.0&quot; encoding=&quot;UTF-8&quot;?&amp;gt;&lt;/span&gt;
&lt;span class=&quot;nt&quot;&gt;&amp;lt;flows&lt;/span&gt; &lt;span class=&quot;na&quot;&gt;xmlns=&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;&quot;http://repo.cuner.com/schema/flow&quot;&lt;/span&gt;&lt;span class=&quot;nt&quot;&gt;&amp;gt;&lt;/span&gt;
    &lt;span class=&quot;nt&quot;&gt;&amp;lt;flow&lt;/span&gt; &lt;span class=&quot;na&quot;&gt;name=&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;&quot;mainFlow&quot;&lt;/span&gt;&lt;span class=&quot;nt&quot;&gt;&amp;gt;&lt;/span&gt;
        &lt;span class=&quot;nt&quot;&gt;&amp;lt;step&lt;/span&gt; &lt;span class=&quot;na&quot;&gt;name=&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;&quot;step1&quot;&lt;/span&gt; &lt;span class=&quot;na&quot;&gt;action=&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;&quot;action1&quot;&lt;/span&gt;&lt;span class=&quot;nt&quot;&gt;/&amp;gt;&lt;/span&gt;
        &lt;span class=&quot;nt&quot;&gt;&amp;lt;step&lt;/span&gt; &lt;span class=&quot;na&quot;&gt;name=&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;&quot;step2&quot;&lt;/span&gt; &lt;span class=&quot;na&quot;&gt;action=&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;&quot;action2&quot;&lt;/span&gt; &lt;span class=&quot;na&quot;&gt;asyn=&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;&quot;true&quot;&lt;/span&gt;&lt;span class=&quot;nt&quot;&gt;/&amp;gt;&lt;/span&gt;
        &lt;span class=&quot;nt&quot;&gt;&amp;lt;step&lt;/span&gt; &lt;span class=&quot;na&quot;&gt;name=&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;&quot;step3&quot;&lt;/span&gt; &lt;span class=&quot;na&quot;&gt;subflow=&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;&quot;subflow&quot;&lt;/span&gt;&lt;span class=&quot;nt&quot;&gt;/&amp;gt;&lt;/span&gt;
        &lt;span class=&quot;nt&quot;&gt;&amp;lt;step&lt;/span&gt; &lt;span class=&quot;na&quot;&gt;name=&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;&quot;step4&quot;&lt;/span&gt; &lt;span class=&quot;na&quot;&gt;subflow=&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;&quot;subflow&quot;&lt;/span&gt; &lt;span class=&quot;na&quot;&gt;asyn=&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;&quot;true&quot;&lt;/span&gt;&lt;span class=&quot;nt&quot;&gt;/&amp;gt;&lt;/span&gt;
        &lt;span class=&quot;nt&quot;&gt;&amp;lt;step&lt;/span&gt; &lt;span class=&quot;na&quot;&gt;name=&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;&quot;step5&quot;&lt;/span&gt; &lt;span class=&quot;na&quot;&gt;action=&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;&quot;action3&quot;&lt;/span&gt;&lt;span class=&quot;nt&quot;&gt;&amp;gt;&lt;/span&gt;
            &lt;span class=&quot;nt&quot;&gt;&amp;lt;condition&lt;/span&gt; &lt;span class=&quot;na&quot;&gt;key=&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;&quot;data&quot;&lt;/span&gt; &lt;span class=&quot;na&quot;&gt;value=&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;&quot;test&quot;&lt;/span&gt; &lt;span class=&quot;na&quot;&gt;comparator=&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;&quot;eq&quot;&lt;/span&gt;&lt;span class=&quot;nt&quot;&gt;/&amp;gt;&lt;/span&gt;
        &lt;span class=&quot;nt&quot;&gt;&amp;lt;/step&amp;gt;&lt;/span&gt;
        &lt;span class=&quot;nt&quot;&gt;&amp;lt;step&lt;/span&gt; &lt;span class=&quot;na&quot;&gt;name=&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;&quot;step6&quot;&lt;/span&gt; &lt;span class=&quot;na&quot;&gt;action=&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;&quot;action3&quot;&lt;/span&gt;&lt;span class=&quot;nt&quot;&gt;&amp;gt;&lt;/span&gt;
            &lt;span class=&quot;nt&quot;&gt;&amp;lt;expCondition&lt;/span&gt; &lt;span class=&quot;na&quot;&gt;expression=&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;'data.getData() == &quot;test&quot; '&lt;/span&gt;&lt;span class=&quot;nt&quot;&gt;/&amp;gt;&lt;/span&gt;
        &lt;span class=&quot;nt&quot;&gt;&amp;lt;/step&amp;gt;&lt;/span&gt;
        &lt;span class=&quot;nt&quot;&gt;&amp;lt;step&lt;/span&gt; &lt;span class=&quot;na&quot;&gt;name=&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;&quot;step7&quot;&lt;/span&gt; &lt;span class=&quot;na&quot;&gt;action=&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;&quot;action3&quot;&lt;/span&gt;&lt;span class=&quot;nt&quot;&gt;&amp;gt;&lt;/span&gt;
            &lt;span class=&quot;nt&quot;&gt;&amp;lt;andCondition&amp;gt;&lt;/span&gt;
                &lt;span class=&quot;nt&quot;&gt;&amp;lt;condition&lt;/span&gt; &lt;span class=&quot;na&quot;&gt;key=&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;&quot;data&quot;&lt;/span&gt; &lt;span class=&quot;na&quot;&gt;value=&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;&quot;test&quot;&lt;/span&gt; &lt;span class=&quot;na&quot;&gt;comparator=&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;&quot;eq&quot;&lt;/span&gt;&lt;span class=&quot;nt&quot;&gt;/&amp;gt;&lt;/span&gt;
            &lt;span class=&quot;nt&quot;&gt;&amp;lt;/andCondition&amp;gt;&lt;/span&gt;
        &lt;span class=&quot;nt&quot;&gt;&amp;lt;/step&amp;gt;&lt;/span&gt;
        &lt;span class=&quot;nt&quot;&gt;&amp;lt;step&lt;/span&gt; &lt;span class=&quot;na&quot;&gt;name=&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;&quot;step8&quot;&lt;/span&gt; &lt;span class=&quot;na&quot;&gt;action=&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;&quot;action3&quot;&lt;/span&gt;&lt;span class=&quot;nt&quot;&gt;&amp;gt;&lt;/span&gt;
            &lt;span class=&quot;nt&quot;&gt;&amp;lt;orderTransition&lt;/span&gt; &lt;span class=&quot;na&quot;&gt;to=&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;&quot;step9&quot;&lt;/span&gt;&lt;span class=&quot;nt&quot;&gt;/&amp;gt;&lt;/span&gt;
        &lt;span class=&quot;nt&quot;&gt;&amp;lt;/step&amp;gt;&lt;/span&gt;
        &lt;span class=&quot;nt&quot;&gt;&amp;lt;step&lt;/span&gt; &lt;span class=&quot;na&quot;&gt;name=&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;&quot;step9&quot;&lt;/span&gt; &lt;span class=&quot;na&quot;&gt;action=&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;&quot;action3&quot;&lt;/span&gt;&lt;span class=&quot;nt&quot;&gt;&amp;gt;&lt;/span&gt;
            &lt;span class=&quot;nt&quot;&gt;&amp;lt;conditionTransition&lt;/span&gt; &lt;span class=&quot;na&quot;&gt;to=&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;&quot;step10&quot;&lt;/span&gt;&lt;span class=&quot;nt&quot;&gt;&amp;gt;&lt;/span&gt;
                &lt;span class=&quot;nt&quot;&gt;&amp;lt;condition&lt;/span&gt; &lt;span class=&quot;na&quot;&gt;key=&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;&quot;data&quot;&lt;/span&gt; &lt;span class=&quot;na&quot;&gt;value=&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;&quot;test&quot;&lt;/span&gt; &lt;span class=&quot;na&quot;&gt;comparator=&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;&quot;eq&quot;&lt;/span&gt;&lt;span class=&quot;nt&quot;&gt;/&amp;gt;&lt;/span&gt;
            &lt;span class=&quot;nt&quot;&gt;&amp;lt;/conditionTransition&amp;gt;&lt;/span&gt;
        &lt;span class=&quot;nt&quot;&gt;&amp;lt;/step&amp;gt;&lt;/span&gt;
        &lt;span class=&quot;nt&quot;&gt;&amp;lt;step&lt;/span&gt; &lt;span class=&quot;na&quot;&gt;name=&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;&quot;step10&quot;&lt;/span&gt; &lt;span class=&quot;na&quot;&gt;action=&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;&quot;action3&quot;&lt;/span&gt;&lt;span class=&quot;nt&quot;&gt;&amp;gt;&lt;/span&gt;
            &lt;span class=&quot;nt&quot;&gt;&amp;lt;expCondition&lt;/span&gt; &lt;span class=&quot;na&quot;&gt;expression=&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;'parameters.get(&quot;params&quot;) == 1'&lt;/span&gt;&lt;span class=&quot;nt&quot;&gt;/&amp;gt;&lt;/span&gt;
        &lt;span class=&quot;nt&quot;&gt;&amp;lt;/step&amp;gt;&lt;/span&gt;
    &lt;span class=&quot;nt&quot;&gt;&amp;lt;/flow&amp;gt;&lt;/span&gt;

    &lt;span class=&quot;nt&quot;&gt;&amp;lt;flow&lt;/span&gt; &lt;span class=&quot;na&quot;&gt;name=&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;&quot;subflow&quot;&lt;/span&gt;&lt;span class=&quot;nt&quot;&gt;&amp;gt;&lt;/span&gt;
        &lt;span class=&quot;nt&quot;&gt;&amp;lt;step&lt;/span&gt; &lt;span class=&quot;na&quot;&gt;name=&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;&quot;sub_step1&quot;&lt;/span&gt; &lt;span class=&quot;na&quot;&gt;action=&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;&quot;action1&quot;&lt;/span&gt; &lt;span class=&quot;na&quot;&gt;asyn=&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;&quot;true&quot;&lt;/span&gt;&lt;span class=&quot;nt&quot;&gt;/&amp;gt;&lt;/span&gt;
        &lt;span class=&quot;nt&quot;&gt;&amp;lt;step&lt;/span&gt; &lt;span class=&quot;na&quot;&gt;name=&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;&quot;sub_step2&quot;&lt;/span&gt; &lt;span class=&quot;na&quot;&gt;action=&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;&quot;action2&quot;&lt;/span&gt;&lt;span class=&quot;nt&quot;&gt;/&amp;gt;&lt;/span&gt;
    &lt;span class=&quot;nt&quot;&gt;&amp;lt;/flow&amp;gt;&lt;/span&gt;
&lt;span class=&quot;nt&quot;&gt;&amp;lt;/flows&amp;gt;&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;h2 id=&quot;heading-4流程注入&quot;&gt;4.流程注入&lt;/h2&gt;

&lt;p&gt;配置文件需要放在classpath下，案例中的配置文件就是在classpath下的flow.xml文件&lt;/p&gt;

&lt;div class=&quot;highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;&amp;lt;bean id=&quot;flowManager&quot; class=&quot;org.cuner.flowframework.core.manager.FlowManager&quot;&amp;gt;
    &amp;lt;property name=&quot;flowFiles&quot;&amp;gt;
        &amp;lt;list&amp;gt;
            &amp;lt;value&amp;gt;flow.xml&amp;lt;/value&amp;gt;
        &amp;lt;/list&amp;gt;
    &amp;lt;/property&amp;gt;
&amp;lt;/bean&amp;gt;
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;h2 id=&quot;heading-5执行&quot;&gt;5.执行&lt;/h2&gt;

&lt;div class=&quot;highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;Result result = flowManager.execute(&quot;mainFlow&quot;, data);
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;
&lt;p&gt;由于各个步骤可异步执行，在主流程的执行中加入了闭锁，只有当所有步骤（包括异步的）执行完成，execute方法才能正确返回。&lt;/p&gt;

&lt;h2 id=&quot;heading-6查看日志&quot;&gt;6.查看日志&lt;/h2&gt;
&lt;p&gt;可查看流程执行的完整堆栈，可以在logback.xml中如下配置&lt;/p&gt;
&lt;div class=&quot;highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;&amp;lt;logger name=&quot;flow-record&quot; level=&quot;info&quot; additivity=&quot;false&quot;&amp;gt;
    &amp;lt;appender-ref ref=&quot;FLOW_RECORD&quot;/&amp;gt;
&amp;lt;/logger&amp;gt;
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;p&gt;上述案例执行后日志如下&lt;/p&gt;
&lt;div class=&quot;highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;21:03:23.431 [main] INFO  flow-record - 2018-08-04 21:03:23,415
[flow:mainFlow | start:2018-08-04 21:03:23,353 | end:2018-08-04 21:03:23,380 | cost:27]
|----[step:step1 | start:2018-08-04 21:03:23,354 | end:2018-08-04 21:03:23,355 | cost:1]
|----(step:step2 | start:2018-08-04 21:03:23,358 | end:2018-08-04 21:03:23,359 | cost:1) (asynchronously)
|----[step:step3 | start:2018-08-04 21:03:23,359 | end:2018-08-04 21:03:23,360 | cost:1]
        |----[sub_flow:subflow | start:2018-08-04 21:03:23,359 | end:2018-08-04 21:03:23,360 | cost:1]
                |----(step:sub_step1 | start:2018-08-04 21:03:23,360 | end:2018-08-04 21:03:23,360 | cost:0) (asynchronously)
                |----[step:sub_step2 | start:2018-08-04 21:03:23,360 | end:2018-08-04 21:03:23,360 | cost:0]
|----(step:step4 | start:2018-08-04 21:03:23,361 | end:2018-08-04 21:03:23,361 | cost:0) (asynchronously)
        |----[sub_flow:subflow | start:2018-08-04 21:03:23,361 | end:2018-08-04 21:03:23,361 | cost:0]
                |----[step:sub_step2 | start:2018-08-04 21:03:23,361 | end:2018-08-04 21:03:23,361 | cost:0]
                |----(step:sub_step1 | start:2018-08-04 21:03:23,361 | end:2018-08-04 21:03:23,361 | cost:0) (asynchronously)
|----[step:step5 | start:2018-08-04 21:03:23,378 | end:2018-08-04 21:03:23,380 | cost:2]
|----[step:step6 | start:2018-08-04 21:03:23,380 | end:2018-08-04 21:03:23,380 | cost:0]
|----[step:step7 | start:2018-08-04 21:03:23,380 | end:2018-08-04 21:03:23,380 | cost:0]
|----[step:step8 | start:2018-08-04 21:03:23,380 | end:2018-08-04 21:03:23,380 | cost:0]
|----[step:step9 | start:2018-08-04 21:03:23,380 | end:2018-08-04 21:03:23,380 | cost:0]
|----[step:step10 | start:2018-08-04 21:03:23,380 | end:2018-08-04 21:03:23,380 | cost:0]
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;h1 id=&quot;heading-源码&quot;&gt;源码&lt;/h1&gt;

&lt;p&gt;最后，附上代码:https://github.com/Cuner/flow-framework&lt;/p&gt;</content><author><name>{&quot;name&quot;=&gt;nil, &quot;job_title&quot;=&gt;nil, &quot;location&quot;=&gt;nil, &quot;email&quot;=&gt;nil, &quot;social_links&quot;=&gt;[{&quot;name&quot;=&gt;&quot;facebook&quot;, &quot;url&quot;=&gt;nil}, {&quot;name&quot;=&gt;&quot;github&quot;, &quot;url&quot;=&gt;&quot;https://github.com/Cuner&quot;}, {&quot;name&quot;=&gt;&quot;instagram&quot;, &quot;url&quot;=&gt;nil}, {&quot;name&quot;=&gt;&quot;linkedin&quot;, &quot;url&quot;=&gt;nil}, {&quot;name&quot;=&gt;&quot;stackoverflow&quot;, &quot;url&quot;=&gt;nil}, {&quot;name&quot;=&gt;&quot;twitter&quot;, &quot;url&quot;=&gt;nil}, {&quot;name&quot;=&gt;&quot;vk&quot;, &quot;url&quot;=&gt;nil}]}</name></author><category term="flow" /><summary type="html">介绍 通用的流程编排框架，将整个流程以xml配置文件的形式管理起来：定义流程、管理上下文、控制流程的流转（按条件或者顺序），各个流程节点的执行（同步或者异步）。同时对每个流程节点进行监控以及统计，完成对流程的整体把控。</summary></entry><entry><title type="html">基于spring的groovy动态加载</title><link href="http://localhost:4000/blog/2018/06/26/groovy-loader/" rel="alternate" type="text/html" title="基于spring的groovy动态加载" /><published>2018-06-26T00:00:00+08:00</published><updated>2018-06-26T00:00:00+08:00</updated><id>http://localhost:4000/blog/2018/06/26/groovy-loader</id><content type="html" xml:base="http://localhost:4000/blog/2018/06/26/groovy-loader/">&lt;h1 id=&quot;heading-groovy-loader背景&quot;&gt;groovy loader背景&lt;/h1&gt;
&lt;p&gt;由于groovy动态语言的特性，使用方式与java一致，同时又特别适合与Spring的动态语言支持一起使用，所以基于java的groovy脚本的动态加载的使用场景还是比较多的&lt;/p&gt;

&lt;h1 id=&quot;heading-简介&quot;&gt;简介&lt;/h1&gt;
&lt;p&gt;动态加载指定目录下的groovy脚本，并将其注册为groovy bean，放置于ApplicationContext容器中，并使用命名空间进行分类区分(一个namespace对应于一个ApplicationContext)。同时能够动态感知到groovy脚本的新增、修改以及删除事件，并自动重新加载。&lt;/p&gt;

&lt;h1 id=&quot;heading-原理&quot;&gt;原理&lt;/h1&gt;
&lt;ul&gt;
  &lt;li&gt;使用spring配置文件来管理注册groovy bean：每一个spring配置文件作为一个ApplicationContext，管理一个namespace下的groovy bean&lt;/li&gt;
  &lt;li&gt;spring配置文件使用标签&lt;code class=&quot;highlighter-rouge&quot;&gt;&amp;lt;lang:groovy&amp;gt;&lt;/code&gt;，通过指定script-source来加载指定路径下的groovy脚本，通过refresh-check-delay属性来定时动态加载每个groovy bean&lt;/li&gt;
  &lt;li&gt;通过扫描监听指定路径下spring配置文件的变更，来接受groovy脚本的新增、删除事件&lt;/li&gt;
&lt;/ul&gt;

&lt;h3 id=&quot;heading-监听器listener&quot;&gt;监听器listener&lt;/h3&gt;
&lt;p&gt;由于我们需要动态获取groovy脚本的变更，包含更新、新增、删除。接收到groovy脚本变更后需要触发用户自定义事件，所以我们先提供一个待用户实现的监听器接口，用于接受groovy变更事件，并执行相应代码&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;GroovyRefreshedEvent&lt;/li&gt;
&lt;/ul&gt;

&lt;div class=&quot;highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;public class GroovyRefreshedEvent {

    private ApplicationContext ancestorContext;

    private Map&amp;lt;String, FileSystemXmlApplicationContext&amp;gt; namespacedContextMap;

    public GroovyRefreshedEvent(ApplicationContext ancestorContext, Map&amp;lt;String, FileSystemXmlApplicationContext&amp;gt; contextMap) {
        this.ancestorContext = ancestorContext;
        this.namespacedContextMap = contextMap;
    }
    ...
}
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;p&gt;上述提到过，指定目录下的groovy脚本会被注册为groovy bean，并使用Applocation容器进行管理，同时还引入了namespace的概念，每个namespace分别对应一个Application容器，允许namespace不同但是类名相关的groovy bean存在。于是监听器的Event对象被设计成包含一个父容器以及namespace为key，对应Applocation容易为value的Map。&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;GroovyRefreshedListener
    &lt;div class=&quot;highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;public interface GroovyRefreshedListener {

  void groovyRefreshed(GroovyRefreshedEvent event);
}
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;    &lt;/div&gt;
  &lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;这个需要用户来实现&lt;/p&gt;

&lt;h3 id=&quot;heading-触发器trigger&quot;&gt;触发器trigger&lt;/h3&gt;
&lt;p&gt;由于需要动态去发现groovy脚本的变更，需要通过定时轮训使用触发器去判断groovy脚本是否完成了变更。上述提到过，框架通过&lt;code class=&quot;highlighter-rouge&quot;&gt;&amp;lt;lang:Groovy&amp;gt;&lt;/code&gt;来定时加载groovy脚本，通过扫描监听指定路径下spring配置文件的变更。通过这样的方式来接受groovy脚本的新增、删除事件。同样触发器也允许用户自定义，框架提供了一个默认的触发器&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;GroovyRefreshedListener
    &lt;div class=&quot;highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;public interface GroovyRefreshTrigger {

  boolean isTriggered(Map&amp;lt;String, Long&amp;gt; resourcesLastModifiedMap, String groovyResourcesDir);
}
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;    &lt;/div&gt;
  &lt;/li&gt;
  &lt;li&gt;ResourceModifiedTrigger
    &lt;div class=&quot;highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;public class ResourceModifiedTrigger implements GroovyRefreshTrigger {
  public boolean isTriggered(Map&amp;lt;String, Long&amp;gt; resourcesLastModifiedMap, String groovyResourcesDir) {
      if (StringUtils.isBlank(groovyResourcesDir)) {
          groovyResourcesDir = this.getClass().getClassLoader().getResource(&quot;&quot;).getPath() + &quot;/spring/groovy&quot;;
      }
      File groovyFileDir = new File(groovyResourcesDir);
      List&amp;lt;File&amp;gt; groovyFileList = NamespacedGroovyLoader.getResourceListFromDir(groovyFileDir);
      for (File file : groovyFileList) {
          //新增
          if (!resourcesLastModifiedMap.containsKey(file.getName())) {
              return true;
          } else {
              //修改
              if (resourcesLastModifiedMap.get(file.getName()) != file.lastModified()) {
                  return true;
              }
          }
      }

      //删除
      if (resourcesLastModifiedMap.size() != groovyFileList.size()) {
          return true;
      }
      return false;
  }
}
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;    &lt;/div&gt;
    &lt;p&gt;默认的触发器就是通过spring配置文件上一次修改的时间，去判断文件是否被修改&lt;/p&gt;
  &lt;/li&gt;
&lt;/ul&gt;

&lt;h3 id=&quot;heading-groovy-loader&quot;&gt;groovy loader&lt;/h3&gt;
&lt;p&gt;初始化时会将指定目录下的groovy脚本动态加载成bean，并根据namespace注册到不同的Application容器中。注：以spring配置文件的名称作为namespace&lt;/p&gt;
&lt;div class=&quot;highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;private void initLoadResources() {
    if (MapUtils.isNotEmpty(this.namespacedContext)) {
        toDestoryContext = new ArrayList&amp;lt;FileSystemXmlApplicationContext&amp;gt;(this.namespacedContext.values());
    }
    this.namespacedContext = new HashMap&amp;lt;String, FileSystemXmlApplicationContext&amp;gt;();
    this.resourcesLastModifiedMap = new ConcurrentHashMap&amp;lt;String, Long&amp;gt;();
    //定位资源文件路径
    if (StringUtils.isBlank(groovyResourcesDir)) {
        groovyResourcesDir = this.getClass().getClassLoader().getResource(&quot;&quot;).getPath() + &quot;/spring/groovy&quot;;
    }
    File groovyFileDir = new File(groovyResourcesDir);
    List&amp;lt;File&amp;gt; groovyFileList = getResourceListFromDir(groovyFileDir);//获取指定目录下所有groovy脚本文件
    for (File file : groovyFileList) {
        FileSystemXmlApplicationContext context = new FileSystemXmlApplicationContext(new String[] {file.toURI().toString()}, true, parentContext);
        this.namespacedContext.put(file.getName().replace(&quot;xml&quot;, &quot;&quot;), context);
        this.resourcesLastModifiedMap.put(file.getName(), file.lastModified());
    }

    //触发监听器事件
    listener.groovyRefreshed(new GroovyRefreshedEvent(parentContext, this.namespacedContext));

    if (CollectionUtils.isNotEmpty(toDestoryContext)) {
        for (FileSystemXmlApplicationContext fileSystemXmlApplicationContext : toDestoryContext) {
            fileSystemXmlApplicationContext.close();
        }
    }
}
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;h3 id=&quot;heading-spring配置文件&quot;&gt;spring配置文件&lt;/h3&gt;
&lt;div class=&quot;highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;&lt;span class=&quot;cp&quot;&gt;&amp;lt;?xml version=&quot;1.0&quot; encoding=&quot;UTF-8&quot;?&amp;gt;&lt;/span&gt;
&lt;span class=&quot;nt&quot;&gt;&amp;lt;beans&lt;/span&gt; &lt;span class=&quot;na&quot;&gt;xmlns=&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;&quot;http://www.springframework.org/schema/beans&quot;&lt;/span&gt;
       &lt;span class=&quot;na&quot;&gt;xmlns:context=&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;&quot;http://www.springframework.org/schema/context&quot;&lt;/span&gt;
       &lt;span class=&quot;na&quot;&gt;xmlns:lang=&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;&quot;http://www.springframework.org/schema/lang&quot;&lt;/span&gt; &lt;span class=&quot;na&quot;&gt;xmlns:xsi=&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;&quot;http://www.w3.org/2001/XMLSchema-instance&quot;&lt;/span&gt;
       &lt;span class=&quot;na&quot;&gt;xsi:schemaLocation=&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;&quot;http://www.springframework.org/schema/beans http://www.springframework.org/schema/beans/spring-beans.xsd
    http://www.springframework.org/schema/context http://www.springframework.org/schema/context/spring-context.xsd
    http://www.springframework.org/schema/lang http://www.springframework.org/schema/lang/spring-lang.xsd &quot;&lt;/span&gt;&lt;span class=&quot;nt&quot;&gt;&amp;gt;&lt;/span&gt;

    &lt;span class=&quot;nt&quot;&gt;&amp;lt;context:annotation-config&lt;/span&gt; &lt;span class=&quot;nt&quot;&gt;/&amp;gt;&lt;/span&gt;

    &lt;span class=&quot;nt&quot;&gt;&amp;lt;lang:groovy&lt;/span&gt; &lt;span class=&quot;na&quot;&gt;id=&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;&quot;test&quot;&lt;/span&gt; &lt;span class=&quot;na&quot;&gt;refresh-check-delay=&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;&quot;2000&quot;&lt;/span&gt; &lt;span class=&quot;na&quot;&gt;proxy-target-class=&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;&quot;true&quot;&lt;/span&gt;
                 &lt;span class=&quot;na&quot;&gt;script-source=&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;&quot;classpath:groovy/one/Test.groovy&quot;&lt;/span&gt; &lt;span class=&quot;nt&quot;&gt;/&amp;gt;&lt;/span&gt;

&lt;span class=&quot;nt&quot;&gt;&amp;lt;/beans&amp;gt;&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;h1 id=&quot;heading-使用&quot;&gt;使用&lt;/h1&gt;
&lt;div class=&quot;highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;&amp;lt;bean id=&quot;listener&quot; class=&quot;org.cuner.groovy.loader.test.TestListener&quot;/&amp;gt;&amp;lt;!--需要实现org.cuner.groovy.loader.listener.GroovyRefreshedListener --&amp;gt;
&amp;lt;bean id=&quot;groovyLoader&quot; class=&quot;org.cuner.groovy.loader.NamespacedGroovyLoader&quot;&amp;gt;
    &amp;lt;property name=&quot;groovyResourcesDir&quot; value=&quot;&quot;/&amp;gt;&amp;lt;!--指定spring groovy配置文件目录，若不设置或者为空则默认为classpath下/spring/groovy目录--&amp;gt;
    &amp;lt;property name=&quot;listener&quot; ref=&quot;listener&quot;/&amp;gt;
    &amp;lt;property name=&quot;trigger&quot; ref=&quot;trigger&quot;/&amp;gt;
&amp;lt;/bean&amp;gt;
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;h1 id=&quot;heading-源码demo&quot;&gt;源码&amp;amp;Demo&lt;/h1&gt;
&lt;p&gt;代码托管在Github上，并附有使用demo，欢迎下载运行: https://github.com/Cuner/groovy-loader&lt;/p&gt;

&lt;h1 id=&quot;heading-版本升级-groovy-loader-v2&quot;&gt;版本升级 groovy-loader-v2&lt;/h1&gt;
&lt;p&gt;v1版本存在的缺陷在于：由于使用了&lt;code class=&quot;highlighter-rouge&quot;&gt;&amp;lt;lang:groovy&amp;gt;&lt;/code&gt;标签，spring定时去重加载groovy bean，即使这个bean没有被修改，由此会产生一些性能消耗问题。为了解决这点，v2实现了groovy脚本的加载以及groovy bean的注入。同时由定时扫描spring配置改为扫描目录下的所有groovy脚本来实现触发器。&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;GroovyScriptsModifiedTrigger
    &lt;div class=&quot;highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;public boolean isTriggered(Map&amp;lt;String, Long&amp;gt; lastScriptsModified, String baseDir) {
  if (StringUtils.isBlank(baseDir)) {
      baseDir = this.getClass().getClassLoader().getResource(&quot;&quot;).getPath() + &quot;/groovy&quot;;
  }

  List&amp;lt;File&amp;gt; fileList = getFileList(new File(baseDir));
  for (File file : fileList) {
      if (lastScriptsModified.get(file.getPath()) == null) {
          return true;
      }
      if (file.lastModified() != lastScriptsModified.get(file.getPath())) {
          return true;
      }
  }

  if (fileList.size() != lastScriptsModified.size()) {
      return true;
  }

  return false;
}
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;    &lt;/div&gt;
    &lt;p&gt;具体实现基本一致，区别在于外部传参baseDir由spring配置文件路径改为groovy脚本根目录路径。接下来我们看看是如何实现groovy脚本的加载以及groovy bean的注入。&lt;/p&gt;
  &lt;/li&gt;
  &lt;li&gt;NamespacedGroovyLoader&lt;/li&gt;
&lt;/ul&gt;

&lt;div class=&quot;highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;/**
 * 递归查找并加载namespace下的所有groovy文件
 * @param file
 * @param namespace
 */
private void scanGroovyFiles(File file, String namespace) throws Exception {
    if (!file.exists()) {
        return;
    }

    if (file.isFile() &amp;amp;&amp;amp; file.getName().endsWith(&quot;.groovy&quot;)) {
        ApplicationContext context = getOrCreateContext(namespace);
        DefaultListableBeanFactory beanFactory = (DefaultListableBeanFactory) context.getAutowireCapableBeanFactory();

        String scriptLocation = file.toURI().toString();
        if (scriptNotExists(context, scriptLocation)) {
            throw new IllegalArgumentException(&quot;script not exists : &quot; + scriptLocation);
        }
        scriptLastModifiedMap.put(file.getPath(), file.lastModified());

        String className = StringUtils.removeEnd(scriptLocation.substring(scriptLocation.indexOf(baseDir) + baseDir.length() + 1).replace(&quot;/&quot;, &quot;.&quot;), &quot;.groovy&quot;);
        // 只有GroovyBean声明的类才实例化
        DSLScriptSource scriptSource = new DSLScriptSource(new ResourceScriptSource(context.getResource(scriptLocation)), className);

        Class scriptClass = groovyClassLoader.parseClass(scriptSource.getScriptAsString(), scriptSource.suggestedClassName());

        // Tell Groovy we don't need any meta
        // information about these classes
        GroovySystem.getMetaClassRegistry().removeMetaClass(scriptClass);
        groovyClassLoader.clearCache();

        // Create script factory bean definition.
        GroovyScriptFactory groovyScriptFactory = new GroovyScriptFactory(scriptLocation);
        groovyScriptFactory.setBeanFactory(beanFactory);
        groovyScriptFactory.setBeanClassLoader(urlClassLoader);
        Object bean = groovyScriptFactory.getScriptedObject(scriptSource);
        if (bean == null) {
            //只有静态方法的groovy脚本(没有类声明)
            return;
        }

        // Tell Groovy we don't need any meta
        // information about these classes
        GroovySystem.getMetaClassRegistry().removeMetaClass(bean.getClass());
        groovyScriptFactory.getGroovyClassLoader().clearCache();

        String beanName = StringUtils.removeEnd(file.getName(), &quot;.groovy&quot;).toLowerCase();
        if (beanFactory.containsBean(beanName)) {
            beanFactory.destroySingleton(beanName); //移除单例bean
            removeInjectCache(context, bean); //移除注入缓存 否则Caused by: java.lang.IllegalArgumentException: object is not an instance of declaring class
        }
        beanFactory.registerSingleton(beanName, bean); //注册单例bean
        beanFactory.autowireBean(bean); //自动注入

    } else if (file.isDirectory()) {
        File[] subFiles = file.listFiles();
        for (File subFile : subFiles) {
            scanGroovyFiles(subFile, namespace);
        }
    }
}
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;p&gt;groovy文件夹下第一级文件夹名称拼接namespacePrefix作为namespace，每个namespace分配一个ApplicationContext容器，每个namespace对应的bean都由各自的beanfactory加载注入，避免同名类加载导致的错误。同时groovy脚本更新后产生新的groovy bean之后，还需要移除之前的groovy bean，值得额外注意的是需要移除注入缓存，否则会报错：Caused by: java.lang.IllegalArgumentException: object is not an instance of declaring class
注意：由于我们不需要groovy的metaclass信息，这里对metaClass进行清除来进行优化&lt;/p&gt;

&lt;p&gt;最后，附上代码:https://github.com/Cuner/groovy-loader-v2&lt;/p&gt;</content><author><name>{&quot;name&quot;=&gt;nil, &quot;job_title&quot;=&gt;nil, &quot;location&quot;=&gt;nil, &quot;email&quot;=&gt;nil, &quot;social_links&quot;=&gt;[{&quot;name&quot;=&gt;&quot;facebook&quot;, &quot;url&quot;=&gt;nil}, {&quot;name&quot;=&gt;&quot;github&quot;, &quot;url&quot;=&gt;&quot;https://github.com/Cuner&quot;}, {&quot;name&quot;=&gt;&quot;instagram&quot;, &quot;url&quot;=&gt;nil}, {&quot;name&quot;=&gt;&quot;linkedin&quot;, &quot;url&quot;=&gt;nil}, {&quot;name&quot;=&gt;&quot;stackoverflow&quot;, &quot;url&quot;=&gt;nil}, {&quot;name&quot;=&gt;&quot;twitter&quot;, &quot;url&quot;=&gt;nil}, {&quot;name&quot;=&gt;&quot;vk&quot;, &quot;url&quot;=&gt;nil}]}</name></author><category term="groovy" /><summary type="html">groovy loader背景 由于groovy动态语言的特性，使用方式与java一致，同时又特别适合与Spring的动态语言支持一起使用，所以基于java的groovy脚本的动态加载的使用场景还是比较多的</summary></entry><entry><title type="html">基于redis的分布式延时队列</title><link href="http://localhost:4000/blog/2018/05/30/delay-queue/" rel="alternate" type="text/html" title="基于redis的分布式延时队列" /><published>2018-05-30T00:00:00+08:00</published><updated>2018-05-30T00:00:00+08:00</updated><id>http://localhost:4000/blog/2018/05/30/delay-queue</id><content type="html" xml:base="http://localhost:4000/blog/2018/05/30/delay-queue/">&lt;p&gt;延时队列的使用场景非常多，目前集中式场景可以使用JDK自带的delayQueue，本文使用redis队列来实现两种分布式的延时队列，并进行了对比分析&lt;/p&gt;

&lt;h2 id=&quot;heading-1封装统一的队列消息结构&quot;&gt;1.封装统一的队列消息结构&lt;/h2&gt;
&lt;div class=&quot;highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;public class DelayMessage {

    /**
     * 正执行消息的token
     */
    private String tmpKey;

    /**
     * 消息内容
     */
    private String message;

    /**
     * 延迟时间 纳秒
     */
    private long delay;

    /**
     * 到期时间 纳秒
     */
    private long expire;

    /**
     * 创建时间 纳秒
     */
    private long registerTime;
    
    ...
}
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;h2 id=&quot;heading-2-同步延时队列&quot;&gt;2. 同步延时队列&lt;/h2&gt;
&lt;p&gt;原理：通过LRANG获取队列头部元素，从而获得到期时间，当数据达到到期时间后，通过LPOP取出数据。并发情况下会加分布式锁，同一时刻只能有一个线程访问队列并阻塞等待数据准备完成(达到延时时间)。当线程获取到可以返回的数据后，才能释放锁。&lt;/p&gt;
&lt;div class=&quot;highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;public DelayMessage pop() {
    while (true) {
        Long waitTime = null;
        Jedis jedis = jedisPool.getResource();
        try {
            if (this.syn) {
                lock.lock(this.queueName);
            }
            //获取头部的数据
            List&amp;lt;String&amp;gt; dataList = jedis.lrange(this.queueName, 0L, 0L);
            if (CollectionUtils.isNotEmpty(dataList)) {
                String data = dataList.get(0);
                DelayMessage message = gson.fromJson(data, DelayMessage.class);
                if (message != null) {
                    long now = System.nanoTime();
                    if (message.getExpire() &amp;gt; now) {
                        //没有到期
                        waitTime = message.getExpire() - now;
                    } else {
                        jedis.lpop(this.queueName);
                        return message;
                    }
                }
            }

            if (waitTime != null) {
                try {
                    Thread.sleep(waitTime / 1000);
                } catch (InterruptedException e) {
                    //do nothing
                }
            }

        } finally {
            if (this.syn) {
                lock.unlock(this.queueName);
            }
            jedis.close();
        }
    }
}
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;
&lt;ul&gt;
  &lt;li&gt;基于redis，&lt;strong&gt;并发情况下会加分布式锁&lt;/strong&gt;，单线程场景（syn=false）性能较好， 并发场景性能较差&lt;/li&gt;
  &lt;li&gt;&lt;strong&gt;若在并发场景下，设置syn=false，会导致消息重复消费、消息丢失的情况&lt;/strong&gt;&lt;/li&gt;
  &lt;li&gt;支持delay时间的动态调整&lt;/li&gt;
&lt;/ul&gt;

&lt;h2 id=&quot;heading-3-并发延时队列&quot;&gt;3. 并发延时队列&lt;/h2&gt;
&lt;p&gt;原理：直接通过LPOP取出数据，当数据达到到期时间后立即返回，若未达到到期时间，线程sleep至到期时间后将数据返回。这样就允许队列在无分布式锁的情况下并行消费。
存在的问题：从数据LPOP移除队列到数据返回之间有一段时间间隔，如果系统在这段时间出现异常，比如宕机、重启等等，就会出现数据丢失的情况。为了避免此种情况，引入了ack的方式，在通过LPOP去除数据后，随机将数据存储到另外一个临时redis set中，在用户接受到消息并处理完成后手动执行ack方法后才将数据从临时set中移除。而在机器重启时，再将改临时set里面的数据重新put到延时队列中。&lt;/p&gt;
&lt;div class=&quot;highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;public DelayMessage pop() {
    while (true) {
        Long waitTime;
        Jedis jedis = jedisPool.getResource();
        try {
            // 取队列头部的消息
            String result = jedis.lpop(queueName);
            // 队列非空
            if (result != null) {
                //暂存此条消息，放入执行集合
                String tmpKey = null;
                if (!autoAck) {
                    tmpKey = this.setExeMsg(result);//解决宕机数据丢失
                }
                DelayMessage delayMessage = gson.fromJson(result, DelayMessage.class);
                if (delayMessage != null) {
                    if (delayMessage.getExpire() &amp;gt; System.nanoTime()) {
                        // 消息未到可执行状态,休眠等待
                        waitTime = delayMessage.getExpire() - System.nanoTime();
                        try {
                            Thread.sleep(waitTime);
                        } catch (InterruptedException e) {
                            // do nothing
                        }
                    }
                    delayMessage.setTmpKey(tmpKey);
                    return delayMessage;
                }
            }
        } finally {
            jedis.close();
        }
    }
}
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;ul&gt;
  &lt;li&gt;基于redis，支持在&lt;strong&gt;无分布式锁&lt;/strong&gt;的情况下进行并发消费&lt;/li&gt;
  &lt;li&gt;autoAck为true时，吞吐量性能极好，autoAck为false，吞吐量会稍有下降&lt;/li&gt;
  &lt;li&gt;支持delay时间的动态调整&lt;/li&gt;
  &lt;li&gt;&lt;strong&gt;autoAck为false时，必须在处理完消息后手动调用ack方法，否则会导致应用重启后重新开始消费&lt;/strong&gt;&lt;/li&gt;
&lt;/ul&gt;

&lt;h2 id=&quot;heading-4性能对比&quot;&gt;4.性能对比&lt;/h2&gt;

&lt;ul&gt;
  &lt;li&gt;RedisConcurrentDelayQueue和RedisSynDelayQueue的简单对比，数据是线下单机环境测试数据&lt;/li&gt;
&lt;/ul&gt;

&lt;table&gt;
  &lt;thead&gt;
    &lt;tr&gt;
      &lt;th style=&quot;text-align: center&quot;&gt;队列种类&lt;/th&gt;
      &lt;th style=&quot;text-align: center&quot;&gt;消费线程数&lt;/th&gt;
      &lt;th style=&quot;text-align: center&quot;&gt;syn&lt;/th&gt;
      &lt;th style=&quot;text-align: center&quot;&gt;autoAck&lt;/th&gt;
      &lt;th style=&quot;text-align: center&quot;&gt;耗时&lt;/th&gt;
      &lt;th style=&quot;text-align: center&quot;&gt;消息丢失&lt;/th&gt;
      &lt;th style=&quot;text-align: center&quot;&gt;重复消费&lt;/th&gt;
    &lt;/tr&gt;
  &lt;/thead&gt;
  &lt;tbody&gt;
    &lt;tr&gt;
      &lt;td style=&quot;text-align: center&quot;&gt;RedisConcurrentDelayQueue&lt;/td&gt;
      &lt;td style=&quot;text-align: center&quot;&gt;1&lt;/td&gt;
      &lt;td style=&quot;text-align: center&quot;&gt;-&lt;/td&gt;
      &lt;td style=&quot;text-align: center&quot;&gt;false&lt;/td&gt;
      &lt;td style=&quot;text-align: center&quot;&gt;53936ms&lt;/td&gt;
      &lt;td style=&quot;text-align: center&quot;&gt;无&lt;/td&gt;
      &lt;td style=&quot;text-align: center&quot;&gt;无&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td style=&quot;text-align: center&quot;&gt;RedisConcurrentDelayQueue&lt;/td&gt;
      &lt;td style=&quot;text-align: center&quot;&gt;1&lt;/td&gt;
      &lt;td style=&quot;text-align: center&quot;&gt;-&lt;/td&gt;
      &lt;td style=&quot;text-align: center&quot;&gt;true&lt;/td&gt;
      &lt;td style=&quot;text-align: center&quot;&gt;13130ms&lt;/td&gt;
      &lt;td style=&quot;text-align: center&quot;&gt;消费进程关闭，正在处理的消息会丢失&lt;/td&gt;
      &lt;td style=&quot;text-align: center&quot;&gt;无&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td style=&quot;text-align: center&quot;&gt;RedisSynDelayQueue&lt;/td&gt;
      &lt;td style=&quot;text-align: center&quot;&gt;1&lt;/td&gt;
      &lt;td style=&quot;text-align: center&quot;&gt;true&lt;/td&gt;
      &lt;td style=&quot;text-align: center&quot;&gt;-&lt;/td&gt;
      &lt;td style=&quot;text-align: center&quot;&gt;55420ms&lt;/td&gt;
      &lt;td style=&quot;text-align: center&quot;&gt;无&lt;/td&gt;
      &lt;td style=&quot;text-align: center&quot;&gt;无&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td style=&quot;text-align: center&quot;&gt;RedisSynDelayQueue&lt;/td&gt;
      &lt;td style=&quot;text-align: center&quot;&gt;1&lt;/td&gt;
      &lt;td style=&quot;text-align: center&quot;&gt;false&lt;/td&gt;
      &lt;td style=&quot;text-align: center&quot;&gt;-&lt;/td&gt;
      &lt;td style=&quot;text-align: center&quot;&gt;20012ms&lt;/td&gt;
      &lt;td style=&quot;text-align: center&quot;&gt;无&lt;/td&gt;
      &lt;td style=&quot;text-align: center&quot;&gt;无&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td style=&quot;text-align: center&quot;&gt;RedisConcurrentDelayQueue&lt;/td&gt;
      &lt;td style=&quot;text-align: center&quot;&gt;10&lt;/td&gt;
      &lt;td style=&quot;text-align: center&quot;&gt;-&lt;/td&gt;
      &lt;td style=&quot;text-align: center&quot;&gt;false&lt;/td&gt;
      &lt;td style=&quot;text-align: center&quot;&gt;7279ms&lt;/td&gt;
      &lt;td style=&quot;text-align: center&quot;&gt;无&lt;/td&gt;
      &lt;td style=&quot;text-align: center&quot;&gt;无&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td style=&quot;text-align: center&quot;&gt;RedisConcurrentDelayQueue&lt;/td&gt;
      &lt;td style=&quot;text-align: center&quot;&gt;10&lt;/td&gt;
      &lt;td style=&quot;text-align: center&quot;&gt;-&lt;/td&gt;
      &lt;td style=&quot;text-align: center&quot;&gt;true&lt;/td&gt;
      &lt;td style=&quot;text-align: center&quot;&gt;1181ms&lt;/td&gt;
      &lt;td style=&quot;text-align: center&quot;&gt;消费进程关闭，正在处理的消息会丢失&lt;/td&gt;
      &lt;td style=&quot;text-align: center&quot;&gt;无&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td style=&quot;text-align: center&quot;&gt;RedisSynDelayQueue&lt;/td&gt;
      &lt;td style=&quot;text-align: center&quot;&gt;10&lt;/td&gt;
      &lt;td style=&quot;text-align: center&quot;&gt;true&lt;/td&gt;
      &lt;td style=&quot;text-align: center&quot;&gt;-&lt;/td&gt;
      &lt;td style=&quot;text-align: center&quot;&gt;61532ms&lt;/td&gt;
      &lt;td style=&quot;text-align: center&quot;&gt;无&lt;/td&gt;
      &lt;td style=&quot;text-align: center&quot;&gt;无&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td style=&quot;text-align: center&quot;&gt;RedisSynDelayQueue&lt;/td&gt;
      &lt;td style=&quot;text-align: center&quot;&gt;10&lt;/td&gt;
      &lt;td style=&quot;text-align: center&quot;&gt;false&lt;/td&gt;
      &lt;td style=&quot;text-align: center&quot;&gt;-&lt;/td&gt;
      &lt;td style=&quot;text-align: center&quot;&gt;-&lt;/td&gt;
      &lt;td style=&quot;text-align: center&quot;&gt;大量消息丢失&lt;/td&gt;
      &lt;td style=&quot;text-align: center&quot;&gt;大量重复消费&lt;/td&gt;
    &lt;/tr&gt;
  &lt;/tbody&gt;
&lt;/table&gt;

&lt;ol&gt;
  &lt;li&gt;若能接受系统重启、关闭时的少量消息丢失，推荐RedisConcurrentDelayQueue，并设置autoAck为true：性能最好，且消费线程越多，消费速度（吞吐量）也会相对越好&lt;/li&gt;
  &lt;li&gt;若不能接受消息丢失，在单机、单线程消费的场景下，可以选择RedisConcurrentDelayQueue（autoAck设置为false）RedisSynDelayQueue（syn设置为false）；&lt;/li&gt;
  &lt;li&gt;若不能接受消息丢失，且需要在多线程、分布式场景下消费，推荐推荐RedisConcurrentDelayQueue（autoAck设置为false），消费线程越多，消费速度（吞吐量）也会相对越好；&lt;/li&gt;
  &lt;li&gt;RedisSynDelayQueue在并发消费的场景下性能较差，不推荐使用。&lt;/li&gt;
&lt;/ol&gt;

&lt;h2 id=&quot;heading-5项目代码&quot;&gt;5.项目代码&lt;/h2&gt;
&lt;p&gt;代码托管在Github上，并附有使用demo，欢迎下载运行: https://github.com/Cuner/delay-queue&lt;/p&gt;

&lt;h2 id=&quot;heading-6切换思路&quot;&gt;6.切换思路&lt;/h2&gt;
&lt;p&gt;当有延时任务或者延时消息产生时，暂时将延时任务/消息存放至某个容器里面(可以是数据记录的方式存储在db，也可以存储在redis zset中等等)，然后采用定时器不断去轮训容器里面的各个延时任务/消息，当扫描获取到达到过期时间的延时任务/消息后，将其推送到消息队列中以供消费，推送成功后再将其从容器里移除。
值得注意的是，同一个达到到期时间的延时任务/消息，可能会被连续的两次扫描命中（延时任务/消息从容器移除有延时），最后导致消息重复消费。&lt;/p&gt;

&lt;p&gt;参考：&lt;a href=&quot;https://tech.youzan.com/queuing_delay/&quot;&gt;有赞延迟队列设计&lt;/a&gt;&lt;/p&gt;</content><author><name>{&quot;name&quot;=&gt;nil, &quot;job_title&quot;=&gt;nil, &quot;location&quot;=&gt;nil, &quot;email&quot;=&gt;nil, &quot;social_links&quot;=&gt;[{&quot;name&quot;=&gt;&quot;facebook&quot;, &quot;url&quot;=&gt;nil}, {&quot;name&quot;=&gt;&quot;github&quot;, &quot;url&quot;=&gt;&quot;https://github.com/Cuner&quot;}, {&quot;name&quot;=&gt;&quot;instagram&quot;, &quot;url&quot;=&gt;nil}, {&quot;name&quot;=&gt;&quot;linkedin&quot;, &quot;url&quot;=&gt;nil}, {&quot;name&quot;=&gt;&quot;stackoverflow&quot;, &quot;url&quot;=&gt;nil}, {&quot;name&quot;=&gt;&quot;twitter&quot;, &quot;url&quot;=&gt;nil}, {&quot;name&quot;=&gt;&quot;vk&quot;, &quot;url&quot;=&gt;nil}]}</name></author><category term="queue" /><summary type="html">延时队列的使用场景非常多，目前集中式场景可以使用JDK自带的delayQueue，本文使用redis队列来实现两种分布式的延时队列，并进行了对比分析</summary></entry><entry><title type="html">SPI框架（一）</title><link href="http://localhost:4000/blog/2018/05/24/spi-framework/" rel="alternate" type="text/html" title="SPI框架（一）" /><published>2018-05-24T00:00:00+08:00</published><updated>2018-05-24T00:00:00+08:00</updated><id>http://localhost:4000/blog/2018/05/24/spi-framework</id><content type="html" xml:base="http://localhost:4000/blog/2018/05/24/spi-framework/">&lt;p&gt;SPI的全名为Service Provider Interface。根据Java的SPI规范，我们可以定义一个服务接口，具体的实现由对应的实现者去提供，即Service Provider（服务提供者）。然后在使用的时候只要根据SPI的规范去获取对应的服务提供者的服务实现即可。简单来说，SPI就是一种为接口寻找服务的机制，基于这种机制，本文提出一种基于动态代理的spi框架的实现方式。&lt;/p&gt;

&lt;h2 id=&quot;heading-1-基于统一的接口&quot;&gt;1 基于统一的接口&lt;/h2&gt;
&lt;p&gt;该SPI框架的核心思想是通过JDK动态代理（代理对象必须为某个接口的实现），为接口寻找满足条件的服务实现。基于上述要求，需要提供一个统一的接口。&lt;/p&gt;
&lt;div class=&quot;highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;public interface SpiBase&amp;lt;T, R&amp;gt; {

    /**
     * 是否执行当前实现的条件
     * @param query
     * @return
     */
    boolean condition(T query);

    /**
     * 具体操作
     * @param query
     * @return
     */
    List&amp;lt;R&amp;gt; invoke(T query);

    /**
     * spi执行时候的配置
     * @param query
     * @return
     */
    SpiConfig config(T query);
}
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;p&gt;作为框架，需要尽可能的符合各类场景&lt;/p&gt;
&lt;ul&gt;
  &lt;li&gt;提供condition方法以及模板类T参数，让用户自定义符合接口实现的要求&lt;/li&gt;
  &lt;li&gt;提供统一的invoke方法来统一服务的某一类行为&lt;/li&gt;
  &lt;li&gt;提供spi执行的config，用来扩展寻求实现的策略&lt;/li&gt;
&lt;/ul&gt;

&lt;div class=&quot;highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;public class SpiConfig {

    /**
     * 是否互斥
     * false:满足执行条件的其他实现也一并调用
     * true:当前实现满足执行要求并执行成功后直接返回，忽略满足执行条件的其他实现
     */
    private boolean mutex;

    /**
     * 优先值
     * 该值越高，执行优先级越高
     */
    private int priority;

    /**
     * 名称 作为标识
     */
    private String name;
    
    ....
}
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;ul&gt;
  &lt;li&gt;参数mutex，决定了某个接口，当有多个满足条件的服务实现时的执行策略，是只选择优先级最高的服务实现去执行，还是说按照优先级顺序多个服务实现顺序执行后将结果合并返回（这也是为什么invoke方法返回list的原因）。&lt;/li&gt;
  &lt;li&gt;参数priority，决定某个服务实现的执行优先级，优先级越高，越先执行&lt;/li&gt;
&lt;/ul&gt;

&lt;h2 id=&quot;heading-2-获取所有用户自定义的服务实现并实例化&quot;&gt;2 获取所有用户自定义的服务实现并实例化&lt;/h2&gt;

&lt;p&gt;2.1 提供注解@BizSpi&lt;/p&gt;
&lt;div class=&quot;highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;@Target({ElementType.TYPE})//目标作用于类
@Retention(RetentionPolicy.RUNTIME)// 注解在class字节码文件中存在，在运行时可以通过反射获取到
@Documented
@Service
public @interface BizSpi {
}
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;p&gt;为了方便的找到用户提供的服务实现类，框架约束用户在其提供的服务实现类上加上注解@BizSpi，当然所有的服务实现类都需要实现统一的接口SpiBase，也可以实现某个继承SpiBase接口的自定义接口。&lt;/p&gt;

&lt;p&gt;2.2 实例化服务实现并保存至内存&lt;/p&gt;
&lt;div class=&quot;highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;public class SpiManager implements ApplicationListener&amp;lt;ContextRefreshedEvent&amp;gt; {

    private static Map&amp;lt;Class, List&amp;lt;SpiBase&amp;gt;&amp;gt; spiProviderMap = new ConcurrentHashMap&amp;lt;Class, List&amp;lt;SpiBase&amp;gt;&amp;gt;();

    private static volatile boolean isLoaded = false;

    public void onApplicationEvent(ContextRefreshedEvent contextRefreshedEvent) {
        if (!isLoaded) {
            Map&amp;lt;String, Object&amp;gt; spiInstanceMap = contextRefreshedEvent.getApplicationContext().getBeansWithAnnotation(BizSpi.class);

            for (Object spiInstance : spiInstanceMap.values()) {
                Class spiInterface = spiInstance.getClass().getInterfaces()[0];
                if (spiProviderMap.containsKey(spiInterface) &amp;amp;&amp;amp; spiProviderMap.get(spiInterface).size() &amp;gt; 0) {
                    spiProviderMap.get(spiInterface).add((SpiBase) spiInstance);
                } else {
                    List&amp;lt;SpiBase&amp;gt; spiProviderList = new ArrayList&amp;lt;SpiBase&amp;gt;();
                    spiProviderList.add((SpiBase) spiInstance);
                    spiProviderMap.put(spiInterface, spiProviderList);
                }
            }

            for (List&amp;lt;SpiBase&amp;gt; spiProviderList : spiProviderMap.values()) {
                Collections.sort(spiProviderList, new Comparator&amp;lt;SpiBase&amp;gt;() {
                    public int compare(SpiBase spiBase1, SpiBase spiBase2) {
                        return spiBase2.config(null).getPriority() - spiBase1.config(null).getPriority();
                    }
                });
            }
        }
        isLoaded = true;
    }

    public static List&amp;lt;SpiBase&amp;gt; getSpiProviderMap(Class spiInterface) {
        return spiProviderMap.get(spiInterface);
    }

}
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;p&gt;这里通过约束的注解@BizSpi来拿到所有服务实现实例化后的对象，通过spiProviderMap来保存管理，其中spiProviderMap的key的集合是所有服务实现所实现的第一级接口（可以是SpiBase，也可以是继承自SpiBase的自定义接口），value则是key代表的接口所对应的所有服务实现实例化后的对象列表（可以看到列表通过SpiConfig中的priority值进行了重排序）。&lt;/p&gt;

&lt;h2 id=&quot;heading-3动态代理&quot;&gt;3.动态代理&lt;/h2&gt;
&lt;div class=&quot;highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;public class SpiProviderFactory&amp;lt;T&amp;gt; implements FactoryBean&amp;lt;T&amp;gt; {

    private Logger logger = LoggerFactory.getLogger(SpiProviderFactory.class);

    private Class&amp;lt;T&amp;gt; targetClass;

    public T getObject() throws Exception {
        InvocationHandler invocationHandler = new InvocationHandler() {
            public Object invoke(Object proxy, Method method, Object[] args) throws Throwable {
                List&amp;lt;SpiBase&amp;gt; spiList = SpiManager.getSpiProviderMap(targetClass);

                // 支持组合,所以必须返回list; 每一个功能点实现也必须返回list
                List combinationResult = new ArrayList();
                for (SpiBase spi : spiList) {
                    if (SpiBase.class.isInstance(spi)) {
                        if (args != null &amp;amp;&amp;amp; spi.condition(args[0])) {
                            SpiConfig spiConfig = spi.config(args[0]);
                            List result = (List) method.invoke(spi, args);
                            if (result != null) {
                                combinationResult.addAll(result);
                                if (spiConfig.isMutex()) {
                                    break;
                                }
                            }
                        }
                    }
                }
                return combinationResult;
            }
        };
        return (T) Proxy.newProxyInstance(Thread.currentThread().getContextClassLoader(),
                new Class[]{targetClass},
                invocationHandler);
    }
   ...
}
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;p&gt;这里用到了工厂，这里需要传入参数targetClass，因为我们需要代理的接口可能是继承了SpiBase的自定义接口。通过服务实现类提供的condition方法可以从spiProviderMap中找到满足条件的服务，在通过SpiConfig的中参数决定服务执行的策略，最终将结果返回。&lt;/p&gt;

&lt;h2 id=&quot;heading-4使用步骤&quot;&gt;4.使用步骤&lt;/h2&gt;
&lt;p&gt;1.继承SpiBase得到自定义的SPI接口(可以添加自定义方法)
2.为SPI接口提供多个服务实现类(注意类需要加上注解@BizSpi)，condition方法决定了服务是否满足执行条件，config方法返回的SpiConfig对象决定了服务执行的策略
3.spring配置&lt;/p&gt;
&lt;div class=&quot;highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;    &amp;lt;!--扫描spi框架--&amp;gt;
    &amp;lt;context:component-scan base-package=&quot;org.cuner.spi.framework&quot;/&amp;gt;

    &amp;lt;!--还需要扫描到你自己的服务实现类--&amp;gt;
    
    &amp;lt;bean id=&quot;demoSpi&quot; class=&quot;org.cuner.spi.framework.core.SpiProviderFactory&quot;&amp;gt;
        &amp;lt;property name=&quot;targetClass&quot; value=&quot;org.cuner.spi.framework.demo.api.demoSpi&quot;/&amp;gt;
    &amp;lt;/bean&amp;gt;
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;
&lt;p&gt;4.spring注入后使用&lt;/p&gt;
&lt;div class=&quot;highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;    @Resource(name = &quot;demoSpi&quot;)
    private DemoSpi demoSpi;
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;p&gt;5.demo
代码托管在Github上，并附有使用demo，欢迎下载运行: https://github.com/Cuner/spi-framework&lt;/p&gt;</content><author><name>{&quot;name&quot;=&gt;nil, &quot;job_title&quot;=&gt;nil, &quot;location&quot;=&gt;nil, &quot;email&quot;=&gt;nil, &quot;social_links&quot;=&gt;[{&quot;name&quot;=&gt;&quot;facebook&quot;, &quot;url&quot;=&gt;nil}, {&quot;name&quot;=&gt;&quot;github&quot;, &quot;url&quot;=&gt;&quot;https://github.com/Cuner&quot;}, {&quot;name&quot;=&gt;&quot;instagram&quot;, &quot;url&quot;=&gt;nil}, {&quot;name&quot;=&gt;&quot;linkedin&quot;, &quot;url&quot;=&gt;nil}, {&quot;name&quot;=&gt;&quot;stackoverflow&quot;, &quot;url&quot;=&gt;nil}, {&quot;name&quot;=&gt;&quot;twitter&quot;, &quot;url&quot;=&gt;nil}, {&quot;name&quot;=&gt;&quot;vk&quot;, &quot;url&quot;=&gt;nil}]}</name></author><category term="SPI" /><summary type="html">SPI的全名为Service Provider Interface。根据Java的SPI规范，我们可以定义一个服务接口，具体的实现由对应的实现者去提供，即Service Provider（服务提供者）。然后在使用的时候只要根据SPI的规范去获取对应的服务提供者的服务实现即可。简单来说，SPI就是一种为接口寻找服务的机制，基于这种机制，本文提出一种基于动态代理的spi框架的实现方式。</summary></entry><entry><title type="html">lucene简介和索引原理</title><link href="http://localhost:4000/blog/2018/04/26/apache-lucene-intro-and-index/" rel="alternate" type="text/html" title="lucene简介和索引原理" /><published>2018-04-26T00:00:00+08:00</published><updated>2018-04-26T00:00:00+08:00</updated><id>http://localhost:4000/blog/2018/04/26/apache-lucene-intro-and-index</id><content type="html" xml:base="http://localhost:4000/blog/2018/04/26/apache-lucene-intro-and-index/">&lt;h1 id=&quot;heading-lucene简介和索引原理&quot;&gt;lucene简介和索引原理&lt;/h1&gt;

&lt;h2 id=&quot;heading-lucene简介&quot;&gt;Lucene简介&lt;/h2&gt;
&lt;p&gt;Lucene是一个高效，全Java实现、开源、高性能、功能完整、易拓展，支持分词以及各种查询方式（前缀、模糊、正则等）、打分高亮、列式存储（DocValues）
的全文检索库。仅支持纯文本文件的索引和搜索。&lt;/p&gt;

&lt;center&gt;&lt;img src=&quot;/assets/images/post/2018-04-26-apache-lucene-intro-and-index/lucene-intro.png&quot; width=&quot;500px&quot; /&gt;&lt;/center&gt;

&lt;h2 id=&quot;heading-lucene索引原理&quot;&gt;lucene索引原理&lt;/h2&gt;
&lt;p&gt;每个字符串都指向包含此字符串的文档(Document)链表，此文档链表称为倒排表&lt;/p&gt;

&lt;center&gt;&lt;img src=&quot;/assets/images/post/2018-04-26-apache-lucene-intro-and-index/index-construction.png&quot; width=&quot;500px&quot; /&gt;&lt;/center&gt;

&lt;h3 id=&quot;heading-索引创建过程&quot;&gt;索引创建过程&lt;/h3&gt;

&lt;center&gt;&lt;img src=&quot;/assets/images/post/2018-04-26-apache-lucene-intro-and-index/index-create-step.png&quot; width=&quot;700px&quot; /&gt;&lt;/center&gt;

&lt;p&gt;1.需要被索引的原文档(document)&lt;/p&gt;

&lt;p&gt;2.将原文档传给分词组件(Tokenizer)，分词后得到词元(Token)&lt;/p&gt;

&lt;p&gt;3.将得到的词元(Token)传给语言处理组件(Linguistic Processor)，进行一些语法转化：包括字母转为小写、缩减(复数变单数)、转变(过去时转变为词根)，将词语转化为词根(Term)&lt;/p&gt;

&lt;p&gt;4.将得到的词(Term)传给索引组件(Indexer)，得到词典和倒排链表(反向索引表)&lt;/p&gt;

&lt;p&gt;5.通过索引存储将索引写入硬盘&lt;/p&gt;

&lt;h3 id=&quot;heading-检索过程&quot;&gt;检索过程&lt;/h3&gt;

&lt;center&gt;&lt;img src=&quot;/assets/images/post/2018-04-26-apache-lucene-intro-and-index/index-search-step.png&quot; width=&quot;700px&quot; /&gt;&lt;/center&gt;

&lt;p&gt;1.用户输入查询语句&lt;/p&gt;

&lt;p&gt;2.对查询语句进行词法分析得到单词以及关键字(关键字有AND, NOT)，然后对得到的单词进行语言处理(同索引过程中的语言处理几乎相同)得到查询词根Term&lt;/p&gt;

&lt;p&gt;3.语法分析，根据查询语句的语法规则来形成一棵语法树。&lt;/p&gt;

&lt;p&gt;4.通过索引存储将索引读入到内存。&lt;/p&gt;

&lt;p&gt;5.利用查询树搜索索引，从而得到每个词(Term) 的文档链表，对文档链表进行交，差，并得到结果文档&lt;/p&gt;

&lt;p&gt;6.根据得到的文档和查询语句的相关性，对结果进行排序。(向量空间模型算法:通过各个关键词根在不同文档中的权重来比较文档与查询语句的相关性)&lt;/p&gt;

&lt;h3 id=&quot;heading-lucene索引基本概念&quot;&gt;lucene索引基本概念&lt;/h3&gt;

&lt;ul&gt;
  &lt;li&gt;索引(index)
    &lt;ul&gt;
      &lt;li&gt;在Lucene中一个索引是放在一个文件夹中的&lt;/li&gt;
    &lt;/ul&gt;
  &lt;/li&gt;
  &lt;li&gt;段(segment)
    &lt;ul&gt;
      &lt;li&gt;一个索引可以包含多个段，段与段之间是独立的，添加新文档可以生成新的段，不同的段可以合并&lt;/li&gt;
    &lt;/ul&gt;
  &lt;/li&gt;
  &lt;li&gt;文档(document)
    &lt;ul&gt;
      &lt;li&gt;文档是我们建索引的基本单位，不同的文档是保存在不同的段中的，一个段可以包含多篇文档&lt;/li&gt;
      &lt;li&gt;新添加的文档是单独保存在一个新生成的段中，随着段的合并，不同的文档合并到同一个段中&lt;/li&gt;
    &lt;/ul&gt;
  &lt;/li&gt;
  &lt;li&gt;域(field)
    &lt;ul&gt;
      &lt;li&gt;一篇文档包含不同类型的信息，可以分开索引，比如标题，时间，正文，作者等，都可以保存在不同的域里&lt;/li&gt;
    &lt;/ul&gt;
  &lt;/li&gt;
  &lt;li&gt;词(term)
    &lt;ul&gt;
      &lt;li&gt;词是索引的最小单位，是经过词法分析和语言处理后的字符串&lt;/li&gt;
    &lt;/ul&gt;
  &lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;Lucene的索引结构中，即保存了正向信息，也保存了反向信息&lt;/p&gt;
&lt;ul&gt;
  &lt;li&gt;正向信息：按层次保存了从索引，一直到词的包含关系：索引(Index) –&amp;gt; 段(segment) –&amp;gt; 文档(Document) –&amp;gt; 域(Field) –&amp;gt; 词(Term)，也即此索引包含了那些段，每个段包含了那些文档，每个文档包含了那些域，每个域包含了那些词&lt;/li&gt;
  &lt;li&gt;反向信息：保存了词典到倒排表的映射：词(Term) –&amp;gt; 文档(Document)&lt;/li&gt;
&lt;/ul&gt;

&lt;h3 id=&quot;heading-lucene结构&quot;&gt;lucene结构&lt;/h3&gt;
&lt;p&gt;全文索引绝大多数是通过倒排索引来做，倒排索引由两个部分组成，即词典和倒排表&lt;/p&gt;

&lt;h4 id=&quot;heading-索引结构&quot;&gt;索引结构&lt;/h4&gt;
&lt;p&gt;lucene从4开始大量使用的数据结构是FST（Finite State Transducer）。FST有两个优点：&lt;/p&gt;

&lt;p&gt;1）空间占用小。通过对词典中单词前缀和后缀的重复利用，压缩了存储空间，压缩率一般在3倍~20倍之间；&lt;/p&gt;

&lt;p&gt;2）查询速度快。O(len(str))的查询时间复杂度。&lt;/p&gt;

&lt;p&gt;3) 模糊查询支持比较好&lt;/p&gt;

&lt;p&gt;4）输入要求有序，更新较为困难&lt;/p&gt;

&lt;p&gt;索引文件：
我们往索引库里插入四个单词abd、abe、acf、acg，看看它的索引文件内容&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;tip部分，每列一个FST索引，所以会有多个FST，每个FST存放前缀和后缀块指针，这里前缀就为a、ab、ac&lt;/li&gt;
  &lt;li&gt;tim里面存放后缀块和词的其他信息如倒排表指针、TFDF等&lt;/li&gt;
  &lt;li&gt;doc文件里就为每个单词的倒排表。&lt;/li&gt;
&lt;/ul&gt;

&lt;center&gt;&lt;img src=&quot;/assets/images/post/2018-04-26-apache-lucene-intro-and-index/index-file-construction.png&quot; width=&quot;700px&quot; /&gt;&lt;/center&gt;

&lt;p&gt;所以它的检索过程分为三个步骤：&lt;/p&gt;
&lt;ol&gt;
  &lt;li&gt;内存加载tip文件，通过FST匹配前缀找到后缀词块位置。&lt;/li&gt;
  &lt;li&gt;根据词块位置，读取磁盘中tim文件中后缀块并找到后缀和相应的倒排表位置信息。&lt;/li&gt;
  &lt;li&gt;根据倒排表位置去doc文件中加载倒排表&lt;/li&gt;
&lt;/ol&gt;

&lt;center&gt;&lt;img src=&quot;/assets/images/post/2018-04-26-apache-lucene-intro-and-index/index-create-example.png&quot; width=&quot;700px&quot; /&gt;&lt;/center&gt;

&lt;ul&gt;
  &lt;li&gt;插入abd时，没有输出&lt;/li&gt;
  &lt;li&gt;插入abe时，计算出前缀ab，但此时不知道后续还不会有其他以ab为前缀的词，所以此时无输出。&lt;/li&gt;
  &lt;li&gt;插入acf时，因为是有序的，知道不会再有ab前缀的词了，这时就可以写tip和tim了，tim中写入后缀词块d、e和它们的倒排表位置ip_d,ip_e，tip中写入a，b和以ab为前缀的后缀词块位置&lt;/li&gt;
  &lt;li&gt;插入acg时，计算出和acf共享前缀ac，这时输入已经结束，所有数据写入磁盘。tim中写入后缀词块f、g和相对应的倒排表位置，tip中写入c和以ac为前缀的后缀词块位置&lt;/li&gt;
&lt;/ul&gt;

&lt;h4 id=&quot;heading-倒排表结构&quot;&gt;倒排表结构&lt;/h4&gt;
&lt;p&gt;Lucene现使用的倒排表结构叫&lt;a href=&quot;https://www.elastic.co/blog/frame-of-reference-and-roaring-bitmaps&quot;&gt;Frame of reference&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;数据压缩：
下图：将6个数字从原先的24bytes压缩到7bytes
注：step1到step2的得到的新数组是后尾数减去前位数得到的&lt;/p&gt;

&lt;center&gt;&lt;img src=&quot;/assets/images/post/2018-04-26-apache-lucene-intro-and-index/frame-of-reference.png&quot; width=&quot;500px&quot; /&gt;&lt;/center&gt;

&lt;p&gt;跳跃表加速合并:
因为布尔查询时，and 和or 操作都需要合并倒排表，这时就需要快速定位相同文档号，所以利用跳跃表来进行相同文档号查找&lt;/p&gt;

&lt;center&gt;&lt;img src=&quot;/assets/images/post/2018-04-26-apache-lucene-intro-and-index/skiplist_linklist_complete.png&quot; width=&quot;700px&quot; /&gt;&lt;/center&gt;

&lt;p&gt;&lt;a href=&quot;http://www.cnblogs.com/forfuture1978/archive/2010/04/04/1704258.html&quot;&gt;链表合并&lt;/a&gt;&lt;/p&gt;

&lt;h2 id=&quot;heading-番外篇&quot;&gt;番外篇&lt;/h2&gt;

&lt;h3 id=&quot;heading-fst原理解析&quot;&gt;&lt;a href=&quot;http://blog.jobbole.com/80669/&quot;&gt;FST原理解析&lt;/a&gt;&lt;/h3&gt;

&lt;h3 id=&quot;heading-跳跃表原理解析&quot;&gt;&lt;a href=&quot;https://www.cnblogs.com/George1994/p/7635731.html&quot;&gt;跳跃表原理解析&lt;/a&gt;&lt;/h3&gt;</content><author><name>{&quot;name&quot;=&gt;nil, &quot;job_title&quot;=&gt;nil, &quot;location&quot;=&gt;nil, &quot;email&quot;=&gt;nil, &quot;social_links&quot;=&gt;[{&quot;name&quot;=&gt;&quot;facebook&quot;, &quot;url&quot;=&gt;nil}, {&quot;name&quot;=&gt;&quot;github&quot;, &quot;url&quot;=&gt;&quot;https://github.com/Cuner&quot;}, {&quot;name&quot;=&gt;&quot;instagram&quot;, &quot;url&quot;=&gt;nil}, {&quot;name&quot;=&gt;&quot;linkedin&quot;, &quot;url&quot;=&gt;nil}, {&quot;name&quot;=&gt;&quot;stackoverflow&quot;, &quot;url&quot;=&gt;nil}, {&quot;name&quot;=&gt;&quot;twitter&quot;, &quot;url&quot;=&gt;nil}, {&quot;name&quot;=&gt;&quot;vk&quot;, &quot;url&quot;=&gt;nil}]}</name></author><category term="lucene" /><summary type="html">lucene简介和索引原理</summary></entry><entry><title type="html">HBASE的索引查询</title><link href="http://localhost:4000/blog/2017/12/25/hbase-search-index/" rel="alternate" type="text/html" title="HBASE的索引查询" /><published>2017-12-25T00:00:00+08:00</published><updated>2017-12-25T00:00:00+08:00</updated><id>http://localhost:4000/blog/2017/12/25/hbase-search-index</id><content type="html" xml:base="http://localhost:4000/blog/2017/12/25/hbase-search-index/">&lt;h3 id=&quot;heading-一级索引&quot;&gt;一级索引&lt;/h3&gt;
&lt;p&gt;在逻辑上，HBase的表数据按RowKey进行字典排序， RowKey实际上是数据表的一级索引，由于HBase本身没有二级索引机制，基于索引检索数据只能单纯地依靠RowKey。&lt;/p&gt;

&lt;h3 id=&quot;heading-热点写&quot;&gt;热点写&lt;/h3&gt;
&lt;p&gt;大部分场景下，我们的rowkey总是顺序增大的，存在比较明显的问题就是&lt;strong&gt;热点写&lt;/strong&gt;，我们总是向最大的start key所在的region写数据，其次，由于热点，我们总是往最大的start key的region写记录，之前分裂出来的region不会被写数据，他们都处于半满状态，这样的分布也是不利的。如果在写比较频繁的场景下，数据增长太快，split的次数也会增多，由于split是比较耗费资源的。&lt;/p&gt;

&lt;h3 id=&quot;heading-热点写的解决思路&quot;&gt;热点写的解决思路&lt;/h3&gt;
&lt;ul&gt;
  &lt;li&gt;随机散列(hash):hash就是rowkey前面由一串随机字符串组成，随机字符串生成方式可以由SHA或者MD5方式生成，那么新增的rowkey就不再是按顺序增大的了，就可以解决写热点问题&lt;/li&gt;
  &lt;li&gt;分区式:这种方式类似于mysql中的分表，结合当前的region数目对id取模作为rowkey的前缀。但是一旦region自然分裂，分裂出来的分区号会是一样的，会有部分热点写问题出现，一般通过增多预分区或者加入多级分区来避免这个问题，通过合理设定预分区可解决热点写问题，同时减少split带来的性能消耗。&lt;/li&gt;
&lt;/ul&gt;

&lt;h3 id=&quot;heading-一级索引的局限&quot;&gt;一级索引的局限&lt;/h3&gt;
&lt;p&gt;为了能支持多条件查询，开发者需要将所有可能作为查询条件的字段一一拼接到RowKey中，这是HBase开发中极为常见的做法，但是无论怎样设计，单一RowKey固有的局限性决定了它不可能有效地支持多条件查询。通常来说，RowKey只能针对条件中含有其首字段的查询给予令人满意的性能支持，在查询其他字段时，表现就差强人意了，在极端情况下某些字段的查询性能可能会退化为全表扫描的水平，这是因为字段在RowKey中的地位是不等价的，它们在RowKey中的排位决定了它们被检索时的性能表现，排序越靠前的字段在查询中越具有优势(类似于mysql联合索引的最左原则)，特别是首位字段具有特别的先发优势，如果查询中包含首位字段，检索时就可以通过首位字段的值确定RowKey的前缀部分，从而大幅度地收窄检索区间，如果不包含则只能在全体数据的RowKey上逐一查找，由此可以想见两者在性能上的差距.&lt;/p&gt;

&lt;h3 id=&quot;heading-二级索引的解决方案&quot;&gt;二级索引的解决方案&lt;/h3&gt;
&lt;p&gt;&lt;strong&gt;原理&lt;/strong&gt;：“二级多列索引”是针对目标记录的某个或某些列建立的“键-值”数据，以列的值为键，以记录的RowKey为值，当以这些列为条件进行查询时，引擎可以通过检索相应的“键-值”数据快速找到目标记录。由于HBase本身并没有索引机制，为了确保非侵入性，引擎将索引视为普通数据存放在数据表中，所以，如何解决索引与主数据的划分存储是引擎第一个需要处理的问题，为了能获得最佳的性能表现，我们并没有将主数据和索引分表储存，而是将它们存放在了同一张表里，通过给索引和主数据的RowKey添加特别设计的Hash前缀，实现了在Region切分时，索引能够跟随其主数据划归到同一Region上，即任意Region上的主数据其索引也必定驻留在同一Region上，这样我们就能把从索引抓取目标主数据的性能损失降低到最小。与此同时，特别设计的Hash前缀还在逻辑上把索引与主数据进行了自动的分离，当全体数据按RowKey排序时，排在前面的都是索引，我们称之为索引区，排在后面的均为主数据，我们称之为主数据区。最后，通过给索引和主数据分配不同的Column Family，又在物理存储上把它们隔离了起来。逻辑和物理上的双重隔离避免了将两类数据存放在同一张表里带来的副作用，防止了它们之间的相互干扰，降低了数据维护的复杂性，可以说这是在性能和可维护性上达到的最佳平衡。&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;方案：&lt;/strong&gt;&lt;/p&gt;
&lt;ul&gt;
  &lt;li&gt;将索引视为普通数据存放在数据表中（确保非侵入性）&lt;/li&gt;
  &lt;li&gt;将主数据和索引数据存放在同一张表里(为了能获得最佳的性能表现)
    &lt;ul&gt;
      &lt;li&gt;通过给索引和主数据的RowKey添加特别设计的Hash前缀，对Region完成预切分后(指定region数，禁止引擎自动切分)，索引能够跟随其主数据划归到同一Region上。（从索引抓取目标主数据的性能损失降低到最小）&lt;/li&gt;
      &lt;li&gt;特别设计的Hash前缀还在逻辑上把索引与主数据进行了自动的分离，当全体数据按RowKey排序时，排在前面的都是索引，我们称之为索引区，排在后面的均为主数据，我们称之为主数据区&lt;/li&gt;
      &lt;li&gt;通过给索引和主数据分配不同的Column Family，又在物理存储上把它们隔离了起来&lt;/li&gt;
    &lt;/ul&gt;
  &lt;/li&gt;
&lt;/ul&gt;

&lt;center&gt;&lt;img src=&quot;/assets/images/post/2017-12-25-hbase-search-index/index.png&quot; width=&quot;500&quot; /&gt;&lt;/center&gt;

&lt;ul&gt;
  &lt;li&gt;四位数字构成Hash前缀，范围从0000到9999，规划切分100个Region，则100个Region的RowKey区间分别为[0000,0099]，[0100,0199]，……，[9900,9999]&lt;/li&gt;
  &lt;li&gt;主数据的RowKey，它由四位Hash前缀和原始ID两部分组成，其中Hash前缀是由引擎分配的一个范围在0000到9999之间的随机值，通过这个随机的Hash前缀可以让主数据均匀地散列到所有的Region上&lt;/li&gt;
  &lt;li&gt;索引的RowKey，格式为：RegionStartKey-索引名-索引键-索引值&lt;/li&gt;
  &lt;li&gt;两种索引：a和b，索引a是为字段q1和q2设计的两列联合索引，索引b是为字段q2和q3设计的两列联合索引&lt;/li&gt;
  &lt;li&gt;假定需要查询满足条件q1=01 and q2=02的Sample记录，分析查询字段和索引匹配情况可知应使用索引a，也就是说我们首先确定了索引名，于是在Region 1上进行scan的区间将从主数据全集收窄至[0000-a, 0000-b)，接着拼接查询字段的值，我们得到了索引键：0102，scan区间又进一步收窄为[0000-a-0102, 0000-a-0103)，于是我们可以很快地找到0000-a-0102-0000|63af51b2这条索引，进而得到了索引值，也就是目标数据的RowKey：0000|63af51b2，通过在Region内执行Get操作，最终得到了目标数据&lt;/li&gt;
&lt;/ul&gt;</content><author><name>{&quot;name&quot;=&gt;nil, &quot;job_title&quot;=&gt;nil, &quot;location&quot;=&gt;nil, &quot;email&quot;=&gt;nil, &quot;social_links&quot;=&gt;[{&quot;name&quot;=&gt;&quot;facebook&quot;, &quot;url&quot;=&gt;nil}, {&quot;name&quot;=&gt;&quot;github&quot;, &quot;url&quot;=&gt;&quot;https://github.com/Cuner&quot;}, {&quot;name&quot;=&gt;&quot;instagram&quot;, &quot;url&quot;=&gt;nil}, {&quot;name&quot;=&gt;&quot;linkedin&quot;, &quot;url&quot;=&gt;nil}, {&quot;name&quot;=&gt;&quot;stackoverflow&quot;, &quot;url&quot;=&gt;nil}, {&quot;name&quot;=&gt;&quot;twitter&quot;, &quot;url&quot;=&gt;nil}, {&quot;name&quot;=&gt;&quot;vk&quot;, &quot;url&quot;=&gt;nil}]}</name></author><category term="hbase" /><summary type="html">一级索引 在逻辑上，HBase的表数据按RowKey进行字典排序， RowKey实际上是数据表的一级索引，由于HBase本身没有二级索引机制，基于索引检索数据只能单纯地依靠RowKey。</summary></entry><entry><title type="html">HBASE原理与架构</title><link href="http://localhost:4000/blog/2017/12/20/hbase-construction-theory/" rel="alternate" type="text/html" title="HBASE原理与架构" /><published>2017-12-20T00:00:00+08:00</published><updated>2017-12-20T00:00:00+08:00</updated><id>http://localhost:4000/blog/2017/12/20/hbase-construction-theory</id><content type="html" xml:base="http://localhost:4000/blog/2017/12/20/hbase-construction-theory/">&lt;p&gt;HBASE是一个构建在HDFS上的分布式列存储系统，比较起传统的关系型数据库的优点在于，可以实现高性能的并发读写操作。同时HBase不同于传统关系型数据库的面向行存储，HBase是面向列存储，列可以动态增加，列为空就不存储数据，能更好的节省存储空间。Hbase还会对数据进行透明切分，使得存储本身具有了水平伸缩性&lt;/p&gt;

&lt;h2 id=&quot;heading-hbase特点&quot;&gt;HBASE特点&lt;/h2&gt;
&lt;ul&gt;
  &lt;li&gt;数据量大:一个表可以有数十亿行，上百万列&lt;/li&gt;
  &lt;li&gt;无模式:每行都有一个可排序的主键和任意多的列，列可以根据需要动态的增加，同一张表中不同的行可以有截然不同的列&lt;/li&gt;
  &lt;li&gt;面向列：面向列（族）的存储和权限控制，列（族）独立检索&lt;/li&gt;
  &lt;li&gt;稀疏:空（null）列并不占用存储空间，表可以设计的非常稀疏；&lt;/li&gt;
  &lt;li&gt;数据多版本:每个单元中的数据可以有多个版本，默认情况下版本号自动分配，是单元格插入时的时间戳&lt;/li&gt;
  &lt;li&gt;数据类型单一:Hbase中的数据都是字符串，没有类型。&lt;/li&gt;
&lt;/ul&gt;

&lt;h2 id=&quot;heading-hbase数据模型&quot;&gt;HBASE数据模型&lt;/h2&gt;
&lt;center&gt;&lt;img src=&quot;/assets/images/post/2017-12-20-hbase-construction-theory/hbase-data-model.png&quot; width=&quot;500px&quot; /&gt;&lt;/center&gt;

&lt;ul&gt;
  &lt;li&gt;行健(Rowkey):是Byte array，是表中每条记录的“主键”，方便快速查找，Rowkey的设计非常重要(检索方式)&lt;/li&gt;
  &lt;li&gt;版本(version):每条记录可动态添加Version Number，类型为Long，默认值是系统时间戳，可由用户自定义&lt;/li&gt;
  &lt;li&gt;列族(Column Family):拥有一个名称，包含一个或者多个相关列&lt;/li&gt;
  &lt;li&gt;列(Colume):属于某一个Column Family，格式:familyName:columnName&lt;/li&gt;
  &lt;li&gt;值(value)&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;Table在水平方向有一个或者多个Column Family组成，一个Column Family中可以由任意多个Column组成，即Column Family支持动态扩展，无需预先定义Column的数量以及类型，所有Column均以二进制格式存储，用户需要自行进行类型转换&lt;/p&gt;

&lt;h2 id=&quot;heading-hbase物理模型&quot;&gt;HBASE物理模型&lt;/h2&gt;

&lt;h3 id=&quot;heading-物理存储&quot;&gt;物理存储&lt;/h3&gt;

&lt;ul&gt;
  &lt;li&gt;Table中所有行都按照row key的字典序排列&lt;/li&gt;
  &lt;li&gt;Table在行的方向上分割为多个Region(相当于一个region对应某张表的startRowkey到endRowKey的数据)&lt;/li&gt;
  &lt;li&gt;Region按大小分割的，每个表开始只有一个region，随着数据增多，region不断增大，当增大到一个阀值的时候，region就会等分会两个新的region，之后会有越来越多的region&lt;/li&gt;
  &lt;li&gt;Region是Hbase中分布式存储和负载均衡的最小单元，不同Region分布到不同RegionServer上&lt;/li&gt;
&lt;/ul&gt;

&lt;center&gt;&lt;img src=&quot;/assets/images/post/2017-12-20-hbase-construction-theory/hbase-table-region.png&quot; width=&quot;500px&quot; /&gt;&lt;/center&gt;

&lt;ul&gt;
  &lt;li&gt;Region虽然是分布式存储的最小单元，但并不是存储的最小单元。Region由一个或者多个Store组成，每个store保存一个columns family；每个Strore又由一个memStore和0至多个StoreFile(基于Hfile实现)组成；memStore存储在内存中，StoreFile存储在HDFS上。&lt;/li&gt;
&lt;/ul&gt;

&lt;center&gt;&lt;img src=&quot;/assets/images/post/2017-12-20-hbase-construction-theory/hbase-region-store.png&quot; width=&quot;500px&quot; /&gt;&lt;/center&gt;

&lt;h3 id=&quot;heading-hbase架构以及基本组件&quot;&gt;HBASE架构以及基本组件&lt;/h3&gt;

&lt;center&gt;&lt;img src=&quot;/assets/images/post/2017-12-20-hbase-construction-theory/hbase-construction.jpg&quot; width=&quot;500px&quot; /&gt;&lt;/center&gt;

&lt;ul&gt;
  &lt;li&gt;&lt;strong&gt;Client&lt;/strong&gt;:包含访问HBase的接口，并维护cache来加快对HBase的访问(比如region的位置信息)；使用HBase RPC机制与HMaster和HRegionServer进行通信，Client与HMaster进行通信进行管理类操作，Client与HRegionServer进行数据读写类操作&lt;/li&gt;
  &lt;li&gt;&lt;strong&gt;Master&lt;/strong&gt;
    &lt;ul&gt;
      &lt;li&gt;为Region server分配region&lt;/li&gt;
      &lt;li&gt;负责Region server的负载均衡&lt;/li&gt;
      &lt;li&gt;发现失效的Region server并重新分配其上的region&lt;/li&gt;
      &lt;li&gt;管理用户对table的增删改查操作&lt;/li&gt;
    &lt;/ul&gt;
  &lt;/li&gt;
  &lt;li&gt;&lt;strong&gt;Region Server&lt;/strong&gt;
    &lt;ul&gt;
      &lt;li&gt;Regionserver维护region，处理对这些region的IO请求&lt;/li&gt;
      &lt;li&gt;Regionserver负责切分在运行过程中变得过大的region&lt;/li&gt;
    &lt;/ul&gt;
  &lt;/li&gt;
  &lt;li&gt;&lt;strong&gt;Zookeeper&lt;/strong&gt;
    &lt;ul&gt;
      &lt;li&gt;通过选举，保证任何时候，集群中只有一个master，Master与RegionServers启动时会向ZooKeeper注册（避免master单点问题）&lt;/li&gt;
      &lt;li&gt;存贮所有Region的寻址入口&lt;/li&gt;
      &lt;li&gt;实时监控Region server的上线和下线信息。并实时通知给Master&lt;/li&gt;
      &lt;li&gt;存储HBase的schema和table元数据&lt;/li&gt;
      &lt;li&gt;默认情况下，HBase 管理ZooKeeper 实例，比如， 启动或者停止ZooKeeper&lt;/li&gt;
    &lt;/ul&gt;
  &lt;/li&gt;
&lt;/ul&gt;

&lt;center&gt;&lt;img src=&quot;/assets/images/post/2017-12-20-hbase-construction-theory/hbase-master-regionserver.png&quot; width=&quot;500px&quot; /&gt;&lt;/center&gt;

&lt;h2 id=&quot;heading-hbase写入过程&quot;&gt;HBASE写入过程&lt;/h2&gt;

&lt;p&gt;Client写入 -&amp;gt; 存入MemStore，一直到MemStore满 -&amp;gt; Flush成一个StoreFile，直至增长到一定阈值 -&amp;gt; 触发Compact合并操作 -&amp;gt; 多个StoreFile合并成一个StoreFile，同时进行版本合并和数据删除 -&amp;gt; 当StoreFiles Compact后，逐步形成越来越大的StoreFile -&amp;gt; 单个StoreFile大小超过一定阈值后，触发Split操作，把当前Region Split成2个Region，Region会下线，新Split出的2个孩子Region会被HMaster分配到相应的HRegionServer上，使得原先1个Region的压力得以分流到2个Region上
由此过程可知，HBase只是增加数据，有所得更新和删除操作，都是在Compact阶段做的，所以，用户写操作只需要进入到内存即可立即返回，从而保证I/O高性能&lt;/p&gt;

&lt;h2 id=&quot;heading-hbase容灾日志恢复&quot;&gt;HBASE容灾(日志恢复)&lt;/h2&gt;

&lt;center&gt;&lt;img src=&quot;/assets/images/post/2017-12-20-hbase-construction-theory/hbase-hlog.png&quot; width=&quot;500px&quot; /&gt;&lt;/center&gt;
&lt;p&gt;每次用户执行写入操作，首先是把Log写入到HLog中，HLog是标准的Hadoop Sequence File，由于Log数据量小，而且是顺序写，速度非常快；同时把数据写入到内存MemStore中，成功后返回给Client，所以对Client来说，HBase写的速度非常快，因为数据只要写入到内存中，就算成功了。接着检查MemStore是否已满，如果满了，就把内存中的MemStore Flush到磁盘上，形成一个新的StoreFile。HLog文件定期会滚动出新的，并删除旧的文件（已持久化到StoreFile中的数据）。当HRegionServer意外终止后，HMaster会通过Zookeeper感知到，HMaster首先会处理遗留的 HLog文件，将其中不同Region的Log数据进行拆分，分别放到相应region的目录下，然后再将失效的region重新分配，领取 到这些region的HRegionServer在Load Region的过程中，会发现有历史HLog需要处理，因此会Replay HLog中的数据到MemStore中，然后flush到StoreFiles，完成数据恢复&lt;/p&gt;

&lt;h2 id=&quot;heading-hbase容错性&quot;&gt;HBASE容错性&lt;/h2&gt;

&lt;ul&gt;
  &lt;li&gt;&lt;strong&gt;master容错&lt;/strong&gt;:Zookeeper重新选择一个新的Master
    &lt;ul&gt;
      &lt;li&gt;无Master过程中，数据读取仍照常进行&lt;/li&gt;
      &lt;li&gt;无master过程中，region切分、负载均衡等无法进行&lt;/li&gt;
    &lt;/ul&gt;
  &lt;/li&gt;
  &lt;li&gt;&lt;strong&gt;regionServer容错&lt;/strong&gt;:定时向Zookeeper汇报心跳，如果一旦时间内未出现心跳，Master将该RegionServer上的Region重新分配到其他RegionServer上，失效服务器上“预写”日志由主服务器进行分割并派送给新的RegionServer&lt;/li&gt;
  &lt;li&gt;&lt;strong&gt;zookeeper容错&lt;/strong&gt;:Zookeeper是一个可靠地服务，一般配置3或5个Zookeeper实例&lt;/li&gt;
&lt;/ul&gt;

&lt;h2 id=&quot;heading-hbase检索和扫描如何找到某条记录对应的regionserver&quot;&gt;HBASE检索和扫描：如何找到某条记录对应的regionServer&lt;/h2&gt;

&lt;p&gt;ROOT与META表
Hbase中有两张特殊表，ROOT和META
META：记录了用户表的Region信息，可以有多个region
ROOT：记录了META表的Region信息，ROOT中只有一个region
Zookeeper中记录了ROOT表的location
客户端访问数据的流程： 
Client -&amp;gt; Zookeeper -&amp;gt; -ROOT- -&amp;gt; .META. -&amp;gt; 用户数据表&lt;/p&gt;</content><author><name>{&quot;name&quot;=&gt;nil, &quot;job_title&quot;=&gt;nil, &quot;location&quot;=&gt;nil, &quot;email&quot;=&gt;nil, &quot;social_links&quot;=&gt;[{&quot;name&quot;=&gt;&quot;facebook&quot;, &quot;url&quot;=&gt;nil}, {&quot;name&quot;=&gt;&quot;github&quot;, &quot;url&quot;=&gt;&quot;https://github.com/Cuner&quot;}, {&quot;name&quot;=&gt;&quot;instagram&quot;, &quot;url&quot;=&gt;nil}, {&quot;name&quot;=&gt;&quot;linkedin&quot;, &quot;url&quot;=&gt;nil}, {&quot;name&quot;=&gt;&quot;stackoverflow&quot;, &quot;url&quot;=&gt;nil}, {&quot;name&quot;=&gt;&quot;twitter&quot;, &quot;url&quot;=&gt;nil}, {&quot;name&quot;=&gt;&quot;vk&quot;, &quot;url&quot;=&gt;nil}]}</name></author><category term="hbase" /><summary type="html">HBASE是一个构建在HDFS上的分布式列存储系统，比较起传统的关系型数据库的优点在于，可以实现高性能的并发读写操作。同时HBase不同于传统关系型数据库的面向行存储，HBase是面向列存储，列可以动态增加，列为空就不存储数据，能更好的节省存储空间。Hbase还会对数据进行透明切分，使得存储本身具有了水平伸缩性</summary></entry><entry><title type="html">HDFS分布式文件系统</title><link href="http://localhost:4000/blog/2017/12/05/hdfs-theory/" rel="alternate" type="text/html" title="HDFS分布式文件系统" /><published>2017-12-05T00:00:00+08:00</published><updated>2017-12-05T00:00:00+08:00</updated><id>http://localhost:4000/blog/2017/12/05/hdfs-theory</id><content type="html" xml:base="http://localhost:4000/blog/2017/12/05/hdfs-theory/">&lt;h2 id=&quot;heading-hdfs设计理念&quot;&gt;HDFS设计理念&lt;/h2&gt;

&lt;p&gt;Hadoop分布式文件系统(HDFS)被设计成适合运行在通用硬件上的分布式文件系统，HDFS是一个高度容错性的系统，适合部署在廉价的机器上。HDFS能提供高吞吐量的数据访问，非常适合大规模数据集上的应用。&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;&lt;b&gt;存储超大文件:&lt;/b&gt;运行在HDFS上的应用具有很大的数据集。HDFS上的一个典型文件大小一般都在G字节至T字节。因此，HDFS被调节以支持大文件存储。它能提供整体上高的数据传输带宽，能在一个集群里扩展到数百个节点。一个单一的HDFS实例应该能支撑数以千万计的文件。&lt;/li&gt;
  &lt;li&gt;&lt;b&gt;一次写入、多次读取:&lt;/b&gt;HDFS存储的数据集作为hadoop的分析对象。在数据集生成后，长时间在此数据集上进行各种分析。每次分析都将设计该数据集的大部分数据甚至全部数据，比之数据访问的低延迟问题，更关键的在于数据访问的高吞吐量，因此读取整个数据集的时间延迟比读取第一条记录的时间延迟更重要。&lt;/li&gt;
  &lt;li&gt;&lt;b&gt;运行在普通廉价的服务器上:&lt;/b&gt;HDFS设计理念之一就是让它能运行在普通的硬件之上，即便硬件出现故障，也可以通过容错策略(错误检测和快速、自动的恢复)来保证数据的高可用。&lt;/li&gt;
&lt;/ul&gt;

&lt;h2 id=&quot;heading-hdfs基本概念&quot;&gt;HDFS基本概念&lt;/h2&gt;
&lt;p&gt;HDFS暴露了文件系统的名字空间，用户能够以文件的形式在上面存储数据。从内部看，一个文件其实被分成一个或多个数据块，这些块存储在一组Datanode上。Namenode执行文件系统的名字空间操作，比如打开、关闭、重命名文件或目录。它也负责确定数据块到具体Datanode节点的映射。Datanode负责处理文件系统客户端的读写请求。在Namenode的统一调度下进行数据块的创建、删除和复制&lt;/p&gt;
&lt;ul&gt;
  &lt;li&gt;&lt;b&gt;数据块(block):&lt;/b&gt;大文件会被分割成多个block进行存储，block大小默认为64MB。每一个block会在多个datanode上存储多份副本，默认是3份。&lt;/li&gt;
  &lt;li&gt;&lt;b&gt;namenode:&lt;/b&gt;namenode是一个中心服务器，负责管理文件目录、文件和block的对应关系以及block和datanode的对应关系。&lt;/li&gt;
  &lt;li&gt;&lt;b&gt;datanode:&lt;/b&gt;datanode就负责存储了，当然大部分容错机制都是在datanode上实现的。&lt;/li&gt;
&lt;/ul&gt;

&lt;h2 id=&quot;heading-hdfs基本架构图&quot;&gt;HDFS基本架构图&lt;/h2&gt;
&lt;center&gt;&lt;img src=&quot;/assets/images/post/2017-12-05-hdfs-theory/hdfs-construction.png&quot; width=&quot;500px&quot; /&gt;&lt;/center&gt;
&lt;p&gt;Rack 是指机架的意思，一个block的三个副本通常会保存到两个或者两个以上的机柜中（当然是机柜中的服务器），这样做的目的是做防灾容错。&lt;/p&gt;

&lt;p&gt;每个Datanode节点周期性地向Namenode发送心跳信号。网络割裂可能导致一部分Datanode跟Namenode失去联系。Namenode通过心跳信号的缺失来检测这一情况，并将这些近期不再发送心跳信号Datanode标记为宕机，不会再将新的IO请求发给它们。任何存储在宕机Datanode上的数据将不再有效。Datanode的宕机可能会引起一些数据块的副本系数低于指定值，Namenode不断地检测这些需要复制的数据块，一旦发现就启动复制操作。在下列情况下，可能需要重新复制：某个Datanode节点失效，某个副本遭到损坏，Datanode上的硬盘错误，或者文件的副本系数增大。&lt;/p&gt;

&lt;h2 id=&quot;heading-hdfs写文件流程&quot;&gt;HDFS写文件流程&lt;/h2&gt;
&lt;center&gt;&lt;img src=&quot;/assets/images/post/2017-12-05-hdfs-theory/hdfs-write.png&quot; width=&quot;500px&quot; /&gt;&lt;/center&gt;

&lt;p&gt;当客户端向HDFS文件写入数据的时候，一开始是写到本地临时文件中。假设该文件的副本系数设置为3，当本地临时文件累积到一个数据块的大小时，客户端会从Namenode获取一个Datanode列表用于存放副本。然后客户端开始向第一个Datanode传输数据，第一个Datanode一小部分一小部分(4 KB)地接收数据，将每一部分写入本地仓库，并同时传输该部分到列表中第二个Datanode节点。第二个Datanode也是这样，一小部分一小部分地接收数据，写入本地仓库，并同时传给第三个Datanode。最后，第三个Datanode接收数据并存储在本地。因此，Datanode能流水线式地从前一个节点接收数据，并在同时转发给下一个节点，数据以流水线的方式从前一个Datanode复制到下一个。
【ps】另一种数据写入的方式是采用多路写，也就是同时别写入到三个Datanode里面。管道写需要时间去完成，所以它有很高的延迟，但是它能更好地利用网络带宽；多路写有着比较低的延迟，因为客户端只需要等待最慢的DataNode确认（假设其余都已成功确认）。但是写入需要共享发送服务器的网络带宽，这对于有着很高负载的系统来说是一个瓶颈。&lt;/p&gt;

&lt;h2 id=&quot;heading-hdfs读文件流程&quot;&gt;HDFS读文件流程&lt;/h2&gt;
&lt;center&gt;&lt;img src=&quot;/assets/images/post/2017-12-05-hdfs-theory/hdfs-read.png&quot; width=&quot;500px&quot; /&gt;&lt;/center&gt;</content><author><name>{&quot;name&quot;=&gt;nil, &quot;job_title&quot;=&gt;nil, &quot;location&quot;=&gt;nil, &quot;email&quot;=&gt;nil, &quot;social_links&quot;=&gt;[{&quot;name&quot;=&gt;&quot;facebook&quot;, &quot;url&quot;=&gt;nil}, {&quot;name&quot;=&gt;&quot;github&quot;, &quot;url&quot;=&gt;&quot;https://github.com/Cuner&quot;}, {&quot;name&quot;=&gt;&quot;instagram&quot;, &quot;url&quot;=&gt;nil}, {&quot;name&quot;=&gt;&quot;linkedin&quot;, &quot;url&quot;=&gt;nil}, {&quot;name&quot;=&gt;&quot;stackoverflow&quot;, &quot;url&quot;=&gt;nil}, {&quot;name&quot;=&gt;&quot;twitter&quot;, &quot;url&quot;=&gt;nil}, {&quot;name&quot;=&gt;&quot;vk&quot;, &quot;url&quot;=&gt;nil}]}</name></author><category term="hdfs" /><summary type="html">HDFS设计理念</summary></entry></feed>