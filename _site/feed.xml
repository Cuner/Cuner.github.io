<?xml version="1.0" encoding="utf-8"?><feed xmlns="http://www.w3.org/2005/Atom" xml:lang="en"><generator uri="https://jekyllrb.com/" version="3.5.2">Jekyll</generator><link href="http://localhost:4000/feed.xml" rel="self" type="application/atom+xml" /><link href="http://localhost:4000/" rel="alternate" type="text/html" hreflang="en" /><updated>2018-04-26T16:16:23+08:00</updated><id>http://localhost:4000/</id><title type="html">Cuner</title><subtitle>No zero day.</subtitle><author><name>{&quot;name&quot;=&gt;nil, &quot;job_title&quot;=&gt;nil, &quot;location&quot;=&gt;nil, &quot;email&quot;=&gt;nil, &quot;social_links&quot;=&gt;[{&quot;name&quot;=&gt;&quot;facebook&quot;, &quot;url&quot;=&gt;nil}, {&quot;name&quot;=&gt;&quot;github&quot;, &quot;url&quot;=&gt;&quot;https://github.com/Cuner&quot;}, {&quot;name&quot;=&gt;&quot;instagram&quot;, &quot;url&quot;=&gt;nil}, {&quot;name&quot;=&gt;&quot;linkedin&quot;, &quot;url&quot;=&gt;nil}, {&quot;name&quot;=&gt;&quot;stackoverflow&quot;, &quot;url&quot;=&gt;nil}, {&quot;name&quot;=&gt;&quot;twitter&quot;, &quot;url&quot;=&gt;nil}, {&quot;name&quot;=&gt;&quot;vk&quot;, &quot;url&quot;=&gt;nil}]}</name></author><entry><title type="html">lucene简介和索引原理</title><link href="http://localhost:4000/blog/2018/04/26/apache-lucene-intro-and-index/" rel="alternate" type="text/html" title="lucene简介和索引原理" /><published>2018-04-26T00:00:00+08:00</published><updated>2018-04-26T00:00:00+08:00</updated><id>http://localhost:4000/blog/2018/04/26/apache-lucene-intro-and-index</id><content type="html" xml:base="http://localhost:4000/blog/2018/04/26/apache-lucene-intro-and-index/">&lt;h1 id=&quot;heading-lucene简介和索引原理&quot;&gt;lucene简介和索引原理&lt;/h1&gt;

&lt;h2 id=&quot;heading-lucene简介&quot;&gt;Lucene简介&lt;/h2&gt;
&lt;p&gt;Lucene是一个高效，全Java实现、开源、高性能、功能完整、易拓展，支持分词以及各种查询方式（前缀、模糊、正则等）、打分高亮、列式存储（DocValues）
的全文检索库。仅支持纯文本文件的索引和搜索。&lt;/p&gt;

&lt;center&gt;&lt;img src=&quot;/assets/images/post/2018-04-26-apache-lucene-intro-and-index/lucene-intro.png&quot; width=&quot;500px&quot; /&gt;&lt;/center&gt;

&lt;h2 id=&quot;heading-lucene索引原理&quot;&gt;lucene索引原理&lt;/h2&gt;
&lt;p&gt;每个字符串都指向包含此字符串的文档(Document)链表，此文档链表称为倒排表&lt;/p&gt;

&lt;center&gt;&lt;img src=&quot;/assets/images/post/2018-04-26-apache-lucene-intro-and-index/index-construction.png&quot; width=&quot;500px&quot; /&gt;&lt;/center&gt;

&lt;h3 id=&quot;heading-索引创建过程&quot;&gt;索引创建过程&lt;/h3&gt;

&lt;center&gt;&lt;img src=&quot;/assets/images/post/2018-04-26-apache-lucene-intro-and-index/index-create-step.png&quot; width=&quot;700px&quot; /&gt;&lt;/center&gt;

&lt;p&gt;1.需要被索引的原文档(document)&lt;/p&gt;

&lt;p&gt;2.将原文档传给分词组件(Tokenizer)，分词后得到词元(Token)&lt;/p&gt;

&lt;p&gt;3.将得到的词元(Token)传给语言处理组件(Linguistic Processor)，进行一些语法转化：包括字母转为小写、缩减(复数变单数)、转变(过去时转变为词根)，将词语转化为词根(Term)&lt;/p&gt;

&lt;p&gt;4.将得到的词(Term)传给索引组件(Indexer)，得到词典和倒排链表(反向索引表)&lt;/p&gt;

&lt;p&gt;5.通过索引存储将索引写入硬盘&lt;/p&gt;

&lt;h3 id=&quot;heading-检索过程&quot;&gt;检索过程&lt;/h3&gt;

&lt;center&gt;&lt;img src=&quot;/assets/images/post/2018-04-26-apache-lucene-intro-and-index/index-search-step.png&quot; width=&quot;700px&quot; /&gt;&lt;/center&gt;

&lt;p&gt;1.用户输入查询语句&lt;/p&gt;

&lt;p&gt;2.对查询语句进行词法分析得到单词以及关键字(关键字有AND, NOT)，然后对得到的单词进行语言处理(同索引过程中的语言处理几乎相同)得到查询词根Term&lt;/p&gt;

&lt;p&gt;3.语法分析，根据查询语句的语法规则来形成一棵语法树。&lt;/p&gt;

&lt;p&gt;4.通过索引存储将索引读入到内存。&lt;/p&gt;

&lt;p&gt;5.利用查询树搜索索引，从而得到每个词(Term) 的文档链表，对文档链表进行交，差，并得到结果文档&lt;/p&gt;

&lt;p&gt;6.根据得到的文档和查询语句的相关性，对结果进行排序。(向量空间模型算法:通过各个关键词根在不同文档中的权重来比较文档与查询语句的相关性)&lt;/p&gt;

&lt;h3 id=&quot;heading-lucene索引基本概念&quot;&gt;lucene索引基本概念&lt;/h3&gt;

&lt;ul&gt;
  &lt;li&gt;索引(index)
    &lt;ul&gt;
      &lt;li&gt;在Lucene中一个索引是放在一个文件夹中的&lt;/li&gt;
    &lt;/ul&gt;
  &lt;/li&gt;
  &lt;li&gt;段(segment)
    &lt;ul&gt;
      &lt;li&gt;一个索引可以包含多个段，段与段之间是独立的，添加新文档可以生成新的段，不同的段可以合并&lt;/li&gt;
    &lt;/ul&gt;
  &lt;/li&gt;
  &lt;li&gt;文档(document)
    &lt;ul&gt;
      &lt;li&gt;文档是我们建索引的基本单位，不同的文档是保存在不同的段中的，一个段可以包含多篇文档&lt;/li&gt;
      &lt;li&gt;新添加的文档是单独保存在一个新生成的段中，随着段的合并，不同的文档合并到同一个段中&lt;/li&gt;
    &lt;/ul&gt;
  &lt;/li&gt;
  &lt;li&gt;域(field)
    &lt;ul&gt;
      &lt;li&gt;一篇文档包含不同类型的信息，可以分开索引，比如标题，时间，正文，作者等，都可以保存在不同的域里&lt;/li&gt;
    &lt;/ul&gt;
  &lt;/li&gt;
  &lt;li&gt;词(term)
    &lt;ul&gt;
      &lt;li&gt;词是索引的最小单位，是经过词法分析和语言处理后的字符串&lt;/li&gt;
    &lt;/ul&gt;
  &lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;Lucene的索引结构中，即保存了正向信息，也保存了反向信息&lt;/p&gt;
&lt;ul&gt;
  &lt;li&gt;正向信息：按层次保存了从索引，一直到词的包含关系：索引(Index) –&amp;gt; 段(segment) –&amp;gt; 文档(Document) –&amp;gt; 域(Field) –&amp;gt; 词(Term)，也即此索引包含了那些段，每个段包含了那些文档，每个文档包含了那些域，每个域包含了那些词&lt;/li&gt;
  &lt;li&gt;反向信息：保存了词典到倒排表的映射：词(Term) –&amp;gt; 文档(Document)&lt;/li&gt;
&lt;/ul&gt;

&lt;h3 id=&quot;heading-lucene结构&quot;&gt;lucene结构&lt;/h3&gt;
&lt;p&gt;全文索引绝大多数是通过倒排索引来做，倒排索引由两个部分组成，即词典和倒排表&lt;/p&gt;

&lt;h4 id=&quot;heading-索引结构&quot;&gt;索引结构&lt;/h4&gt;
&lt;p&gt;lucene从4开始大量使用的数据结构是FST（Finite State Transducer）。FST有两个优点：&lt;/p&gt;

&lt;p&gt;1）空间占用小。通过对词典中单词前缀和后缀的重复利用，压缩了存储空间，压缩率一般在3倍~20倍之间；&lt;/p&gt;

&lt;p&gt;2）查询速度快。O(len(str))的查询时间复杂度。&lt;/p&gt;

&lt;p&gt;3) 模糊查询支持比较好&lt;/p&gt;

&lt;p&gt;4）输入要求有序，更新较为困难&lt;/p&gt;

&lt;p&gt;索引文件：
我们往索引库里插入四个单词abd、abe、acf、acg，看看它的索引文件内容&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;tip部分，每列一个FST索引，所以会有多个FST，每个FST存放前缀和后缀块指针，这里前缀就为a、ab、ac&lt;/li&gt;
  &lt;li&gt;tim里面存放后缀块和词的其他信息如倒排表指针、TFDF等&lt;/li&gt;
  &lt;li&gt;doc文件里就为每个单词的倒排表。&lt;/li&gt;
&lt;/ul&gt;

&lt;center&gt;&lt;img src=&quot;/assets/images/post/2018-04-26-apache-lucene-intro-and-index/index-file-construction.png&quot; width=&quot;700px&quot; /&gt;&lt;/center&gt;

&lt;p&gt;所以它的检索过程分为三个步骤：&lt;/p&gt;
&lt;ol&gt;
  &lt;li&gt;内存加载tip文件，通过FST匹配前缀找到后缀词块位置。&lt;/li&gt;
  &lt;li&gt;根据词块位置，读取磁盘中tim文件中后缀块并找到后缀和相应的倒排表位置信息。&lt;/li&gt;
  &lt;li&gt;根据倒排表位置去doc文件中加载倒排表&lt;/li&gt;
&lt;/ol&gt;

&lt;center&gt;&lt;img src=&quot;/assets/images/post/2018-04-26-apache-lucene-intro-and-index/index-create-example.png&quot; width=&quot;700px&quot; /&gt;&lt;/center&gt;

&lt;ul&gt;
  &lt;li&gt;插入abd时，没有输出&lt;/li&gt;
  &lt;li&gt;插入abe时，计算出前缀ab，但此时不知道后续还不会有其他以ab为前缀的词，所以此时无输出。&lt;/li&gt;
  &lt;li&gt;插入acf时，因为是有序的，知道不会再有ab前缀的词了，这时就可以写tip和tim了，tim中写入后缀词块d、e和它们的倒排表位置ip_d,ip_e，tip中写入a，b和以ab为前缀的后缀词块位置&lt;/li&gt;
  &lt;li&gt;插入acg时，计算出和acf共享前缀ac，这时输入已经结束，所有数据写入磁盘。tim中写入后缀词块f、g和相对应的倒排表位置，tip中写入c和以ac为前缀的后缀词块位置&lt;/li&gt;
&lt;/ul&gt;

&lt;h4 id=&quot;heading-倒排表结构&quot;&gt;倒排表结构&lt;/h4&gt;
&lt;p&gt;Lucene现使用的倒排表结构叫&lt;a href=&quot;https://www.elastic.co/blog/frame-of-reference-and-roaring-bitmaps&quot;&gt;Frame of reference&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;数据压缩：
下图：将6个数字从原先的24bytes压缩到7bytes
注：step1到step2的得到的新数组是后尾数减去前位数得到的&lt;/p&gt;

&lt;center&gt;&lt;img src=&quot;/assets/images/post/2018-04-26-apache-lucene-intro-and-index/frame-of-reference.png&quot; width=&quot;500px&quot; /&gt;&lt;/center&gt;

&lt;p&gt;跳跃表加速合并:
因为布尔查询时，and 和or 操作都需要合并倒排表，这时就需要快速定位相同文档号，所以利用跳跃表来进行相同文档号查找&lt;/p&gt;

&lt;center&gt;&lt;img src=&quot;/assets/images/post/2018-04-26-apache-lucene-intro-and-index/skiplist_linklist_complete.png&quot; width=&quot;700px&quot; /&gt;&lt;/center&gt;

&lt;p&gt;&lt;a href=&quot;http://www.cnblogs.com/forfuture1978/archive/2010/04/04/1704258.html&quot;&gt;链表合并&lt;/a&gt;&lt;/p&gt;

&lt;h2 id=&quot;heading-番外篇&quot;&gt;番外篇&lt;/h2&gt;

&lt;h3 id=&quot;heading-fst原理解析&quot;&gt;&lt;a href=&quot;http://blog.jobbole.com/80669/&quot;&gt;FST原理解析&lt;/a&gt;&lt;/h3&gt;

&lt;h3 id=&quot;heading-跳跃表原理解析&quot;&gt;&lt;a href=&quot;https://www.cnblogs.com/George1994/p/7635731.html&quot;&gt;跳跃表原理解析&lt;/a&gt;&lt;/h3&gt;</content><author><name>{&quot;name&quot;=&gt;nil, &quot;job_title&quot;=&gt;nil, &quot;location&quot;=&gt;nil, &quot;email&quot;=&gt;nil, &quot;social_links&quot;=&gt;[{&quot;name&quot;=&gt;&quot;facebook&quot;, &quot;url&quot;=&gt;nil}, {&quot;name&quot;=&gt;&quot;github&quot;, &quot;url&quot;=&gt;&quot;https://github.com/Cuner&quot;}, {&quot;name&quot;=&gt;&quot;instagram&quot;, &quot;url&quot;=&gt;nil}, {&quot;name&quot;=&gt;&quot;linkedin&quot;, &quot;url&quot;=&gt;nil}, {&quot;name&quot;=&gt;&quot;stackoverflow&quot;, &quot;url&quot;=&gt;nil}, {&quot;name&quot;=&gt;&quot;twitter&quot;, &quot;url&quot;=&gt;nil}, {&quot;name&quot;=&gt;&quot;vk&quot;, &quot;url&quot;=&gt;nil}]}</name></author><category term="apache lucene" /><summary type="html">lucene简介和索引原理</summary></entry><entry><title type="html">HBASE的索引查询</title><link href="http://localhost:4000/blog/2017/12/25/hbase-search-index/" rel="alternate" type="text/html" title="HBASE的索引查询" /><published>2017-12-25T00:00:00+08:00</published><updated>2017-12-25T00:00:00+08:00</updated><id>http://localhost:4000/blog/2017/12/25/hbase-search-index</id><content type="html" xml:base="http://localhost:4000/blog/2017/12/25/hbase-search-index/">&lt;h3 id=&quot;heading-一级索引&quot;&gt;一级索引&lt;/h3&gt;
&lt;p&gt;在逻辑上，HBase的表数据按RowKey进行字典排序， RowKey实际上是数据表的一级索引，由于HBase本身没有二级索引机制，基于索引检索数据只能单纯地依靠RowKey。&lt;/p&gt;

&lt;h3 id=&quot;heading-热点写&quot;&gt;热点写&lt;/h3&gt;
&lt;p&gt;大部分场景下，我们的rowkey总是顺序增大的，存在比较明显的问题就是&lt;strong&gt;热点写&lt;/strong&gt;，我们总是向最大的start key所在的region写数据，其次，由于热点，我们总是往最大的start key的region写记录，之前分裂出来的region不会被写数据，他们都处于半满状态，这样的分布也是不利的。如果在写比较频繁的场景下，数据增长太快，split的次数也会增多，由于split是比较耗费资源的。&lt;/p&gt;

&lt;h3 id=&quot;heading-热点写的解决思路&quot;&gt;热点写的解决思路&lt;/h3&gt;
&lt;ul&gt;
  &lt;li&gt;随机散列(hash):hash就是rowkey前面由一串随机字符串组成，随机字符串生成方式可以由SHA或者MD5方式生成，那么新增的rowkey就不再是按顺序增大的了，就可以解决写热点问题&lt;/li&gt;
  &lt;li&gt;分区式:这种方式类似于mysql中的分表，结合当前的region数目对id取模作为rowkey的前缀。但是一旦region自然分裂，分裂出来的分区号会是一样的，会有部分热点写问题出现，一般通过增多预分区或者加入多级分区来避免这个问题，通过合理设定预分区可解决热点写问题，同时减少split带来的性能消耗。&lt;/li&gt;
&lt;/ul&gt;

&lt;h3 id=&quot;heading-一级索引的局限&quot;&gt;一级索引的局限&lt;/h3&gt;
&lt;p&gt;由于HBase本身没有二级索引机制，基于索引检索数据只能单纯地依靠RowKey，为了能支持多条件查询，开发者需要将所有可能作为查询条件的字段一一拼接到RowKey中，这是HBase开发中极为常见的做法，但是无论怎样设计，单一RowKey固有的局限性决定了它不可能有效地支持多条件查询。通常来说，RowKey只能针对条件中含有其首字段的查询给予令人满意的性能支持，在查询其他字段时，表现就差强人意了，因为字段在RowKey中的地位是不等价的，它们在RowKey中的排位决定了它们被检索时的性能表现，排序越靠前的字段在查询中越具有优势(类似于mysql联合索引的最左原则)&lt;/p&gt;

&lt;h3 id=&quot;heading-二级索引的解决方案&quot;&gt;二级索引的解决方案&lt;/h3&gt;
&lt;p&gt;&lt;strong&gt;原理&lt;/strong&gt;：“二级多列索引”是针对目标记录的某个或某些列建立的“键-值”数据，以列的值为键，以记录的RowKey为值，当以这些列为条件进行查询时，引擎可以通过检索相应的“键-值”数据快速找到目标记录。&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;方案：&lt;/strong&gt;&lt;/p&gt;
&lt;ul&gt;
  &lt;li&gt;将索引视为普通数据存放在数据表中（确保非侵入性）&lt;/li&gt;
  &lt;li&gt;将主数据和索引数据存放在同一张表里(为了能获得最佳的性能表现)
    &lt;ul&gt;
      &lt;li&gt;通过给索引和主数据的RowKey添加特别设计的Hash前缀，对Region完成预切分后(指定region数，禁止引擎自动切分)，索引能够跟随其主数据划归到同一Region上。（从索引抓取目标主数据的性能损失降低到最小）&lt;/li&gt;
      &lt;li&gt;特别设计的Hash前缀还在逻辑上把索引与主数据进行了自动的分离，当全体数据按RowKey排序时，排在前面的都是索引，我们称之为索引区，排在后面的均为主数据，我们称之为主数据区&lt;/li&gt;
      &lt;li&gt;通过给索引和主数据分配不同的Column Family，又在物理存储上把它们隔离了起来&lt;/li&gt;
    &lt;/ul&gt;
  &lt;/li&gt;
&lt;/ul&gt;

&lt;center&gt;&lt;img src=&quot;/assets/images/post/2017-12-25-hbase-search-index/index.png&quot; width=&quot;500&quot; /&gt;&lt;/center&gt;

&lt;ul&gt;
  &lt;li&gt;四位数字构成Hash前缀，范围从0000到9999，规划切分100个Region，则100个Region的RowKey区间分别为[0000,0099]，[0100,0199]，……，[9900,9999]&lt;/li&gt;
  &lt;li&gt;主数据的RowKey，它由四位Hash前缀和原始ID两部分组成，其中Hash前缀是由引擎分配的一个范围在0000到9999之间的随机值，通过这个随机的Hash前缀可以让主数据均匀地散列到所有的Region上&lt;/li&gt;
  &lt;li&gt;索引的RowKey，格式为：RegionStartKey-索引名-索引键-索引值&lt;/li&gt;
  &lt;li&gt;两种索引：a和b，索引a是为字段q1和q2设计的两列联合索引，索引b是为字段q2和q3设计的两列联合索引&lt;/li&gt;
  &lt;li&gt;由索引找到对应的rowkey之后，直接在本地的region执行get操作，改操作执行效率是非常高的&lt;/li&gt;
&lt;/ul&gt;</content><author><name>{&quot;name&quot;=&gt;nil, &quot;job_title&quot;=&gt;nil, &quot;location&quot;=&gt;nil, &quot;email&quot;=&gt;nil, &quot;social_links&quot;=&gt;[{&quot;name&quot;=&gt;&quot;facebook&quot;, &quot;url&quot;=&gt;nil}, {&quot;name&quot;=&gt;&quot;github&quot;, &quot;url&quot;=&gt;&quot;https://github.com/Cuner&quot;}, {&quot;name&quot;=&gt;&quot;instagram&quot;, &quot;url&quot;=&gt;nil}, {&quot;name&quot;=&gt;&quot;linkedin&quot;, &quot;url&quot;=&gt;nil}, {&quot;name&quot;=&gt;&quot;stackoverflow&quot;, &quot;url&quot;=&gt;nil}, {&quot;name&quot;=&gt;&quot;twitter&quot;, &quot;url&quot;=&gt;nil}, {&quot;name&quot;=&gt;&quot;vk&quot;, &quot;url&quot;=&gt;nil}]}</name></author><category term="hbase" /><summary type="html">一级索引 在逻辑上，HBase的表数据按RowKey进行字典排序， RowKey实际上是数据表的一级索引，由于HBase本身没有二级索引机制，基于索引检索数据只能单纯地依靠RowKey。</summary></entry><entry><title type="html">HBASE原理与架构</title><link href="http://localhost:4000/blog/2017/12/20/hbase-construction-theory/" rel="alternate" type="text/html" title="HBASE原理与架构" /><published>2017-12-20T00:00:00+08:00</published><updated>2017-12-20T00:00:00+08:00</updated><id>http://localhost:4000/blog/2017/12/20/hbase-construction-theory</id><content type="html" xml:base="http://localhost:4000/blog/2017/12/20/hbase-construction-theory/">&lt;p&gt;HBASE是一个构建在HDFS上的分布式列存储系统，比较起传统的关系型数据库的优点在于，可以实现高性能的并发读写操作。同时HBase不同于传统关系型数据库的面向行存储，HBase是面向列存储，列可以动态增加，列为空就不存储数据，能更好的节省存储空间。Hbase还会对数据进行透明切分，使得存储本身具有了水平伸缩性&lt;/p&gt;

&lt;h2 id=&quot;heading-hbase特点&quot;&gt;HBASE特点&lt;/h2&gt;
&lt;ul&gt;
  &lt;li&gt;数据量大:一个表可以有数十亿行，上百万列&lt;/li&gt;
  &lt;li&gt;无模式:每行都有一个可排序的主键和任意多的列，列可以根据需要动态的增加，同一张表中不同的行可以有截然不同的列&lt;/li&gt;
  &lt;li&gt;面向列：面向列（族）的存储和权限控制，列（族）独立检索&lt;/li&gt;
  &lt;li&gt;稀疏:空（null）列并不占用存储空间，表可以设计的非常稀疏；&lt;/li&gt;
  &lt;li&gt;数据多版本:每个单元中的数据可以有多个版本，默认情况下版本号自动分配，是单元格插入时的时间戳&lt;/li&gt;
  &lt;li&gt;数据类型单一:Hbase中的数据都是字符串，没有类型。&lt;/li&gt;
&lt;/ul&gt;

&lt;h2 id=&quot;heading-hbase数据模型&quot;&gt;HBASE数据模型&lt;/h2&gt;
&lt;center&gt;&lt;img src=&quot;/assets/images/post/2017-12-20-hbase-construction-theory/hbase-data-model.png&quot; width=&quot;500px&quot; /&gt;&lt;/center&gt;

&lt;ul&gt;
  &lt;li&gt;行健(Rowkey):是Byte array，是表中每条记录的“主键”，方便快速查找，Rowkey的设计非常重要(检索方式)&lt;/li&gt;
  &lt;li&gt;版本(version):每条记录可动态添加Version Number，类型为Long，默认值是系统时间戳，可由用户自定义&lt;/li&gt;
  &lt;li&gt;列族(Column Family):拥有一个名称，包含一个或者多个相关列&lt;/li&gt;
  &lt;li&gt;列(Colume):属于某一个Column Family，格式:familyName:columnName&lt;/li&gt;
  &lt;li&gt;值(value)&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;Table在水平方向有一个或者多个Column Family组成，一个Column Family中可以由任意多个Column组成，即Column Family支持动态扩展，无需预先定义Column的数量以及类型，所有Column均以二进制格式存储，用户需要自行进行类型转换&lt;/p&gt;

&lt;h2 id=&quot;heading-hbase物理模型&quot;&gt;HBASE物理模型&lt;/h2&gt;

&lt;h3 id=&quot;heading-物理存储&quot;&gt;物理存储&lt;/h3&gt;

&lt;ul&gt;
  &lt;li&gt;Table中所有行都按照row key的字典序排列&lt;/li&gt;
  &lt;li&gt;Table在行的方向上分割为多个Region(相当于一个region对应某张表的startRowkey到endRowKey的数据)&lt;/li&gt;
  &lt;li&gt;Region按大小分割的，每个表开始只有一个region，随着数据增多，region不断增大，当增大到一个阀值的时候，region就会等分会两个新的region，之后会有越来越多的region&lt;/li&gt;
  &lt;li&gt;Region是Hbase中分布式存储和负载均衡的最小单元，不同Region分布到不同RegionServer上&lt;/li&gt;
&lt;/ul&gt;

&lt;center&gt;&lt;img src=&quot;/assets/images/post/2017-12-20-hbase-construction-theory/hbase-table-region.png&quot; width=&quot;500px&quot; /&gt;&lt;/center&gt;

&lt;ul&gt;
  &lt;li&gt;Region虽然是分布式存储的最小单元，但并不是存储的最小单元。Region由一个或者多个Store组成，每个store保存一个columns family；每个Strore又由一个memStore和0至多个StoreFile(基于Hfile实现)组成；memStore存储在内存中，StoreFile存储在HDFS上。&lt;/li&gt;
&lt;/ul&gt;

&lt;center&gt;&lt;img src=&quot;/assets/images/post/2017-12-20-hbase-construction-theory/hbase-region-store.png&quot; width=&quot;500px&quot; /&gt;&lt;/center&gt;

&lt;h3 id=&quot;heading-hbase架构以及基本组件&quot;&gt;HBASE架构以及基本组件&lt;/h3&gt;

&lt;center&gt;&lt;img src=&quot;/assets/images/post/2017-12-20-hbase-construction-theory/hbase-construction.jpg&quot; width=&quot;500px&quot; /&gt;&lt;/center&gt;

&lt;ul&gt;
  &lt;li&gt;&lt;strong&gt;Client&lt;/strong&gt;:包含访问HBase的接口，并维护cache来加快对HBase的访问(比如region的位置信息)；使用HBase RPC机制与HMaster和HRegionServer进行通信，Client与HMaster进行通信进行管理类操作，Client与HRegionServer进行数据读写类操作&lt;/li&gt;
  &lt;li&gt;&lt;strong&gt;Master&lt;/strong&gt;
    &lt;ul&gt;
      &lt;li&gt;为Region server分配region&lt;/li&gt;
      &lt;li&gt;负责Region server的负载均衡&lt;/li&gt;
      &lt;li&gt;发现失效的Region server并重新分配其上的region&lt;/li&gt;
      &lt;li&gt;管理用户对table的增删改查操作&lt;/li&gt;
    &lt;/ul&gt;
  &lt;/li&gt;
  &lt;li&gt;&lt;strong&gt;Region Server&lt;/strong&gt;
    &lt;ul&gt;
      &lt;li&gt;Regionserver维护region，处理对这些region的IO请求&lt;/li&gt;
      &lt;li&gt;Regionserver负责切分在运行过程中变得过大的region&lt;/li&gt;
    &lt;/ul&gt;
  &lt;/li&gt;
  &lt;li&gt;&lt;strong&gt;Zookeeper&lt;/strong&gt;
    &lt;ul&gt;
      &lt;li&gt;通过选举，保证任何时候，集群中只有一个master，Master与RegionServers启动时会向ZooKeeper注册（避免master单点问题）&lt;/li&gt;
      &lt;li&gt;存贮所有Region的寻址入口&lt;/li&gt;
      &lt;li&gt;实时监控Region server的上线和下线信息。并实时通知给Master&lt;/li&gt;
      &lt;li&gt;存储HBase的schema和table元数据&lt;/li&gt;
      &lt;li&gt;默认情况下，HBase 管理ZooKeeper 实例，比如， 启动或者停止ZooKeeper&lt;/li&gt;
    &lt;/ul&gt;
  &lt;/li&gt;
&lt;/ul&gt;

&lt;center&gt;&lt;img src=&quot;/assets/images/post/2017-12-20-hbase-construction-theory/hbase-master-regionserver.png&quot; width=&quot;500px&quot; /&gt;&lt;/center&gt;

&lt;h2 id=&quot;heading-hbase写入过程&quot;&gt;HBASE写入过程&lt;/h2&gt;

&lt;p&gt;Client写入 -&amp;gt; 存入MemStore，一直到MemStore满 -&amp;gt; Flush成一个StoreFile，直至增长到一定阈值 -&amp;gt; 触发Compact合并操作 -&amp;gt; 多个StoreFile合并成一个StoreFile，同时进行版本合并和数据删除 -&amp;gt; 当StoreFiles Compact后，逐步形成越来越大的StoreFile -&amp;gt; 单个StoreFile大小超过一定阈值后，触发Split操作，把当前Region Split成2个Region，Region会下线，新Split出的2个孩子Region会被HMaster分配到相应的HRegionServer上，使得原先1个Region的压力得以分流到2个Region上
由此过程可知，HBase只是增加数据，有所得更新和删除操作，都是在Compact阶段做的，所以，用户写操作只需要进入到内存即可立即返回，从而保证I/O高性能&lt;/p&gt;

&lt;h2 id=&quot;heading-hbase容灾日志恢复&quot;&gt;HBASE容灾(日志恢复)&lt;/h2&gt;

&lt;center&gt;&lt;img src=&quot;/assets/images/post/2017-12-20-hbase-construction-theory/hbase-hlog.png&quot; width=&quot;500px&quot; /&gt;&lt;/center&gt;
&lt;p&gt;每次用户执行写入操作，首先是把Log写入到HLog中，HLog是标准的Hadoop Sequence File，由于Log数据量小，而且是顺序写，速度非常快；同时把数据写入到内存MemStore中，成功后返回给Client，所以对Client来说，HBase写的速度非常快，因为数据只要写入到内存中，就算成功了。接着检查MemStore是否已满，如果满了，就把内存中的MemStore Flush到磁盘上，形成一个新的StoreFile。HLog文件定期会滚动出新的，并删除旧的文件（已持久化到StoreFile中的数据）。当HRegionServer意外终止后，HMaster会通过Zookeeper感知到，HMaster首先会处理遗留的 HLog文件，将其中不同Region的Log数据进行拆分，分别放到相应region的目录下，然后再将失效的region重新分配，领取 到这些region的HRegionServer在Load Region的过程中，会发现有历史HLog需要处理，因此会Replay HLog中的数据到MemStore中，然后flush到StoreFiles，完成数据恢复&lt;/p&gt;

&lt;h2 id=&quot;heading-hbase容错性&quot;&gt;HBASE容错性&lt;/h2&gt;

&lt;ul&gt;
  &lt;li&gt;&lt;strong&gt;master容错&lt;/strong&gt;:Zookeeper重新选择一个新的Master
    &lt;ul&gt;
      &lt;li&gt;无Master过程中，数据读取仍照常进行&lt;/li&gt;
      &lt;li&gt;无master过程中，region切分、负载均衡等无法进行&lt;/li&gt;
    &lt;/ul&gt;
  &lt;/li&gt;
  &lt;li&gt;&lt;strong&gt;regionServer容错&lt;/strong&gt;:定时向Zookeeper汇报心跳，如果一旦时间内未出现心跳，Master将该RegionServer上的Region重新分配到其他RegionServer上，失效服务器上“预写”日志由主服务器进行分割并派送给新的RegionServer&lt;/li&gt;
  &lt;li&gt;&lt;strong&gt;zookeeper容错&lt;/strong&gt;:Zookeeper是一个可靠地服务，一般配置3或5个Zookeeper实例&lt;/li&gt;
&lt;/ul&gt;

&lt;h2 id=&quot;heading-hbase检索和扫描如何找到某条记录对应的regionserver&quot;&gt;HBASE检索和扫描：如何找到某条记录对应的regionServer&lt;/h2&gt;

&lt;p&gt;ROOT与META表
Hbase中有两张特殊表，ROOT和META
META：记录了用户表的Region信息，可以有多个region
ROOT：记录了META表的Region信息，ROOT中只有一个region
Zookeeper中记录了ROOT表的location
客户端访问数据的流程： 
Client -&amp;gt; Zookeeper -&amp;gt; -ROOT- -&amp;gt; .META. -&amp;gt; 用户数据表&lt;/p&gt;</content><author><name>{&quot;name&quot;=&gt;nil, &quot;job_title&quot;=&gt;nil, &quot;location&quot;=&gt;nil, &quot;email&quot;=&gt;nil, &quot;social_links&quot;=&gt;[{&quot;name&quot;=&gt;&quot;facebook&quot;, &quot;url&quot;=&gt;nil}, {&quot;name&quot;=&gt;&quot;github&quot;, &quot;url&quot;=&gt;&quot;https://github.com/Cuner&quot;}, {&quot;name&quot;=&gt;&quot;instagram&quot;, &quot;url&quot;=&gt;nil}, {&quot;name&quot;=&gt;&quot;linkedin&quot;, &quot;url&quot;=&gt;nil}, {&quot;name&quot;=&gt;&quot;stackoverflow&quot;, &quot;url&quot;=&gt;nil}, {&quot;name&quot;=&gt;&quot;twitter&quot;, &quot;url&quot;=&gt;nil}, {&quot;name&quot;=&gt;&quot;vk&quot;, &quot;url&quot;=&gt;nil}]}</name></author><category term="hbase" /><summary type="html">HBASE是一个构建在HDFS上的分布式列存储系统，比较起传统的关系型数据库的优点在于，可以实现高性能的并发读写操作。同时HBase不同于传统关系型数据库的面向行存储，HBase是面向列存储，列可以动态增加，列为空就不存储数据，能更好的节省存储空间。Hbase还会对数据进行透明切分，使得存储本身具有了水平伸缩性</summary></entry><entry><title type="html">HDFS分布式文件系统</title><link href="http://localhost:4000/blog/2017/12/05/hdfs-theory/" rel="alternate" type="text/html" title="HDFS分布式文件系统" /><published>2017-12-05T00:00:00+08:00</published><updated>2017-12-05T00:00:00+08:00</updated><id>http://localhost:4000/blog/2017/12/05/hdfs-theory</id><content type="html" xml:base="http://localhost:4000/blog/2017/12/05/hdfs-theory/">&lt;h2 id=&quot;heading-hdfs设计理念&quot;&gt;HDFS设计理念&lt;/h2&gt;

&lt;p&gt;Hadoop分布式文件系统(HDFS)被设计成适合运行在通用硬件上的分布式文件系统，HDFS是一个高度容错性的系统，适合部署在廉价的机器上。HDFS能提供高吞吐量的数据访问，非常适合大规模数据集上的应用。&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;&lt;b&gt;存储超大文件:&lt;/b&gt;运行在HDFS上的应用具有很大的数据集。HDFS上的一个典型文件大小一般都在G字节至T字节。因此，HDFS被调节以支持大文件存储。它能提供整体上高的数据传输带宽，能在一个集群里扩展到数百个节点。一个单一的HDFS实例应该能支撑数以千万计的文件。&lt;/li&gt;
  &lt;li&gt;&lt;b&gt;一次写入、多次读取:&lt;/b&gt;HDFS存储的数据集作为hadoop的分析对象。在数据集生成后，长时间在此数据集上进行各种分析。每次分析都将设计该数据集的大部分数据甚至全部数据，比之数据访问的低延迟问题，更关键的在于数据访问的高吞吐量，因此读取整个数据集的时间延迟比读取第一条记录的时间延迟更重要。&lt;/li&gt;
  &lt;li&gt;&lt;b&gt;运行在普通廉价的服务器上:&lt;/b&gt;HDFS设计理念之一就是让它能运行在普通的硬件之上，即便硬件出现故障，也可以通过容错策略(错误检测和快速、自动的恢复)来保证数据的高可用。&lt;/li&gt;
&lt;/ul&gt;

&lt;h2 id=&quot;heading-hdfs基本概念&quot;&gt;HDFS基本概念&lt;/h2&gt;
&lt;p&gt;HDFS暴露了文件系统的名字空间，用户能够以文件的形式在上面存储数据。从内部看，一个文件其实被分成一个或多个数据块，这些块存储在一组Datanode上。Namenode执行文件系统的名字空间操作，比如打开、关闭、重命名文件或目录。它也负责确定数据块到具体Datanode节点的映射。Datanode负责处理文件系统客户端的读写请求。在Namenode的统一调度下进行数据块的创建、删除和复制&lt;/p&gt;
&lt;ul&gt;
  &lt;li&gt;&lt;b&gt;数据块(block):&lt;/b&gt;大文件会被分割成多个block进行存储，block大小默认为64MB。每一个block会在多个datanode上存储多份副本，默认是3份。&lt;/li&gt;
  &lt;li&gt;&lt;b&gt;namenode:&lt;/b&gt;namenode是一个中心服务器，负责管理文件目录、文件和block的对应关系以及block和datanode的对应关系。&lt;/li&gt;
  &lt;li&gt;&lt;b&gt;datanode:&lt;/b&gt;datanode就负责存储了，当然大部分容错机制都是在datanode上实现的。&lt;/li&gt;
&lt;/ul&gt;

&lt;h2 id=&quot;heading-hdfs基本架构图&quot;&gt;HDFS基本架构图&lt;/h2&gt;
&lt;center&gt;&lt;img src=&quot;/assets/images/post/2017-12-05-hdfs-theory/hdfs-construction.png&quot; width=&quot;500px&quot; /&gt;&lt;/center&gt;
&lt;p&gt;Rack 是指机架的意思，一个block的三个副本通常会保存到两个或者两个以上的机柜中（当然是机柜中的服务器），这样做的目的是做防灾容错。&lt;/p&gt;

&lt;p&gt;每个Datanode节点周期性地向Namenode发送心跳信号。网络割裂可能导致一部分Datanode跟Namenode失去联系。Namenode通过心跳信号的缺失来检测这一情况，并将这些近期不再发送心跳信号Datanode标记为宕机，不会再将新的IO请求发给它们。任何存储在宕机Datanode上的数据将不再有效。Datanode的宕机可能会引起一些数据块的副本系数低于指定值，Namenode不断地检测这些需要复制的数据块，一旦发现就启动复制操作。在下列情况下，可能需要重新复制：某个Datanode节点失效，某个副本遭到损坏，Datanode上的硬盘错误，或者文件的副本系数增大。&lt;/p&gt;

&lt;h2 id=&quot;heading-hdfs写文件流程&quot;&gt;HDFS写文件流程&lt;/h2&gt;
&lt;center&gt;&lt;img src=&quot;/assets/images/post/2017-12-05-hdfs-theory/hdfs-write.png&quot; width=&quot;500px&quot; /&gt;&lt;/center&gt;

&lt;p&gt;当客户端向HDFS文件写入数据的时候，一开始是写到本地临时文件中。假设该文件的副本系数设置为3，当本地临时文件累积到一个数据块的大小时，客户端会从Namenode获取一个Datanode列表用于存放副本。然后客户端开始向第一个Datanode传输数据，第一个Datanode一小部分一小部分(4 KB)地接收数据，将每一部分写入本地仓库，并同时传输该部分到列表中第二个Datanode节点。第二个Datanode也是这样，一小部分一小部分地接收数据，写入本地仓库，并同时传给第三个Datanode。最后，第三个Datanode接收数据并存储在本地。因此，Datanode能流水线式地从前一个节点接收数据，并在同时转发给下一个节点，数据以流水线的方式从前一个Datanode复制到下一个。
【ps】另一种数据写入的方式是采用多路写，也就是同时别写入到三个Datanode里面。管道写需要时间去完成，所以它有很高的延迟，但是它能更好地利用网络带宽；多路写有着比较低的延迟，因为客户端只需要等待最慢的DataNode确认（假设其余都已成功确认）。但是写入需要共享发送服务器的网络带宽，这对于有着很高负载的系统来说是一个瓶颈。&lt;/p&gt;

&lt;h2 id=&quot;heading-hdfs读文件流程&quot;&gt;HDFS读文件流程&lt;/h2&gt;
&lt;center&gt;&lt;img src=&quot;/assets/images/post/2017-12-05-hdfs-theory/hdfs-read.png&quot; width=&quot;500px&quot; /&gt;&lt;/center&gt;</content><author><name>{&quot;name&quot;=&gt;nil, &quot;job_title&quot;=&gt;nil, &quot;location&quot;=&gt;nil, &quot;email&quot;=&gt;nil, &quot;social_links&quot;=&gt;[{&quot;name&quot;=&gt;&quot;facebook&quot;, &quot;url&quot;=&gt;nil}, {&quot;name&quot;=&gt;&quot;github&quot;, &quot;url&quot;=&gt;&quot;https://github.com/Cuner&quot;}, {&quot;name&quot;=&gt;&quot;instagram&quot;, &quot;url&quot;=&gt;nil}, {&quot;name&quot;=&gt;&quot;linkedin&quot;, &quot;url&quot;=&gt;nil}, {&quot;name&quot;=&gt;&quot;stackoverflow&quot;, &quot;url&quot;=&gt;nil}, {&quot;name&quot;=&gt;&quot;twitter&quot;, &quot;url&quot;=&gt;nil}, {&quot;name&quot;=&gt;&quot;vk&quot;, &quot;url&quot;=&gt;nil}]}</name></author><category term="hdfs" /><summary type="html">HDFS设计理念</summary></entry><entry><title type="html">Spring AOP代理</title><link href="http://localhost:4000/blog/2017/06/29/spring-aop-proxy/" rel="alternate" type="text/html" title="Spring AOP代理" /><published>2017-06-29T00:00:00+08:00</published><updated>2017-06-29T00:00:00+08:00</updated><id>http://localhost:4000/blog/2017/06/29/spring-aop-proxy</id><content type="html" xml:base="http://localhost:4000/blog/2017/06/29/spring-aop-proxy/">&lt;h2 id=&quot;heading-一spring-aop代理的相关属性&quot;&gt;一、Spring AOP代理的相关属性&lt;/h2&gt;

&lt;ul&gt;
  &lt;li&gt;开启AOP自动代理&lt;/li&gt;
&lt;/ul&gt;

&lt;div class=&quot;highlighter-rouge&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;&amp;lt;aop:aspect-autoproxy /&amp;gt;
&lt;/code&gt;&lt;/pre&gt;
&lt;/div&gt;

&lt;ul&gt;
  &lt;li&gt;proxy-target-class:强调spring应该使用那种代理方式：JDK动态代理和CGLIB
    &lt;ul&gt;
      &lt;li&gt;JDK动态代理：代理对象必须为某个接口的实现，它是通过在运行期间创建一个接口的实现类来完成对目标对象的代理【默认属性值为false，即使用的是JDK动态代理】&lt;/li&gt;
      &lt;li&gt;CGLIB代理：原理类似于JDK代理，不同之处在于运行期间生成的代理对象是针对目标类扩展的子类，CGLIB是高效代码生成包，底层是依靠ASM（字节码编辑类库）操作字节码实现的，性能比JDK强。&lt;/li&gt;
      &lt;li&gt;使用CGLIB代理会出现的问题:无法通知Final方法，因为他们不允许被覆盖；还需要将CGLIB二进制包放入classpath下面；强制使用CGLIB代理需要将proxy-target-class设置为true&lt;/li&gt;
    &lt;/ul&gt;
  &lt;/li&gt;
  &lt;li&gt;expose-proxy:目标对象内部的自我调用将无法实施切面中的增强&lt;/li&gt;
&lt;/ul&gt;

&lt;h2 id=&quot;heading-二aop代理无法切入同类调用方法的问题&quot;&gt;二、AOP代理无法切入同类调用方法的问题&lt;/h2&gt;

&lt;div class=&quot;highlighter-rouge&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;@Service
public class Service {  
  
    //这个方法调用被切的方法,在外部被调用 
    public void callMethodA() {  
        ......  
        callMethodB();  
        ......  
    }  
      
    //Aop切入的方法 
    public void callMethodB() {  
        ......  
    }  
} 

@Aspect
@Service
public class Aspect {
    @After(&quot;execution(* Service.callMethodB(..))&quot;)  
    public void after() {  
        Logger.info(&quot;after call and do something.&quot;);
    }  
}  

//调用方式
service.callMethodA();

//spring配置
&amp;lt;aop:aspect-autoproxy proxy-target-class=&quot;true&quot;/&amp;gt;
&lt;/code&gt;&lt;/pre&gt;
&lt;/div&gt;

&lt;p&gt;上述的调用方式是根本无法进去切面的，在callMethodA()方法中调用callMethodB()相当于调用this.callMethodB()，此处的this指向目标对象，并不是调用代理对象的callMethodB()方法，解决方式如下两点&lt;/p&gt;
&lt;ul&gt;
  &lt;li&gt;强制使用AOP代理&lt;/li&gt;
&lt;/ul&gt;

&lt;div class=&quot;highlighter-rouge&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;//spring配置
&amp;lt;aop:aspectj-autoproxy proxy-target-class=&quot;true&quot; expose-proxy=&quot;true&quot; /&amp;gt;

//调用callMethodB()
((Service)AopContext.currentProxy()).callMethodB();
&lt;/code&gt;&lt;/pre&gt;
&lt;/div&gt;

&lt;ul&gt;
  &lt;li&gt;通过spring上下文获取代理类&lt;/li&gt;
&lt;/ul&gt;

&lt;div class=&quot;highlighter-rouge&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;//spring配置
&amp;lt;aop:aspectj-autoproxy proxy-target-class=&quot;true&quot;/&amp;gt;

//调用callMethodB()
applicationContext.getBean(&quot;service&quot;).callMethodB();
&lt;/code&gt;&lt;/pre&gt;
&lt;/div&gt;

&lt;p&gt;PS:使用第一种方式的时候要注意获取代理对象时的强制转换:使用默认的JDK动态代理的方式需要转换为接口，使用CGLIB代理的方式可以直接使用实现类的类型；同时代理对象使用的方法需要是public修饰的方法；spring自带的@transactional注解在使用中也有上述问题，该注解默认使用CGLIB代理。&lt;/p&gt;</content><author><name>{&quot;name&quot;=&gt;nil, &quot;job_title&quot;=&gt;nil, &quot;location&quot;=&gt;nil, &quot;email&quot;=&gt;nil, &quot;social_links&quot;=&gt;[{&quot;name&quot;=&gt;&quot;facebook&quot;, &quot;url&quot;=&gt;nil}, {&quot;name&quot;=&gt;&quot;github&quot;, &quot;url&quot;=&gt;&quot;https://github.com/Cuner&quot;}, {&quot;name&quot;=&gt;&quot;instagram&quot;, &quot;url&quot;=&gt;nil}, {&quot;name&quot;=&gt;&quot;linkedin&quot;, &quot;url&quot;=&gt;nil}, {&quot;name&quot;=&gt;&quot;stackoverflow&quot;, &quot;url&quot;=&gt;nil}, {&quot;name&quot;=&gt;&quot;twitter&quot;, &quot;url&quot;=&gt;nil}, {&quot;name&quot;=&gt;&quot;vk&quot;, &quot;url&quot;=&gt;nil}]}</name></author><category term="aop" /><summary type="html">一、Spring AOP代理的相关属性</summary></entry><entry><title type="html">java网络编程</title><link href="http://localhost:4000/blog/2017/06/29/java-io-model/" rel="alternate" type="text/html" title="java网络编程" /><published>2017-06-29T00:00:00+08:00</published><updated>2017-06-29T00:00:00+08:00</updated><id>http://localhost:4000/blog/2017/06/29/java-io-model</id><content type="html" xml:base="http://localhost:4000/blog/2017/06/29/java-io-model/">&lt;h2 id=&quot;heading-一nio&quot;&gt;一、NIO&lt;/h2&gt;

&lt;ul&gt;
  &lt;li&gt;通道和缓冲区(Channels and Buffer):标准的IO基于字节流和字符流进行操作的，而NIO是基于通道（Channel）和缓冲区（Buffer）进行操作，数据总是从通道读取到缓冲区中，或者从缓冲区写入到通道中。&lt;/li&gt;
&lt;/ul&gt;

&lt;center&gt;&lt;img src=&quot;/assets/images/post/2017-06-29-java-io-model/nio-channel-buffer.jpg&quot; width=&quot;500&quot; /&gt;&lt;/center&gt;

&lt;ul&gt;
  &lt;li&gt;选择器(Seletor):Java NIO的选择器允许一个单独的线程来监视多个输入通道，你可以使用一个选择器注册多个通道，并设置感兴趣的通道事件，然后使用一个单独的线程来“选择”已准备好的通道：这些通道里已经有可以处理的输入，或备写入的通道。这种选择机制，使得一个单独的线程很容易来管理多个通道。&lt;/li&gt;
&lt;/ul&gt;

&lt;center&gt;&lt;img src=&quot;/assets/images/post/2017-06-29-java-io-model/nio-selector.jpg&quot; width=&quot;500&quot; /&gt;&lt;/center&gt;

&lt;ul&gt;
  &lt;li&gt;非阻塞模式:Java IO的各种流是阻塞的。这意味着，当一个线程调用read() 或 write()时，该线程被阻塞，直到有一些数据被读取，或数据完全写入。该线程在此期间不能再干任何事情了。 Java NIO的非阻塞模式，使一个线程从某通道发送请求读取数据，但是它仅能得到目前可用的数据，如果目前没有数据可用时，就什么都不会获取。而不是保持线程阻塞，所以直至数据变的可以读取之前，该线程可以继续做其他的事情。 非阻塞写也是如此。一个线程请求写入一些数据到某通道，但不需要等待它完全写入，这个线程同时可以去做别的事情。 线程通常将非阻塞IO的空闲时间用于在其它通道上执行IO操作，所以一个单独的线程现在可以管理多个输入和输出通道（channel）。 Java NIO可以让你异步的使用IO，例如：当线程从通道读取数据到缓冲区时，线程还是可以进行其他事情。当数据被写入到缓冲区时，线程可以继续处理它。从缓冲区写入通道也类似。&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;PS:NIO解析数据可能比从一个阻塞流中读取数据更复杂。&lt;/p&gt;

&lt;center&gt;&lt;img src=&quot;/assets/images/post/2017-06-29-java-io-model/nio-data-read.jpg&quot; width=&quot;500&quot; /&gt;&lt;/center&gt;

&lt;h2 id=&quot;heading-二网络编程三类模型&quot;&gt;二、网络编程三类模型&lt;/h2&gt;

&lt;ul&gt;
  &lt;li&gt;BIO(blocking IO):&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;传统的BIO网络编程是同步阻塞型的， 传统的同步阻塞模型开发中，ServerSocket负责绑定IP地址，启动监听端口；等待Socket发起连接操作。通常使用一个独立的线程来负责监听客户端的连接，当连接成功后，服务端需要创建一个新的线程负责双方的通信，双方通过输入和输出流进行同步阻塞式通信，即一连接一线程模型。这类网络模型在高并发的场景下，会实例出大量的线程，导致系统资源的耗费。你有少量的连接使用非常高的带宽，一次发送大量的数据，也许典型的IO服务器实现可能非常契合。&lt;/p&gt;

&lt;center&gt;&lt;img src=&quot;/assets/images/post/2017-06-29-java-io-model/bio-connection-thread.jpg&quot; width=&quot;500&quot; /&gt;&lt;/center&gt;

&lt;ul&gt;
  &lt;li&gt;NIO(NO Blocking IO):&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;NIO网络编程是同步非阻塞型的，等同于多路复用的IO模型。如果需要管理同时打开的成千上万个连接，这些连接每次只是发送少量的数据，例如聊天服务器，实现NIO的服务器可能是一个优势。同样，如果你需要维持许多打开的连接到其他计算机上，如P2P网络中，使用一个单独的线程来管理你所有出站连接，可能是一个优势。仅用单个线程来处理多个Channels的好处是，只需要更少的线程来处理通道。事实上，可以只用一个线程处理所有的通道。对于操作系统来说，线程之间上下文切换的开销很大，而且每个线程都要占用系统的一些资源（如内存）。因此，使用的线程越少越好。 但是，需要记住，现代的操作系统和CPU在多任务方面表现的越来越好，所以多线程的开销随着时间的推移，变得越来越小了。实际上，如果一个CPU有多个内核，不使用多任务可能是在浪费CPU能力。&lt;/p&gt;

&lt;center&gt;&lt;img src=&quot;/assets/images/post/2017-06-29-java-io-model/nio-connection-thread.jpg&quot; width=&quot;500&quot; /&gt;&lt;/center&gt;

&lt;ul&gt;
  &lt;li&gt;AIO(Asynchronous IO)&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;AIO网络编程是异步非阻塞型的。以读操作为例，当发起一个读请求后，请求线程并不用关心通道中的数据何时准备就绪，也不用亲自对准备就绪后的数据进行处理，在发起读请求后请求线程可以接着做任何其他事情。此后内核将自动等待数据的到来，当通道中的数据准备就绪后，系统将自动调用事先指定好的处理器对数据进行处理。请求线程只需要调用相应的read/write方法，并且传入CompletionHandler(动作完成的处理器)就已经完成任务，后续的操作都会异步的自动完成。&lt;/p&gt;

&lt;p&gt;相比NIO，AIO更加适合连接数较大且IO操作较重(单次IO传输的数据较大)的场景，例如相册服务器。&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;三者之间的比较
    &lt;ul&gt;
      &lt;li&gt;BIO，同步阻塞式IO，简单理解：一个连接一个线程&lt;/li&gt;
      &lt;li&gt;NIO，同步非阻塞IO，简单理解：一个线程&lt;/li&gt;
      &lt;li&gt;AIO，异步非阻塞IO，简单理解：一个有效请求一个线程&lt;/li&gt;
    &lt;/ul&gt;
  &lt;/li&gt;
&lt;/ul&gt;

&lt;h2 id=&quot;heading-三举例&quot;&gt;三、举例&lt;/h2&gt;

&lt;p&gt;1.上班期间，公司内部1500余人口打开聊天工具进行工作交流，假设1s内一共进行50次通信，我们来看看这三种IO模型的资源消耗：【NIO最为适合】&lt;/p&gt;
&lt;ul&gt;
  &lt;li&gt;BIO:服务器根据1500个连接需要分配1500个线程(考虑到BIO读写相互阻塞，这里应该是1500*2个线程)，这些线程各自独立完成读写操作&lt;/li&gt;
  &lt;li&gt;NIO:服务器根据连接创建通道，并且通过selector来管理这1500个通道，同时使用一个线程来监听来自这1500个通道的读写操作，这一个线程要保证在1s内完成50次读写操作（可以增加线程来管理这些通道，避免读写操作耗时较长影响到下一次对通道的监听）&lt;/li&gt;
  &lt;li&gt;AIO:不需要建立连接，1s内需要分配50个线程来完成有效的读写请求，线程之间相互独立&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;2.换一个场景，将TT聊天改成向相册服务器上传下载图片，这种场景AIO更为适合：如果使用NIO，需要使用有限的线程来处理这种数据量大(50张图片)的读写操作会相当耗时，严重地延后距离下一次监听读写操作的时间，而AIO使用50个有效的线程避免了这一问题&lt;/p&gt;</content><author><name>{&quot;name&quot;=&gt;nil, &quot;job_title&quot;=&gt;nil, &quot;location&quot;=&gt;nil, &quot;email&quot;=&gt;nil, &quot;social_links&quot;=&gt;[{&quot;name&quot;=&gt;&quot;facebook&quot;, &quot;url&quot;=&gt;nil}, {&quot;name&quot;=&gt;&quot;github&quot;, &quot;url&quot;=&gt;&quot;https://github.com/Cuner&quot;}, {&quot;name&quot;=&gt;&quot;instagram&quot;, &quot;url&quot;=&gt;nil}, {&quot;name&quot;=&gt;&quot;linkedin&quot;, &quot;url&quot;=&gt;nil}, {&quot;name&quot;=&gt;&quot;stackoverflow&quot;, &quot;url&quot;=&gt;nil}, {&quot;name&quot;=&gt;&quot;twitter&quot;, &quot;url&quot;=&gt;nil}, {&quot;name&quot;=&gt;&quot;vk&quot;, &quot;url&quot;=&gt;nil}]}</name></author><category term="网络IO" /><summary type="html">一、NIO</summary></entry><entry><title type="html">网络IO模型</title><link href="http://localhost:4000/blog/2017/06/22/IO-model/" rel="alternate" type="text/html" title="网络IO模型" /><published>2017-06-22T00:00:00+08:00</published><updated>2017-06-22T00:00:00+08:00</updated><id>http://localhost:4000/blog/2017/06/22/IO-model</id><content type="html" xml:base="http://localhost:4000/blog/2017/06/22/IO-model/">&lt;p&gt;IO发生时涉及的对象和步骤：对于一个network IO (这里我们以read举例)，它会涉及到两个系统对象，一个是调用这个IO的process (or thread)，另一个就是系统内核(kernel)。当一个read操作发生时，它会经历两个阶段：&lt;/p&gt;
&lt;ol&gt;
  &lt;li&gt;等待数据准备到内核中&lt;/li&gt;
  &lt;li&gt;将数据从内核拷贝到进程中&lt;/li&gt;
&lt;/ol&gt;

&lt;h2 id=&quot;heading-同步阻塞io模型&quot;&gt;同步阻塞I/O模型：&lt;/h2&gt;

&lt;ul&gt;
  &lt;li&gt;
    &lt;p&gt;在进程空间中调用recvfrom，kernel(内核)就开始了IO的第一个阶段：准备数据，对于network io来说，很多时候数据在一开始还没有到达（比如，还没有收到一个完整的UDP包），这个时候内核就要等待足够的数据到来。而在用户进程这边，整个进程会被阻塞。当kernel一直等到数据准备好了，它就会将数据从kernel中拷贝到用户内存，然后kernel返回结果，用户进程才解除block的状态，重新运行起来。其系统调用直到数据包到达且被复制到应用进程的缓冲区中或者发生错误再返回，在此期间一直会等待，进程从调用recvfrom开始到它返回的整段时间内都是阻塞的。所以阻塞IO的特点是在IO执行的两个阶段(等待数据和拷贝数据的两个阶段)都被阻塞了。&lt;/p&gt;
  &lt;/li&gt;
  &lt;li&gt;
    &lt;p&gt;在阻塞期间，线程是无法执行任何运算或者响应任何的网络请求，采用此类IO模型的系统为保持多个连接，通常会使用多线程技术，但是一旦需要同时响应大量的连接请求，多线程会严重占用系统资源，降低系统对外界的响应效率。再次基础上，也可以使用线程池技术，其维持一定合理数量的线程，并让空闲的线程重新承担新的执行任务，用以减少线程频繁创建以及销毁带来的开销，但是线程池也只是在一定程度上缓解了大量IO操作带来的资源占用问题。&lt;/p&gt;
  &lt;/li&gt;
&lt;/ul&gt;

&lt;center&gt;&lt;img src=&quot;/assets/images/post/2017-06-22-IO-model/同步阻塞.jpg&quot; width=&quot;500&quot; /&gt;&lt;/center&gt;

&lt;h2 id=&quot;heading-同步非阻塞io模型&quot;&gt;同步非阻塞I/O模型：&lt;/h2&gt;

&lt;ul&gt;
  &lt;li&gt;
    &lt;p&gt;当用户进程发出read操作时，如果kernel中的数据还没有准备好，那么它并不会block用户进程，就直接返回错误，从用户进程角度讲 ，它发起一个read操作后，并不需要等待，而是马上就得到了一个结果。用户进程判断结果是一个error时，它就知道数据还没有准备好，于是它可以再次发送read操作。一旦kernel中的数据准备好了，并且又再次收到了用户进程的system call，那么它马上就将数据拷贝到了用户内存，然后返回。&lt;/p&gt;
  &lt;/li&gt;
  &lt;li&gt;
    &lt;p&gt;一般对于非阻塞I/O模型进行轮训检查这个状态，查看内核是不是有数据到来。所以，在非阻塞式IO中，用户进程其实是需要不断的主动询问kernel数据准备好了没有。&lt;/p&gt;
  &lt;/li&gt;
  &lt;li&gt;
    &lt;p&gt;使用此类iO模型的服务器可以通过循环调用recv()接口，可以在单个线程内实现对所有连接的数据接收工作。但是上述模型绝不被推荐。因为，循环调用recv()将大幅度推高CPU 占用率；此外，在这个方案中recv()更多的是起到检测到某一个连接中“操作是否完成”的作用，实际操作系统提供了更为高效的检测“操作是否完成“作用的接口，例如select()多路复用模式，可以一次检测多个连接是否活跃。&lt;/p&gt;
  &lt;/li&gt;
&lt;/ul&gt;

&lt;center&gt;&lt;img src=&quot;/assets/images/post/2017-06-22-IO-model/同步非阻塞.jpg&quot; width=&quot;500&quot; /&gt;&lt;/center&gt;

&lt;h3 id=&quot;heading-io复用模型&quot;&gt;I/O复用模型：&lt;/h3&gt;

&lt;ul&gt;
  &lt;li&gt;
    &lt;p&gt;Linux提供select/poll，在读取文件过程中，进程通过将一个或多个fd(文件描述符)传递给select/poll系统调用，阻塞的select操作上，这样select/poll可以帮我们检测多个fd是否处于就绪状态。select/poll是顺序扫描fd是否准备就绪，而且支持的fd有限。Linux还而外提供了epoll系统调用，epoll使用基于事件驱动方式代替顺序扫描，当有fd准备就绪时，立即回调函数rollback&lt;/p&gt;
  &lt;/li&gt;
  &lt;li&gt;
    &lt;p&gt;当用户进程调用了select，那么整个进程会被block，而同时，kernel会“监视”所有select负责的socket，当任何一个socket中的数据准备好了，select就会返回。这个时候用户进程再调用read操作，将数据从kernel拷贝到用户进程。&lt;/p&gt;
  &lt;/li&gt;
  &lt;li&gt;
    &lt;p&gt;这个图和blocking IO的图其实并没有太大的不同，事实上还更差一些。因为这里需要使用两个系统调用(select和recvfrom)，而blocking IO只调用了一个系统调用(recvfrom)。但是，用select的优势在于它可以同时处理多个connection。（如果处理的连接数不是很高的话，使用select/epoll的web server不一定比使用multi-threading + blocking IO的web server性能更好，可能延迟还更大。select/epoll的优势并不是对于单个连接能处理得更快，而是在于能处理更多的连接。）&lt;/p&gt;
  &lt;/li&gt;
  &lt;li&gt;
    &lt;p&gt;优点：相比其他IO模型，该模型只用单线程执行，占用CPU资源少，同时能够为多个客户端提供服务。&lt;/p&gt;
  &lt;/li&gt;
  &lt;li&gt;
    &lt;p&gt;缺点：1.当需要探测的句柄值较大时，select事件探测操作会花费大量的时间去顺序轮训句柄【linux提供epoll来替代轮训，通过事件驱动来告知进程数据准备就绪】；2.IO多路复用模型在每一个执行周期都会探测一组事件，一个特定的事件会触发某个特定的响应，一旦数据报过大，或者接受数据包并处理的过程很长，导致事件响应的执行体庞大，会验证影响到下一次执行select的实时性&lt;/p&gt;
  &lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;PS：I/O复用模型一般也被划分为同步非阻塞IO模型，虽然整个用户进程在执行select时会被阻塞，但是在整个过程中，数据从内核准备就绪的IO过程并未阻塞住：当某个连接的数据未准备至内核中时，IO并未阻塞住而是将空闲时间用于在其它连接上执行IO操作【多个连接之间的IO操作互相不阻塞】&lt;/p&gt;

&lt;center&gt;&lt;img src=&quot;/assets/images/post/2017-06-22-IO-model/IO多路复用.jpg&quot; width=&quot;500&quot; /&gt;&lt;/center&gt;

&lt;h2 id=&quot;heading-信号驱动io模型&quot;&gt;信号驱动I/O模型：&lt;/h2&gt;

&lt;ul&gt;
  &lt;li&gt;通过系统调用sigaction执行一个信号处理函数(此系统调用立即返回，进程继续工作，它是非阻塞的)。当数据准备就绪时，就为该进程生成一个SIGIO信号，通过信号回调通知应用程序调用recvfrom来读取数据&lt;/li&gt;
&lt;/ul&gt;

&lt;center&gt;&lt;img src=&quot;/assets/images/post/2017-06-22-IO-model/信号驱动.jpg&quot; width=&quot;500&quot; /&gt;&lt;/center&gt;

&lt;h2 id=&quot;heading-异步io模型&quot;&gt;异步I/O模型：&lt;/h2&gt;

&lt;ul&gt;
  &lt;li&gt;用户进程发起read操作之后，立刻就可以开始去做其它的事。而另一方面，从kernel的角度，当它受到一个asynchronous read之后，首先它会立刻返回，所以不会对用户进程产生任何block。然后，kernel会等待数据准备完成，然后将数据拷贝到用户内存，当这一切都完成之后，kernel会给用户进程发送一个signal，告诉它read操作完成了。这种模型与信号驱动模型的主要区别是：信号驱动I/O由内核通知我们合适可以开始一个I/O操作；而异步I/O模型由内核通知我们I/O操作何时完成。&lt;/li&gt;
&lt;/ul&gt;

&lt;center&gt;&lt;img src=&quot;/assets/images/post/2017-06-22-IO-model/异步.jpg&quot; width=&quot;500&quot; /&gt;&lt;/center&gt;

&lt;h2 id=&quot;heading-阻塞与非阻塞&quot;&gt;阻塞与非阻塞&lt;/h2&gt;

&lt;ul&gt;
  &lt;li&gt;
    &lt;p&gt;阻塞与非阻塞关注的是程序在等待调用结果时的状态：阻塞调用是指调用结果返回之前，当前线程会被挂起，调用线程只有在拿到结果之后才返回；非阻塞调用指在不能立刻获得结果之前，该调用不会阻塞当前线程。&lt;/p&gt;
  &lt;/li&gt;
  &lt;li&gt;
    &lt;p&gt;调用blocking IO会一直block住对应的进程直到操作完成，而non-blocking IO在kernel还在准备数据的情况下会立刻返回。&lt;/p&gt;
  &lt;/li&gt;
&lt;/ul&gt;

&lt;center&gt;&lt;img src=&quot;/assets/images/post/2017-06-22-IO-model/阻塞与非阻塞.jpg&quot; width=&quot;500&quot; /&gt;&lt;/center&gt;

&lt;h2 id=&quot;heading-同步与异步&quot;&gt;同步与异步&lt;/h2&gt;

&lt;ul&gt;
  &lt;li&gt;
    &lt;p&gt;同步和异步关注的是消息通信机制。所谓同步，就是在发出一个调用时，在没有得到结果之前，该调用就不返回，但是一旦调用返回了，就得到返回值了。换句话说，就是调用者在主动等待这个调用的结果。而异步则相反，调用在发出之后，这个调用就直接返回了，此时没有返回结果。换句话说，当一个异步过程调用发出之后，调用者不会立刻得到结果，而是在调用发出之后，【被调用者通过状态、通知来通知调用者，或通过回调函数处理这个调用】。&lt;/p&gt;
  &lt;/li&gt;
  &lt;li&gt;
    &lt;p&gt;图中的IO操作其实是指真实的IO操作，是指当kernel中数据准备好的时候，recvfrom会将数据从kernel拷贝到用户内存中这个过程。异步的不同之处在于当进程发起IO操作之后，就直接返回再也不理睬了，直到kernel发送一个信号，告诉进程说IO完成。在这整个过程中，进程完全没有被block。&lt;/p&gt;
  &lt;/li&gt;
&lt;/ul&gt;

&lt;center&gt;&lt;img src=&quot;/assets/images/post/2017-06-22-IO-model/同步与异步.jpg&quot; width=&quot;500&quot; /&gt;&lt;/center&gt;

&lt;h2 id=&quot;heading-总结&quot;&gt;总结&lt;/h2&gt;

&lt;ul&gt;
  &lt;li&gt;
    &lt;p&gt;总的来说，IO模型有5种之多：阻塞IO，非阻塞IO，IO复用，信号驱动IO，异步IO。前四种都属于同步IO。阻塞IO不必说了。非阻塞IO ，IO请求后立刻返回，IO没有就绪会返回错误，需要请求进程主动轮询不断发IO请求直到返回正确。IO复用同非阻塞IO本质一样，不过利用了新的select系统调用，由内核来负责本来是请求进程该做的轮询操作。看似比非阻塞IO还多了一个系统调用开销，不过因为可以支持多路IO，才算提高了效率。信号驱动IO，调用sigaltion系统调用，当内核中IO数据就绪时以SIGIO信号通知请求进程，请求进程再把数据从内核读入到用户空间，这一步是阻塞的。&lt;/p&gt;
  &lt;/li&gt;
  &lt;li&gt;
    &lt;p&gt;异步IO，如定义所说，不会因为IO操作阻塞，IO操作全部完成才通知请求进程。&lt;/p&gt;
  &lt;/li&gt;
  &lt;li&gt;
    &lt;p&gt;经过上面的介绍，会发现non-blocking IO和asynchronous IO的区别还是很明显的。在non-blocking IO中，虽然进程大部分时间都不会被block，但是它仍然要求进程去主动的check，并且当数据准备完成以后，也需要进程主动的再次调用recvfrom来将数据拷贝到用户内存。而asynchronous IO则完全不同。它就像是用户进程将整个IO操作交给了他人（kernel）完成，然后他人做完后发信号通知。在此期间，用户进程不需要去检查IO操作的状态，也不需要主动的去拷贝数据。&lt;/p&gt;
  &lt;/li&gt;
&lt;/ul&gt;</content><author><name>{&quot;name&quot;=&gt;nil, &quot;job_title&quot;=&gt;nil, &quot;location&quot;=&gt;nil, &quot;email&quot;=&gt;nil, &quot;social_links&quot;=&gt;[{&quot;name&quot;=&gt;&quot;facebook&quot;, &quot;url&quot;=&gt;nil}, {&quot;name&quot;=&gt;&quot;github&quot;, &quot;url&quot;=&gt;&quot;https://github.com/Cuner&quot;}, {&quot;name&quot;=&gt;&quot;instagram&quot;, &quot;url&quot;=&gt;nil}, {&quot;name&quot;=&gt;&quot;linkedin&quot;, &quot;url&quot;=&gt;nil}, {&quot;name&quot;=&gt;&quot;stackoverflow&quot;, &quot;url&quot;=&gt;nil}, {&quot;name&quot;=&gt;&quot;twitter&quot;, &quot;url&quot;=&gt;nil}, {&quot;name&quot;=&gt;&quot;vk&quot;, &quot;url&quot;=&gt;nil}]}</name></author><category term="网络IO" /><summary type="html">IO发生时涉及的对象和步骤：对于一个network IO (这里我们以read举例)，它会涉及到两个系统对象，一个是调用这个IO的process (or thread)，另一个就是系统内核(kernel)。当一个read操作发生时，它会经历两个阶段： 等待数据准备到内核中 将数据从内核拷贝到进程中</summary></entry><entry><title type="html">数据库主从复制</title><link href="http://localhost:4000/blog/2017/05/15/database-master-slave-syn/" rel="alternate" type="text/html" title="数据库主从复制" /><published>2017-05-15T00:00:00+08:00</published><updated>2017-05-15T00:00:00+08:00</updated><id>http://localhost:4000/blog/2017/05/15/database-master-slave-syn</id><content type="html" xml:base="http://localhost:4000/blog/2017/05/15/database-master-slave-syn/">&lt;p&gt;复制过程中一个服务器充当主服务器，而一个或多个其它服务器充当从服务器。&lt;/p&gt;

&lt;h2 id=&quot;heading-一异步复制&quot;&gt;一、异步复制&lt;/h2&gt;
&lt;ul&gt;
  &lt;li&gt;MySQL的异步复制是MySQL自带的数据同步功能，在公司里面也是也就最为常见的。&lt;/li&gt;
  &lt;li&gt;Master服务器中需要开启二进制日志 binlog ，从服务器需要开启中继日志 relay-log 。&lt;/li&gt;
  &lt;li&gt;二进制日志binlog的主要功能是：记录数据库的变更内容；二进制日志在备份还原的时候至关重要。&lt;/li&gt;
  &lt;li&gt;中继日志relay-log则是从服务器中开启，作用是从主服务器的二进制日志中复制，并在在从服务器本地执行一次，达到与主服务器内容一致的效果。&lt;/li&gt;
  &lt;li&gt;一般MySQL复制是放在内网中进行的，因为MySQL的同步并没有进行加密。而且相比较于在公网传输，在内网中丢包的概率较低，带宽也高。&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;&lt;strong&gt;复制过程：&lt;/strong&gt;&lt;/p&gt;
&lt;ol&gt;
  &lt;li&gt;该过程的第一部分就是master记录二进制日志。在每个事务更新数据完成之前，master在二进制日志中记录这些改变。MySQL将事务串行的写入二进制日志，即使事务中的语句都是交叉执行的。在事件写入二进制日志完成后，master通知存储引擎提交事务。&lt;/li&gt;
  &lt;li&gt;下一步就是slave将master的binary log拷贝到它自己的中继日志。首先，slave开始一个工作线程——I/O线程。I/O线程在master上打开一个普通的连接，然后开始binlog dump process（根据从服务器在日志中读取的最后一次成功更新的位置）。Binlog dump process从master的二进制日志中读取事件，如果已经跟上master，它会睡眠并等待master产生新的事件。I/O线程将这些事件写入中继日志。&lt;/li&gt;
  &lt;li&gt;SQL slave thread（SQL从线程）处理该过程的最后一步。SQL线程从中继日志读取事件，并重放其中的事件而更新slave的数据，使其与master中的数据一致。只要该线程与I/O线程保持一致，中继日志通常会位于OS的缓存中，所以中继日志的开销很小。&lt;/li&gt;
&lt;/ol&gt;

&lt;p&gt;此外，在master中也有一个工作线程（I/O线程）：和其它MySQL的连接一样，slave在master中打开一个连接也会使得master开始一个线程。复制过程有一个很重要的限制——复制在slave上是串行化的，也就是说master上的并行更新操作不能在slave上并行操作。&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;/assets/images/post/2017-05-15-database-master-slave-sync/master-slave-sync.png&quot; alt=&quot;master-slave-sync.png&quot; /&gt;&lt;/p&gt;

&lt;h2 id=&quot;heading-二半同步复制&quot;&gt;二、半同步复制&lt;/h2&gt;
&lt;ul&gt;
  &lt;li&gt;与传统的异步复制相比，半同步复制在多个Slave节点中会选取一个节点进行半同步复制。也就是说，当Master提交一个事务的时候，在这个半同步复制的Slave端返回一个同步完成的Ack包之后，服务器才会向用户返回事务提交成功，而其他的节点则是采用传统的异步复制方式进行同步。&lt;/li&gt;
  &lt;li&gt;半同步是复制是基于异步复制之上进行的，也就是说配置半同步复制之前需要先配置到异步复制。&lt;/li&gt;
  &lt;li&gt;半同步复制可以保证在主节点发生故障的时候，总有一个节点的数据与主节点一样。这样在进行切换的时候，可以更加快速地把这个Slave节点设置成主节点来使用。&lt;/li&gt;
&lt;/ul&gt;

&lt;h2 id=&quot;heading-三binlog-格式&quot;&gt;三、binlog 格式&lt;/h2&gt;

&lt;h3 id=&quot;heading-statement每一条会修改数据的sql都会记录在binlog中&quot;&gt;statement:每一条会修改数据的sql都会记录在binlog中&lt;/h3&gt;

&lt;ul&gt;
  &lt;li&gt;
    &lt;p&gt;优点：不需要记录每一行的变化，减少了binlog日志量，节约了IO，提高性能。(相比row能节约多少性能与日志量，这个取决于应用的SQL情况，正常同一条记录修改或者插入row格式所产生的日志量还小于Statement产生的日志量，但是考虑到如果带条件的update操作，以及整表删除，alter表等操作，ROW格式会产生大量日志，因此在考虑是否使用ROW格式日志时应该跟据应用的实际情况，其所产生的日志量会增加多少，以及带来的IO性能问题。)&lt;/p&gt;
  &lt;/li&gt;
  &lt;li&gt;
    &lt;p&gt;缺点：由于记录的只是执行语句，为了这些语句能在slave上正确运行，因此还必须记录每条语句在执行的时候的一些相关信息(时间等)，以保证所有语句能在slave得到和在master端执行时候相同的结果。&lt;/p&gt;
  &lt;/li&gt;
&lt;/ul&gt;

&lt;h3 id=&quot;heading-row不记录sql语句上下文相关信息仅保存哪条记录被修改&quot;&gt;Row:不记录sql语句上下文相关信息，仅保存哪条记录被修改&lt;/h3&gt;

&lt;ul&gt;
  &lt;li&gt;
    &lt;p&gt;优点：binlog中可以不记录执行的sql语句的上下文相关的信息，仅需要记录那一条记录被修改成什么了。所以rowlevel的日志内容会非常清楚的记录下每一行数据修改的细节。而且不会出现某些特定情况下的存储过程，或function，以及trigger的调用和触发无法被正确复制的问题&lt;/p&gt;
  &lt;/li&gt;
  &lt;li&gt;
    &lt;p&gt;缺点：所有的执行的语句当记录到日志中的时候，都将以每行记录的修改来记录，这样可能会产生大量的日志内容,比如一条update语句，修改多条记录，则binlog中每一条修改都会有记录，这样造成binlog日志量会很大，特别是当执行alter table之类的语句的时候，由于表结构修改，每条记录都发生改变，那么该表每一条记录都会记录到日志中。&lt;/p&gt;
  &lt;/li&gt;
&lt;/ul&gt;

&lt;h3 id=&quot;heading-mixedlevel-是以上两种level的混合使用&quot;&gt;Mixedlevel: 是以上两种level的混合使用。&lt;/h3&gt;

&lt;ul&gt;
  &lt;li&gt;一般的语句修改使用statment格式保存binlog，如一些函数，statement无法完成主从复制的操作，则采用row格式保存binlog,MySQL会根据执行的每一条具体的sql语句来区分对待记录的日志形式，也就是在Statement和Row之间选择一种.新版本的MySQL中队row level模式也被做了优化，并不是所有的修改都会以row level来记录，像遇到表结构变更的时候就会以statement模式来记录。至于update或者delete等修改数据的语句，还是会记录所有行的变更。&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;注：所以当数据库在采取异步复制的同步策略时，如果当binlog的格式是Row的情况下存在【在主库更新十条记录之后，从库只更新了5条】的情况&lt;/p&gt;</content><author><name>{&quot;name&quot;=&gt;nil, &quot;job_title&quot;=&gt;nil, &quot;location&quot;=&gt;nil, &quot;email&quot;=&gt;nil, &quot;social_links&quot;=&gt;[{&quot;name&quot;=&gt;&quot;facebook&quot;, &quot;url&quot;=&gt;nil}, {&quot;name&quot;=&gt;&quot;github&quot;, &quot;url&quot;=&gt;&quot;https://github.com/Cuner&quot;}, {&quot;name&quot;=&gt;&quot;instagram&quot;, &quot;url&quot;=&gt;nil}, {&quot;name&quot;=&gt;&quot;linkedin&quot;, &quot;url&quot;=&gt;nil}, {&quot;name&quot;=&gt;&quot;stackoverflow&quot;, &quot;url&quot;=&gt;nil}, {&quot;name&quot;=&gt;&quot;twitter&quot;, &quot;url&quot;=&gt;nil}, {&quot;name&quot;=&gt;&quot;vk&quot;, &quot;url&quot;=&gt;nil}]}</name></author><category term="mysql" /><summary type="html">复制过程中一个服务器充当主服务器，而一个或多个其它服务器充当从服务器。</summary></entry><entry><title type="html">数据库锁机制</title><link href="http://localhost:4000/blog/2017/03/29/database-lock-mechanism/" rel="alternate" type="text/html" title="数据库锁机制" /><published>2017-03-29T00:00:00+08:00</published><updated>2017-03-29T00:00:00+08:00</updated><id>http://localhost:4000/blog/2017/03/29/database-lock-mechanism</id><content type="html" xml:base="http://localhost:4000/blog/2017/03/29/database-lock-mechanism/">&lt;h1 id=&quot;heading-数据库锁机制&quot;&gt;数据库锁机制&lt;/h1&gt;

&lt;h2 id=&quot;heading-为什么需要锁&quot;&gt;为什么需要锁&lt;/h2&gt;

&lt;ul&gt;
  &lt;li&gt;死锁问题&lt;/li&gt;
  &lt;li&gt;并发问题导致的不正确数据的读取和存储，破坏数据一致性
    &lt;ol&gt;
      &lt;li&gt;丢失更新：当两个或多个事务选择同一行，然后基于最初选定的值更新该行时，由于每个事务都不知道其他事务的存在，就会发生丢失更新问题－－最后的更新覆盖了由其他事务所做的更新。例如，两个编辑人员制作了同一文档的电子副本。每个编辑人员独立地更改其副本，然后保存更改后的副本，这样就覆盖了原始文档。最后保存其更改副本的编辑人员覆盖另一个编辑人员所做的更改。如果在一个编辑人员完成并提交事务之前，另一个编辑人员不能访问同一文件，则可避免此问题&lt;/li&gt;
      &lt;li&gt;脏读：一个事务正在对一条记录做修改，在这个事务完成并提交前，这条记录的数据就处于不一致状态；这时，另一个事务也来读取同一条记录，如果不加控制，第二个事务读取了这些“脏”数据，并据此做进一步的处理，就会产生未提交的数据依赖关系。这种现象被形象地叫做&quot;脏读&quot;。&lt;/li&gt;
      &lt;li&gt;不可重复读：一个事务在读取某些数据后的某个时间，再次读取以前读过的数据，却发现其读出的数据已经发生了改变、或某些记录已经被删除了！这种现象就叫做“不可重复读”。&lt;/li&gt;
      &lt;li&gt;幻读：一个事务按相同的查询条件重新读取以前检索过的数据，却发现其他事务插入了满足其查询条件的新数据，这种现象就称为“幻读”。&lt;/li&gt;
    &lt;/ol&gt;
  &lt;/li&gt;
&lt;/ul&gt;

&lt;h2 id=&quot;heading-锁的分类&quot;&gt;锁的分类&lt;/h2&gt;

&lt;h3 id=&quot;heading-数据库维度&quot;&gt;数据库维度&lt;/h3&gt;

&lt;ul&gt;
  &lt;li&gt;共享锁:&lt;br /&gt;
用于不更改或不更新数据的操作（只读操作）。共享锁允许并发事务读取同一个资源，数据资源上存在共享锁时，任何其他事务不允许修改数据&lt;/li&gt;
  &lt;li&gt;排它锁:&lt;br /&gt;
用于数据修改，确保不会同时多重更新同一数据。资源上存在排他锁时，其他任何事务不允许给资源上锁，当资源上有其他锁时，也无法对其加上排它锁&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;PS：只有共享锁与共享锁相互兼容，共享锁与排它锁、排它锁之间都互不兼容&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;
    &lt;p&gt;意向锁&lt;/p&gt;
  &lt;/li&gt;
  &lt;li&gt;
    &lt;p&gt;更新锁&lt;/p&gt;
    &lt;ol&gt;
      &lt;li&gt;用于可更新的资源中，防止多个会话在读取、锁定以及随后可能进行的资源更新时发生的死锁问题。&lt;/li&gt;
      &lt;li&gt;通常形式的死锁：一般一个更新模式由一个事务组成，此事务读取记录，获取资源的共享锁，然后修改行，此操作要求锁转换为排它锁。如果两个事务同时获得了资源上的共享锁，然后试图同时更新数据，则一个事务尝试将锁转换为排它锁。由于一个事务的排它锁与另一事务的共享锁的不兼容，从共享锁到排它锁的转换必须要等待一段时间，发送锁等待。而第二个事务同时也试图获取排它锁进行更新。由于两个事务都要转化为排它锁，并且每个事务都要等待另一个事务释放掉共享锁，因此发生死锁&lt;/li&gt;
      &lt;li&gt;更新锁一次只有一个事务可以获取资源的更新锁。如果事务修改资源，那么更新锁转化为排它锁，否则转化为共享锁。当资源上存在更新锁时，允许资源被读取（即更新锁与共享锁兼容），但不允许资源被修改&lt;/li&gt;
      &lt;li&gt;一般来说，在执行UPDATE操作时，SQL SERVER会使用到更新锁而不是依次加上共享锁和排它锁，已经回避了这种通常形式的死锁，更新锁与意向锁相互兼容&lt;/li&gt;
    &lt;/ol&gt;
  &lt;/li&gt;
&lt;/ul&gt;

&lt;h3 id=&quot;heading-锁机制&quot;&gt;锁机制&lt;/h3&gt;

&lt;table&gt;
  &lt;thead&gt;
    &lt;tr&gt;
      &lt;th&gt;DBMS&lt;/th&gt;
      &lt;th&gt;SELECT&lt;/th&gt;
      &lt;th&gt;UPDATE&lt;/th&gt;
      &lt;th&gt;INSERT&lt;/th&gt;
      &lt;th&gt;DELETE&lt;/th&gt;
    &lt;/tr&gt;
  &lt;/thead&gt;
  &lt;tbody&gt;
    &lt;tr&gt;
      &lt;td&gt;MySQL(InnoDB)&lt;/td&gt;
      &lt;td&gt;不加锁&lt;/td&gt;
      &lt;td&gt;排它锁&lt;/td&gt;
      &lt;td&gt;排它锁&lt;/td&gt;
      &lt;td&gt;排它锁&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td&gt;SQL SERVER&lt;/td&gt;
      &lt;td&gt;共享锁&lt;/td&gt;
      &lt;td&gt;更新锁&lt;/td&gt;
      &lt;td&gt;排它锁&lt;/td&gt;
      &lt;td&gt;排它锁&lt;/td&gt;
    &lt;/tr&gt;
  &lt;/tbody&gt;
&lt;/table&gt;

&lt;p&gt;这两种锁机制的区别在于MySQL的查询与更新操作互相不阻塞；而SQL SERVER的更新锁转化成排它锁之前，其查询与更新操作互相不阻塞，当更新锁要转化为排它锁时，需要等待共享锁的释放，当更新锁转化为排它锁后，查询数据需要等待排它锁的释放。&lt;/p&gt;

&lt;p&gt;参考：&lt;br /&gt;
&lt;a href=&quot;http://blog.csdn.net/samjustin1/article/details/52210125&quot;&gt;数据库锁机制&lt;/a&gt;&lt;br /&gt;
&lt;a href=&quot;http://blog.chinaunix.net/uid-24111901-id-2627857.html&quot;&gt;InnoDB锁机制&lt;/a&gt;&lt;br /&gt;
&lt;a href=&quot;http://blog.itpub.net/13651903/viewspace-1091664/&quot;&gt;SQL SERVER锁机制&lt;/a&gt;&lt;/p&gt;

&lt;h3 id=&quot;heading-程序员思想维度&quot;&gt;程序员思想维度&lt;/h3&gt;
&lt;ul&gt;
  &lt;li&gt;悲观锁
    &lt;ol&gt;
      &lt;li&gt;悲观并发控制（又名“悲观锁”，Pessimistic Concurrency Control，缩写“PCC”）是一种并发控制的方法。它可以阻止一个事务以影响其他用户的方式来修改数据。如果一个事务执行的操作都某行数据应用了锁，那只有当这个事务把锁释放，其他事务才能够执行与该锁冲突的操作。悲观锁的实现，往往依靠数据库提供的锁机制。悲观并发控制主要用于数据争用激烈的环境，以及发生并发冲突时使用锁保护数据的成本要低于回滚事务的成本的环境中。&lt;/li&gt;
      &lt;li&gt;悲观并发控制实际上是“先取锁再访问”的保守策略，为数据处理的安全提供了保证。但是在效率方面，处理加锁的机制会让数据库产生额外的开销，还有增加产生死锁的机会；另外，在只读型事务处理中由于不会产生冲突，也没必要使用锁，这样做只能增加系统负载；还有会降低了并行性，一个事务如果锁定了某行数据，其他事务就必须等待该事务处理完才可以处理那行数&lt;/li&gt;
    &lt;/ol&gt;
  &lt;/li&gt;
  &lt;li&gt;乐观锁
    &lt;ol&gt;
      &lt;li&gt;乐观并发控制（又名“乐观锁”，Optimistic Concurrency Control，缩写“OCC”）是一种并发控制的方法。它假设多用户并发的事务在处理时不会彼此互相影响，各事务能够在不产生锁的情况下处理各自影响的那部分数据。在提交数据更新之前，每个事务会先检查在该事务读取数据后，有没有其他事务又修改了该数据。如果其他事务有更新的话，正在提交的事务会进行回滚。&lt;/li&gt;
      &lt;li&gt;乐观并发控制相信事务之间的数据竞争(data race)的概率是比较小的，因此尽可能直接做下去，直到提交的时候才去锁定，所以不会主动产生任何锁和死锁。但是在并发量高的情况下，可能导致某次数据修改多次重试，影响单次成功操作的时间。&lt;/li&gt;
      &lt;li&gt;数据版本实现乐观锁：实现数据版本有两种方式，第一种是使用版本号，第二种是使用时间戳。使用版本号时，可以在数据初始化时指定一个版本号，每次对数据的更新操作都对版本号执行+1操作。并判断当前版本号是不是该数据的最新的版本号。
        &lt;div class=&quot;highlighter-rouge&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;update table 
set date=1,version=version+1
where id=#{id} and version=#{version};
&lt;/code&gt;&lt;/pre&gt;
        &lt;/div&gt;
      &lt;/li&gt;
    &lt;/ol&gt;
  &lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;参考：&lt;br /&gt;
&lt;a href=&quot;http://www.open-open.com/lib/view/open1452046967245.html&quot;&gt;乐观锁与悲观锁&lt;/a&gt;&lt;/p&gt;

&lt;h2 id=&quot;heading-乐观锁另一种实现方式cas&quot;&gt;乐观锁另一种实现方式CAS&lt;/h2&gt;

&lt;p&gt;CAS是项乐观锁技术，当多个线程尝试使用CAS同时更新同一个变量时，只有其中一个线程能更新变量的值，而其它线程都失败，失败的线程并不会被挂起，而是被告知这次竞争中失败，并可以再次尝试。&lt;/p&gt;

&lt;p&gt;CAS 操作包含三个操作数 —— 内存位置（V）、预期原值（A）和新值(B)。如果内存位置的值与预期原值相匹配，那么处理器会自动将该位置值更新为新值。否则，处理器不做任何操作。无论哪种情况，它都会在 CAS 指令之前返回该位置的值。CAS 有效地说明了“我认为位置 V 应该包含值 A；如果包含该值，则将 B 放到这个位置；否则，不要更改该位置，只告诉我这个位置现在的值即可。”这其实和乐观锁的冲突检查+数据更新的原理是一样的。&lt;/p&gt;

&lt;p&gt;java.util.concurrent(J.U.C)就是建立在CAS之上的。相对于对于synchronized这种阻塞算法，CAS是非阻塞算法的一种常见实现。所以J.U.C在性能上有了很大的提升。&lt;/p&gt;
&lt;div class=&quot;highlighter-rouge&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;public class AtomicInteger extends Number implements java.io.Serializable {
    private volatile int value;  
 
    public final int get() {  
        return value;  
    }  
 
    public final int getAndIncrement() {  
        for (;;) {  
            int current = get();  
            int next = current + 1;  
            if (compareAndSet(current, next))  
                return current;  
        }  
    }  
 
    public final boolean compareAndSet(int expect, int update) {  
        return unsafe.compareAndSwapInt(this, valueOffset, expect, update);  
    }  
}
&lt;/code&gt;&lt;/pre&gt;
&lt;/div&gt;

&lt;p&gt;参考：&lt;br /&gt;
&lt;a href=&quot;http://www.importnew.com/20472.html&quot;&gt;乐观锁的一种实现方式—CAS&lt;/a&gt;&lt;/p&gt;

&lt;h2 id=&quot;heading-案例1初审统计数据迁移&quot;&gt;案例1：初审统计数据迁移&lt;/h2&gt;

&lt;ul&gt;
  &lt;li&gt;迁移背景&lt;br /&gt;
原有的统计方式采用的是实时count的方法获取统计数据，造成的问题是查询慢且无法获取长时间段的统计数据（sql超时）、无法获取某日统计数据的快照（前一天的待审核数据会变成今天的审核通过数据）&lt;/li&gt;
  &lt;li&gt;采用迁移方式&lt;br /&gt;
使用raptor迁移平台，扫描审核记录表，取出累计统计数据后进行加1操作，然后更新到统计表中。由于平台特性，数据迁移过程具有高并发性，由于强行采用先读取后更新的方式，会造成丢失更新的情况，于是这里考虑采用CAS&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;step 1:&lt;/p&gt;
&lt;div class=&quot;highlighter-rouge&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;select id,passCount,rejectCount,hideCount,warnCount,waitCount 
from book.TradeItemAuditCount 
where type = #{type} and date = #{date} and editor = #{editor} 
and isDeleted = 0 limit 1

&lt;/code&gt;&lt;/pre&gt;
&lt;/div&gt;
&lt;p&gt;step 2:【失败重试】&lt;/p&gt;
&lt;div class=&quot;highlighter-rouge&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;update book.TradeItemAuditCount 
set passCount = #{passCount} , rejectCount = #{rejectCount} , hideCount = #{hideCount} , warnCount = #{warnCount} , waitCount = #{waitCount} , updated = #{updated}
where id = #{id} and passCount = #{oldPassCount} and rejectCount = #{oldRejectCount} and hideCount = #{oldHideCount} and warnCount = #{oldWarnCount} and waitCount = #{oldWaitCount}
and isDeleted = 0 limit 1
&lt;/code&gt;&lt;/pre&gt;
&lt;/div&gt;

&lt;ul&gt;
  &lt;li&gt;处理结果&lt;br /&gt;
一共扫描审核结果4335668条数据，对重试次数超过100的更新操作进行记录，发现更新操作出现大部分的重试，任务本身DB写操作的qps较低【都不需要通过控制台限制速率..】&lt;/li&gt;
&lt;/ul&gt;

&lt;h2 id=&quot;heading-案例2商品库存&quot;&gt;案例2：商品库存&lt;/h2&gt;
&lt;ul&gt;
  &lt;li&gt;商品库存与上述案例1一致，都是对数据记录进行加减操作，发现库存的更新方式如下：
    &lt;div class=&quot;highlighter-rouge&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;update 库存表
set stock=stock-1
where id=#{id}
&lt;/code&gt;&lt;/pre&gt;
    &lt;/div&gt;
  &lt;/li&gt;
  &lt;li&gt;
    &lt;p&gt;直接使用数据库的排它锁就简单的避免了并发导致的丢失更新问题，之前提到的一次只有一个事务拥有资源的排它锁，并发的更新操作都试图占有资源的排它锁，当资源上存在排它锁时，其他更新操作需要等待锁的释放&lt;/p&gt;
  &lt;/li&gt;
  &lt;li&gt;相比案例1的解决方案，案例2的解决方式直接使用了MySQL InnoDB更新操作本身就拥有的排它锁，不需要额外的开销，而案例1不必要的查询操作以及多次的重试操作严重影响到了数据迁移的性能，所以案例1是反面例子..&lt;/li&gt;
&lt;/ul&gt;

&lt;h2 id=&quot;heading-案例3商品打标&quot;&gt;案例3：商品打标&lt;/h2&gt;
&lt;ul&gt;
  &lt;li&gt;随着上打标的qps上涨，出现达标更新数据丢失的情况
    &lt;div class=&quot;highlighter-rouge&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;&lt;span class=&quot;p&quot;&gt;{&lt;/span&gt;&lt;span class=&quot;nt&quot;&gt;&quot;tags&quot;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;:&lt;/span&gt;&lt;span class=&quot;s2&quot;&gt;&quot;16,32,233,22&quot;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt;&lt;span class=&quot;nt&quot;&gt;&quot;itemState&quot;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;:&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;1&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt;&lt;span class=&quot;nt&quot;&gt;&quot;hd&quot;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;:&lt;/span&gt;&lt;span class=&quot;s2&quot;&gt;&quot;ai:4|nd:18&quot;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt;&lt;span class=&quot;nt&quot;&gt;&quot;au&quot;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;:&lt;/span&gt;&lt;span class=&quot;s2&quot;&gt;&quot;baoming&quot;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;}&lt;/span&gt;&lt;span class=&quot;w&quot;&gt;
&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;
    &lt;/div&gt;
  &lt;/li&gt;
  &lt;li&gt;处理方案
    &lt;ol&gt;
      &lt;li&gt;乐观锁：采用CAS
        &lt;div class=&quot;highlighter-rouge&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;update TradeItem
set extra=#{extra}
where tradeItemId=#{tradeItemId} and extra=#{oldExtra}
&lt;/code&gt;&lt;/pre&gt;
        &lt;/div&gt;
        &lt;p&gt;这里使用长字符串做更新条件，会影响到SQL性能？？？&lt;/p&gt;
      &lt;/li&gt;
      &lt;li&gt;乐观锁：采用数据版本 
 表中新增version字段标识数据版本，作为数据更新的检查方式
        &lt;div class=&quot;highlighter-rouge&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;update TradeItem
set extra=#{extra} , version=version+1
where tradeItemId=#{tradeItemId} and version=#{version}
&lt;/code&gt;&lt;/pre&gt;
        &lt;/div&gt;
        &lt;p&gt;此方案改造较大，还需要为表新增字段，而且采用乐观锁拥有这一律的弊端：重试带来的时间代价，一旦并发量上涨，某次更新操作的重试次数也会随之上涨，直接影响到暴露服务的响应时间。【限制重试次数能够一定程度上控制更新操作的响应时间，但是仍然会出现更新丢失的现象（让调用方进行重试操作，分摊单次请求的响应时间？）】&lt;/p&gt;
      &lt;/li&gt;
      &lt;li&gt;悲观锁&lt;br /&gt;
更新丢失的根本原因是执行查询、修改两个操作之间数据被另一事务修改了，单纯的UPDATE操作其实也是进行着先查询后修改的操作，没有产生更新丢失是因为数据上存在排它锁（sql server则是更新锁），在执行期间并不允许其他修改。同理我们将要打标的商品记录加上排它锁或者更新锁就能解决问题。&lt;br /&gt;
MySQL:
        &lt;div class=&quot;highlighter-rouge&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;start transaction;
SELECT extra
FROM TradeItem 
WHERE tradeItemId=#{tradeItemId}
FOR UPDATE;
UPDATE TradeItem 
SET extra = bdo.AddTag(tag,extra)
WHERE tradeItemId=#{tradeItemId};
commit;
&lt;/code&gt;&lt;/pre&gt;
        &lt;/div&gt;
        &lt;p&gt;SQL SERVER:&lt;/p&gt;
        &lt;div class=&quot;highlighter-rouge&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;BEGIN TRANSACTION --开始一个事务
SELECT extra
FROM TradeItem WITH (UPDLOCK)
WHERE tradeItemId=#{tradeItemId}
UPDATE TradeItem 
SET extra = bdo.AddTag(tag,extra)
WHERE tradeItemId=#{tradeItemId}
COMMIT TRANSACTION --提交事务
&lt;/code&gt;&lt;/pre&gt;
        &lt;/div&gt;
        &lt;p&gt;该方案避免了重试带来的开销，同时使用排它锁（更新锁）也没有额外增加锁的开销【直接把commit写到sql里面会被raptor拦截，只能使用dateSource.getConnection设置自动提交为false后提交】&lt;/p&gt;
      &lt;/li&gt;
    &lt;/ol&gt;
  &lt;/li&gt;
&lt;/ul&gt;

&lt;h2 id=&quot;heading-悲观锁乐观锁的取舍&quot;&gt;悲观锁乐观锁的取舍&lt;/h2&gt;</content><author><name>{&quot;name&quot;=&gt;nil, &quot;job_title&quot;=&gt;nil, &quot;location&quot;=&gt;nil, &quot;email&quot;=&gt;nil, &quot;social_links&quot;=&gt;[{&quot;name&quot;=&gt;&quot;facebook&quot;, &quot;url&quot;=&gt;nil}, {&quot;name&quot;=&gt;&quot;github&quot;, &quot;url&quot;=&gt;&quot;https://github.com/Cuner&quot;}, {&quot;name&quot;=&gt;&quot;instagram&quot;, &quot;url&quot;=&gt;nil}, {&quot;name&quot;=&gt;&quot;linkedin&quot;, &quot;url&quot;=&gt;nil}, {&quot;name&quot;=&gt;&quot;stackoverflow&quot;, &quot;url&quot;=&gt;nil}, {&quot;name&quot;=&gt;&quot;twitter&quot;, &quot;url&quot;=&gt;nil}, {&quot;name&quot;=&gt;&quot;vk&quot;, &quot;url&quot;=&gt;nil}]}</name></author><category term="mysql" /><summary type="html">数据库锁机制</summary></entry></feed>